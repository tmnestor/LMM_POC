{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 Vision: 2-Turn Balance-Description Bank Statement Extraction\n",
    "\n",
    "**Protocol**: Two independent single-turn prompts + Python parsing/filtering\n",
    "\n",
    "**Key Insight**: Balance-description prompt works for BOTH date-per-row AND date-grouped formats!\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Turn 0: Image + Prompt â†’ Headers (fresh context)\n",
    "        â†“ (Python pattern matching)\n",
    "        â†“ (Check if Balance column exists)\n",
    "Turn 1: Image + Prompt â†’ Balance-Description extraction (fresh context)\n",
    "        â†“ (Python parsing + filtering)\n",
    "Schema Fields: TRANSACTION_DATES, LINE_ITEM_DESCRIPTIONS, TRANSACTION_AMOUNTS_PAID\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to concepts (Date, Description, Debit, Credit, Balance)\n",
    "3. **Turn 1 (LLM)**: Extract using balance-description prompt (works for all date formats)\n",
    "4. **Python Parsing**: Parse hierarchical output â†’ Filter for debits â†’ Extract schema fields\n",
    "\n",
    "### Why Balance-Description Works:\n",
    "- **Anchors extraction to Balance column** - unambiguous reference point\n",
    "- **Works for date-per-row**: Each transaction gets its date\n",
    "- **Works for date-grouped**: Date headers naturally map to transactions\n",
    "- **No format classification needed** - eliminates Turn 0.5 entirely!\n",
    "\n",
    "### Key Advantages over 3-Turn Table Extraction:\n",
    "- âœ… **Simpler pipeline** - 2 turns instead of 3\n",
    "- âœ… **No format classification** - works universally\n",
    "- âœ… **Balance-anchored** - reduces debit/credit confusion\n",
    "- âœ… **Hierarchical output** - easier to parse date groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "\n",
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Llama-3.2-Vision model\n",
    "# Update this path to your local Llama model\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"ğŸ”§ Loading Llama-3.2-Vision model...\")\n",
    "\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_id,\n",
    "    use_quantization=False,\n",
    "    device_map='auto',\n",
    "    max_new_tokens=4096,  # Increased for balance-description output\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Add tie_weights() call\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    print(\"âœ… Model weights tied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ tie_weights() warning: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load bank statement image\n",
    "# Update this path to your test image\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/cba_date_grouped.png\"\n",
    "\n",
    "print(\"ğŸ“ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"âœ… Image loaded: {image.size}\")\n",
    "print(f\"âœ… Images list created with {len(images)} image(s)\")\n",
    "\n",
    "# Display the loaded image for visual verification\n",
    "print(\"ğŸ–¼ï¸  Bank statement image:\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Statement Extraction Protocol (2-Turn Balance-Description)\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract using balance-description prompt\n",
    "- Python: Parse, filter, and extract schema fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Turn 0 - Identify table headers (prompt)\n",
    "# TURN 0: Identify Table Headers\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ’¬ TURN 0: Identifying actual table headers\")\n",
    "print(\"ğŸ¤– Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Turn 0 - Execute and parse headers\n",
    "\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "turn0_response = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "# Free memory\n",
    "del inputs, output, generate_ids\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"âœ… Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(turn0_response)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Parse the identified headers\n",
    "header_lines = [line.strip() for line in turn0_response.split('\\n') if line.strip()]\n",
    "identified_headers = []\n",
    "\n",
    "for line in header_lines:\n",
    "    cleaned = line.lstrip('0123456789.-â€¢* ').strip()\n",
    "    cleaned = cleaned.replace('**', '').replace('__', '')\n",
    "    if cleaned.endswith(':'):\n",
    "        continue\n",
    "    if len(cleaned) > 40:\n",
    "        continue\n",
    "    if cleaned and len(cleaned) > 2:\n",
    "        identified_headers.append(cleaned)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Parsed {len(identified_headers)} column headers:\")\n",
    "for i, header in enumerate(identified_headers, 1):\n",
    "    print(f\"  {i}. '{header}'\")\n",
    "\n",
    "# Store for subsequent turns\n",
    "table_headers = identified_headers\n",
    "print(f\"\\nâœ… Stored table_headers: {table_headers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**\n",
    "- Which header represents **Credit/Deposit**\n",
    "- Which header represents **Balance** (CRITICAL for this approach!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Pattern Matching - Map headers to generic columns\n",
    "\n",
    "DATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\n",
    "DESCRIPTION_PATTERNS = [\n",
    "    'description', 'details', 'transaction details', 'trans details',\n",
    "    'particulars', 'narrative', 'transaction', 'trans'\n",
    "]\n",
    "DEBIT_PATTERNS = ['debit', 'debits', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\n",
    "CREDIT_PATTERNS = ['credit', 'credits', 'deposit', 'deposits', 'received', 'cr']\n",
    "BALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n",
    "AMOUNT_PATTERNS = ['amount', 'amt', 'value', 'total']\n",
    "\n",
    "def match_header(headers, patterns, fallback=None):\n",
    "    \"\"\"Match a header using pattern keywords.\"\"\"\n",
    "    headers_lower = [h.lower() for h in headers]\n",
    "    \n",
    "    # Try exact match first\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern == header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    # Try substring match\n",
    "    for pattern in patterns:\n",
    "        if len(pattern) > 2:\n",
    "            for i, header_lower in enumerate(headers_lower):\n",
    "                if pattern in header_lower:\n",
    "                    return headers[i]\n",
    "    \n",
    "    return fallback\n",
    "\n",
    "# Perform pattern matching\n",
    "date_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\n",
    "desc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n",
    "amount_col = match_header(table_headers, AMOUNT_PATTERNS, fallback=None)\n",
    "debit_col = match_header(table_headers, DEBIT_PATTERNS, fallback=amount_col if amount_col else 'Debit')\n",
    "credit_col = match_header(table_headers, CREDIT_PATTERNS, fallback=amount_col if amount_col else 'Credit')\n",
    "balance_col = match_header(table_headers, BALANCE_PATTERNS, fallback=None)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATTERN MATCHING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“‹ Extracted Headers: {table_headers}\")\n",
    "print(f\"\\nğŸ” Mapped Columns:\")\n",
    "print(f\"  Date        â†’ '{date_col}'\")\n",
    "print(f\"  Description â†’ '{desc_col}'\")\n",
    "print(f\"  Debit       â†’ '{debit_col}'\")\n",
    "print(f\"  Credit      â†’ '{credit_col}'\")\n",
    "print(f\"  Balance     â†’ '{balance_col}'\")\n",
    "\n",
    "# CRITICAL: Check if Balance column exists\n",
    "has_balance = balance_col is not None and balance_col in table_headers\n",
    "print(f\"\\nğŸ¯ Balance column detected: {'âœ… YES' if has_balance else 'âŒ NO'}\")\n",
    "\n",
    "if not has_balance:\n",
    "    print(\"âš ï¸  WARNING: No balance column found. This notebook requires a balance column.\")\n",
    "    print(\"   Consider using the 3-turn table extraction notebook instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 1: Balance-Description Extraction\n",
    "\n",
    "This is the key innovation - instead of extracting a markdown table, we ask the model to list all balances with their associated transaction details.\n",
    "\n",
    "**Prompt Pattern:**\n",
    "```\n",
    "List all the balances in the {balance_col} column, including:\n",
    "- Date from the Date Header of the balance\n",
    "- {desc_col}\n",
    "- {debit_col} Amount or \"NOT_FOUND\"\n",
    "- {credit_col} Amount or \"NOT_FOUND\"\n",
    "```\n",
    "\n",
    "This produces hierarchical output that's easy to parse and works for both date formats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Turn 1 - Balance-Description Extraction Prompt\n",
    "\n",
    "if has_balance:\n",
    "    extraction_prompt = f\"\"\"List all the balances in the {balance_col} column, including:\n",
    "- Date from the Date Header of the balance\n",
    "- {desc_col}\n",
    "- {debit_col} Amount or \"NOT_FOUND\"\n",
    "- {credit_col} Amount or \"NOT_FOUND\" \"\"\"\n",
    "    \n",
    "    print(\"ğŸ“ TURN 1: Balance-Description Extraction\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Extraction Prompt:\")\n",
    "    print(extraction_prompt)\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"âŒ Cannot proceed - no balance column detected.\")\n",
    "    extraction_prompt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Turn 1 - Execute extraction (INDEPENDENT, fresh context)\n",
    "\n",
    "if extraction_prompt:\n",
    "    # CRITICAL: Create FRESH message structure (NOT appending to conversation history)\n",
    "    messageDataStructure_turn1 = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": extraction_prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ¤– Generating response with Llama-3.2-Vision...\")\n",
    "    \n",
    "    textInput = processor.apply_chat_template(\n",
    "        messageDataStructure_turn1, add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=4096,  # Increased for balance-description output\n",
    "        do_sample=False,\n",
    "        temperature=None,\n",
    "        top_p=None,\n",
    "    )\n",
    "    \n",
    "    generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "    extraction_response = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "    \n",
    "    # Free memory\n",
    "    del inputs, output, generate_ids\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\nâœ… Turn 1 extraction complete!\")\n",
    "    print(f\"\\nğŸ“Š Response length: {len(extraction_response)} characters\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TURN 1 - BALANCE-DESCRIPTION EXTRACTION:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(extraction_response)\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"âŒ Skipping extraction - no valid prompt.\")\n",
    "    extraction_response = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Parsing: Balance-Description Response\n",
    "\n",
    "Parse the hierarchical balance-description output into transaction rows.\n",
    "\n",
    "Expected format:\n",
    "```\n",
    "1. **Thu 04 Sep 2025**\n",
    "   - Description: Direct Debit DOMINO'S PTY LTD\n",
    "   - Debit: $117.57\n",
    "   - Balance: $8586.28 CR\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Parse balance-description response\n",
    "\n",
    "def parse_balance_description_response(response_text, date_col, desc_col, debit_col, credit_col, balance_col):\n",
    "    \"\"\"\n",
    "    Parse the hierarchical balance-description response into transaction rows.\n",
    "    \n",
    "    Returns list of dicts with standardized column names.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    current_date = None\n",
    "    current_transaction = {}\n",
    "    \n",
    "    lines = response_text.strip().split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Check for date header (numbered item with bold date)\n",
    "        # Pattern: \"1. **Thu 04 Sep 2025**\" or \"1. Thu 04 Sep 2025\"\n",
    "        date_match = re.match(r\"^\\d+\\.\\s*\\*?\\*?([A-Za-z]{3}\\s+\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})\\*?\\*?\", line)\n",
    "        if not date_match:\n",
    "            # Also try without day name: \"1. **04 Sep 2025**\"\n",
    "            date_match = re.match(r\"^\\d+\\.\\s*\\*?\\*?(\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})\\*?\\*?\", line)\n",
    "        if not date_match:\n",
    "            # Also try DD/MM/YYYY format: \"1. **03/05/2025**\"\n",
    "            date_match = re.match(r\"^\\d+\\.\\s*\\*?\\*?(\\d{1,2}/\\d{1,2}/\\d{4})\\*?\\*?\", line)\n",
    "        \n",
    "        if date_match:\n",
    "            # Save previous transaction if exists\n",
    "            if current_transaction and current_date:\n",
    "                current_transaction[date_col] = current_date\n",
    "                rows.append(current_transaction)\n",
    "                current_transaction = {}\n",
    "            \n",
    "            current_date = date_match.group(1).strip()\n",
    "            continue\n",
    "        \n",
    "        # Check for field lines\n",
    "        # Pattern: \"- Description: ...\" or \"   - Debit: ...\"\n",
    "        field_match = re.match(r\"^\\s*-\\s*(\\w+):\\s*(.+)$\", line)\n",
    "        if field_match:\n",
    "            field_name = field_match.group(1).strip().lower()\n",
    "            field_value = field_match.group(2).strip()\n",
    "            \n",
    "            # Map field names to column names\n",
    "            if field_name == \"description\":\n",
    "                # If we already have a description, this is a new transaction under same date\n",
    "                if desc_col in current_transaction and current_transaction[desc_col]:\n",
    "                    # Save current transaction\n",
    "                    if current_date:\n",
    "                        current_transaction[date_col] = current_date\n",
    "                    rows.append(current_transaction)\n",
    "                    current_transaction = {}\n",
    "                current_transaction[desc_col] = field_value\n",
    "            \n",
    "            elif field_name == \"debit\" or field_name == debit_col.lower() or field_name == \"withdrawal\":\n",
    "                current_transaction[debit_col] = field_value\n",
    "            \n",
    "            elif field_name == \"credit\" or field_name == credit_col.lower() or field_name == \"deposit\":\n",
    "                current_transaction[credit_col] = field_value\n",
    "            \n",
    "            elif field_name == \"balance\":\n",
    "                current_transaction[balance_col] = field_value\n",
    "            \n",
    "            elif field_name == \"amount\":\n",
    "                # Generic amount - put in debit by default\n",
    "                if debit_col not in current_transaction:\n",
    "                    current_transaction[debit_col] = field_value\n",
    "    \n",
    "    # Don't forget the last transaction\n",
    "    if current_transaction and current_date:\n",
    "        current_transaction[date_col] = current_date\n",
    "        rows.append(current_transaction)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "\n",
    "def parse_markdown_table(markdown_text):\n",
    "    \"\"\"Fallback: Parse markdown table into list of dictionaries.\"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line:\n",
    "            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n",
    "            if cleaned:\n",
    "                header_idx = i\n",
    "                break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        return []\n",
    "    \n",
    "    header_line = lines[header_idx]\n",
    "    header_parts = [h.strip() for h in header_line.split('|')]\n",
    "    if header_parts and header_parts[0] == '':\n",
    "        header_parts = header_parts[1:]\n",
    "    if header_parts and header_parts[-1] == '':\n",
    "        header_parts = header_parts[:-1]\n",
    "    headers = [h for h in header_parts if h]\n",
    "    \n",
    "    rows = []\n",
    "    for line in lines[header_idx + 1:]:\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "        cleaned = line.replace('|', '').replace('-', '').replace(' ', '').replace(':', '')\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        value_parts = [v.strip() for v in line.split('|')]\n",
    "        if value_parts and value_parts[0] == '':\n",
    "            value_parts = value_parts[1:]\n",
    "        if value_parts and value_parts[-1] == '':\n",
    "            value_parts = value_parts[:-1]\n",
    "        if len(value_parts) == len(headers):\n",
    "            rows.append(dict(zip(headers, value_parts)))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "\n",
    "# Parse the extraction response\n",
    "if extraction_response:\n",
    "    # Try balance-description format first\n",
    "    all_rows = parse_balance_description_response(\n",
    "        extraction_response, date_col, desc_col, debit_col, credit_col, balance_col\n",
    "    )\n",
    "    \n",
    "    # Fallback to markdown table if balance-description parsing failed\n",
    "    if not all_rows and \"|\" in extraction_response:\n",
    "        print(\"âš ï¸  Fallback: parsing as markdown table\")\n",
    "        all_rows = parse_markdown_table(extraction_response)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Parsed {len(all_rows)} total rows\")\n",
    "    \n",
    "    # Display parsed rows\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PARSED TRANSACTIONS:\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, row in enumerate(all_rows[:10]):  # Show first 10\n",
    "        print(f\"\\n{i+1}. {row}\")\n",
    "    if len(all_rows) > 10:\n",
    "        print(f\"\\n... and {len(all_rows) - 10} more rows\")\n",
    "else:\n",
    "    all_rows = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for Debit Transactions\n",
    "\n",
    "For tax purposes, we only want transactions where the taxpayer PAID money (debits/withdrawals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Filter for debit transactions\n",
    "\n",
    "def parse_amount(value):\n",
    "    \"\"\"Extract numeric value from formatted currency string.\"\"\"\n",
    "    if not value or value.strip() == \"\":\n",
    "        return 0.0\n",
    "    cleaned = value.replace(\"$\", \"\").replace(\",\", \"\").replace(\"CR\", \"\").replace(\"DR\", \"\").strip()\n",
    "    try:\n",
    "        return float(cleaned)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def is_non_transaction_row(row, desc_col):\n",
    "    \"\"\"Check if this row is NOT an actual transaction.\"\"\"\n",
    "    desc = row.get(desc_col, \"\").strip().upper()\n",
    "    if \"OPENING BALANCE\" in desc:\n",
    "        return True\n",
    "    if \"CLOSING BALANCE\" in desc:\n",
    "        return True\n",
    "    if \"BROUGHT FORWARD\" in desc:\n",
    "        return True\n",
    "    if \"CARRIED FORWARD\" in desc:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_debit_transactions(rows, debit_col, desc_col=None):\n",
    "    \"\"\"Filter rows to only those with actual debit transactions (amount > 0).\"\"\"\n",
    "    debit_rows = []\n",
    "    for row in rows:\n",
    "        debit_value = row.get(debit_col, \"\").strip()\n",
    "        \n",
    "        if not debit_value:\n",
    "            continue\n",
    "        \n",
    "        # Skip NOT_FOUND values\n",
    "        if debit_value.upper() == \"NOT_FOUND\":\n",
    "            continue\n",
    "        \n",
    "        # Parse amount and check if > 0\n",
    "        amount = parse_amount(debit_value)\n",
    "        if amount <= 0:\n",
    "            continue\n",
    "        \n",
    "        if desc_col and is_non_transaction_row(row, desc_col):\n",
    "            continue\n",
    "        \n",
    "        debit_rows.append(row)\n",
    "    \n",
    "    return debit_rows\n",
    "\n",
    "\n",
    "# Filter to debit transactions\n",
    "debit_rows = filter_debit_transactions(all_rows, debit_col, desc_col)\n",
    "\n",
    "print(f\"\\nğŸ“Š Filtered to {len(debit_rows)} debit transactions\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEBIT TRANSACTIONS ONLY:\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in enumerate(debit_rows):\n",
    "    date = row.get(date_col, \"N/A\")\n",
    "    desc = row.get(desc_col, \"N/A\")\n",
    "    amount = row.get(debit_col, \"N/A\")\n",
    "    print(f\"{i+1}. [{date}] {desc} - {amount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Schema Fields\n",
    "\n",
    "Convert parsed debit transactions to universal.yaml schema format:\n",
    "- `TRANSACTION_DATES`: Pipe-delimited dates\n",
    "- `LINE_ITEM_DESCRIPTIONS`: Pipe-delimited descriptions\n",
    "- `TRANSACTION_AMOUNTS_PAID`: Pipe-delimited amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Extract schema fields\n",
    "\n",
    "def extract_schema_fields(debit_rows, date_col, desc_col, debit_col, all_rows=None):\n",
    "    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n",
    "    if not debit_rows:\n",
    "        return {\n",
    "            \"DOCUMENT_TYPE\": \"BANK_STATEMENT\",\n",
    "            \"STATEMENT_DATE_RANGE\": \"NOT_FOUND\",\n",
    "            \"TRANSACTION_DATES\": \"NOT_FOUND\",\n",
    "            \"LINE_ITEM_DESCRIPTIONS\": \"NOT_FOUND\",\n",
    "            \"TRANSACTION_AMOUNTS_PAID\": \"NOT_FOUND\",\n",
    "        }\n",
    "    \n",
    "    # Extract debit transaction fields\n",
    "    debit_dates = []\n",
    "    descriptions = []\n",
    "    amounts = []\n",
    "    \n",
    "    for row in debit_rows:\n",
    "        date = row.get(date_col, \"\").strip()\n",
    "        desc = row.get(desc_col, \"\").strip()\n",
    "        amount = row.get(debit_col, \"\").strip()\n",
    "        \n",
    "        if date:\n",
    "            debit_dates.append(date)\n",
    "        if desc:\n",
    "            descriptions.append(desc)\n",
    "        if amount:\n",
    "            amounts.append(amount)\n",
    "    \n",
    "    # Calculate date range from ALL transactions (not just debits)\n",
    "    date_range = \"NOT_FOUND\"\n",
    "    rows_for_range = all_rows if all_rows is not None else debit_rows\n",
    "    all_dates = [row.get(date_col, \"\").strip() for row in rows_for_range]\n",
    "    all_dates = [d for d in all_dates if d]\n",
    "    if all_dates:\n",
    "        date_range = f\"{all_dates[0]} - {all_dates[-1]}\"\n",
    "    \n",
    "    return {\n",
    "        \"DOCUMENT_TYPE\": \"BANK_STATEMENT\",\n",
    "        \"STATEMENT_DATE_RANGE\": date_range,\n",
    "        \"TRANSACTION_DATES\": \" | \".join(debit_dates) if debit_dates else \"NOT_FOUND\",\n",
    "        \"LINE_ITEM_DESCRIPTIONS\": \" | \".join(descriptions) if descriptions else \"NOT_FOUND\",\n",
    "        \"TRANSACTION_AMOUNTS_PAID\": \" | \".join(amounts) if amounts else \"NOT_FOUND\",\n",
    "    }\n",
    "\n",
    "\n",
    "# Extract schema fields\n",
    "schema_fields = extract_schema_fields(debit_rows, date_col, desc_col, debit_col, all_rows=all_rows)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTED SCHEMA FIELDS:\")\n",
    "print(\"=\" * 60)\n",
    "for field, value in schema_fields.items():\n",
    "    # Truncate long values for display\n",
    "    display_value = str(value)[:100] + \"...\" if len(str(value)) > 100 else str(value)\n",
    "    print(f\"\\n{field}:\")\n",
    "    print(f\"  {display_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This 2-turn balance-description approach:\n",
    "1. âœ… **Eliminated Turn 0.5** - No date format classification needed\n",
    "2. âœ… **Works universally** - Same prompt for date-per-row AND date-grouped\n",
    "3. âœ… **Balance-anchored** - Uses balance column as reference point\n",
    "4. âœ… **Simpler pipeline** - Just 2 LLM calls instead of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Summary statistics\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š EXTRACTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ”§ Method: 2-Turn Balance-Description\")\n",
    "print(f\"ğŸ“‹ Headers detected: {len(table_headers)}\")\n",
    "print(f\"ğŸ’° Balance column: {balance_col}\")\n",
    "print(f\"ğŸ“ Total transactions parsed: {len(all_rows)}\")\n",
    "print(f\"ğŸ’¸ Debit transactions: {len(debit_rows)}\")\n",
    "print(f\"\\nâœ… Pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
