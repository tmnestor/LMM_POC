{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Document Extraction with Llama Vision (V2)\n",
    "\n",
    "Streamlined batch processing notebook using modular components.\n",
    "\n",
    "**V2 Features:**\n",
    "- **Sophisticated bank statement extraction** using multi-turn UnifiedBankExtractor\n",
    "- Turn 0: Header detection (identifies actual column names)\n",
    "- Turn 1: Adaptive extraction with structure-dynamic prompts\n",
    "- Automatic strategy selection: BALANCE_DESCRIPTION, AMOUNT_DESCRIPTION, etc.\n",
    "- Early model loading\n",
    "- Configurable output directory\n",
    "- Comprehensive analytics and visualizations\n",
    "- Clean, modular code structure\n",
    "\n",
    "**Bank Statement Processing Toggle:**\n",
    "- `USE_SOPHISTICATED_BANK_EXTRACTION`: True (default) uses multi-turn extraction\n",
    "- `ENABLE_BALANCE_CORRECTION`: Optional mathematical balance validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: field_types_from_yaml = {'monetary': ['GST_AMOUNT', 'TOTAL_AMOUNT', 'LINE_ITEM_PRICES', 'LINE_ITEM_TOTAL_PRICES', 'TRANSACTION_AMOUNTS_PAID', 'TRANSACTION_AMOUNTS_RECEIVED', 'ACCOUNT_BALANCE'], 'boolean': ['IS_GST_INCLUDED'], 'list': ['LINE_ITEM_DESCRIPTIONS', 'LINE_ITEM_QUANTITIES', 'LINE_ITEM_PRICES', 'LINE_ITEM_TOTAL_PRICES', 'TRANSACTION_DATES', 'TRANSACTION_AMOUNTS_PAID', 'TRANSACTION_AMOUNTS_RECEIVED', 'ACCOUNT_BALANCE'], 'date': ['INVOICE_DATE', 'STATEMENT_DATE_RANGE', 'TRANSACTION_DATES'], 'transaction_list': ['TRANSACTION_DATES', 'TRANSACTION_AMOUNTS_PAID', 'TRANSACTION_AMOUNTS_RECEIVED', 'ACCOUNT_BALANCE']}\n",
      "DEBUG: boolean fields from YAML = ['IS_GST_INCLUDED']\n",
      "DEBUG: self.boolean_fields = ['IS_GST_INCLUDED']\n",
      "DEBUG _ensure_fields_loaded: BOOLEAN_FIELDS = ['IS_GST_INCLUDED']\n",
      "\u2705 All imports loaded successfully\n",
      "\u2705 Llama batch processing modules imported successfully\n",
      "\u2705 V2: BankStatementAdapter imported for sophisticated bank extraction\n"
     ]
    }
   ],
   "source": [
    "#Cell 1\n",
    "# Enable autoreload for module changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['EVALUATION_METHOD'] = 'order_aware_f1'  # or 'f1', 'kieval', 'order_aware_f1', 'correlation'\n",
    "\n",
    "# Standard library imports\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "\n",
    "# Project-specific imports\n",
    "from common.batch_analytics import BatchAnalytics\n",
    "from common.batch_processor import BatchDocumentProcessor\n",
    "from common.batch_reporting import BatchReporter\n",
    "from common.batch_visualizations import BatchVisualizer\n",
    "from common.evaluation_metrics import load_ground_truth\n",
    "from common.extraction_parser import discover_images\n",
    "from common.gpu_optimization import emergency_cleanup\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "# V2: Sophisticated bank statement processing\n",
    "from common.bank_statement_adapter import BankStatementAdapter\n",
    "\n",
    "print(\"\u2705 All imports loaded successfully\")\n",
    "print(\"\u2705 Llama batch processing modules imported successfully\")\n",
    "print(\"\u2705 V2: BankStatementAdapter imported for sophisticated bank extraction\")\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-emptive Memory Cleanup\n",
    "\n",
    "**CRITICAL for V100**: Run this cell first to prevent OOM errors when switching between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">\ud83e\uddf9 PRE-EMPTIVE V100 MEMORY CLEANUP</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31m\ud83e\uddf9 PRE-EMPTIVE V100 MEMORY CLEANUP\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Clearing any existing model caches before loading...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33mClearing any existing model caches before loading\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udca1 This prevents OOM errors when switching between models on V100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\ud83d\udca1 This prevents OOM errors when switching between models on V100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udea8 Running V100 emergency GPU cleanup...\n",
      "\ud83e\uddf9 Starting V100-optimized GPU memory cleanup...\n",
      "   \ud83d\udcca Initial GPU memory: 0.00GB allocated, 0.00GB reserved\n",
      "   \u2705 Final GPU memory: 0.00GB allocated, 0.00GB reserved\n",
      "   \ud83d\udcbe Memory freed: 0.00GB\n",
      "\u2705 V100-optimized memory cleanup complete\n",
      "\u2705 V100 emergency cleanup complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Memory cleanup complete - ready for model loading</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Memory cleanup complete - ready for model loading\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">\ud83d\udccb Next: Import modules and configure settings</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m\ud83d\udccb Next: Import modules and configure settings\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 2\n",
    "# Initialize console for rich output\n",
    "console = Console()# Pre-emptive V100 Memory Cleanup - Run FIRST to prevent OOM errors\n",
    "rprint(\"[bold red]\ud83e\uddf9 PRE-EMPTIVE V100 MEMORY CLEANUP[/bold red]\")\n",
    "rprint(\"[yellow]Clearing any existing model caches before loading...[/yellow]\")\n",
    "rprint(\"[cyan]\ud83d\udca1 This prevents OOM errors when switching between models on V100[/cyan]\")\n",
    "\n",
    "# Emergency cleanup to ensure clean slate\n",
    "emergency_cleanup(verbose=True)\n",
    "\n",
    "rprint(\"[green]\u2705 Memory cleanup complete - ready for model loading[/green]\")\n",
    "rprint(\"[dim]\ud83d\udccb Next: Import modules and configure settings[/dim]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Configuration set up successfully\n",
      "\ud83d\udcc2 Data directory: /home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic\n",
      "\ud83d\udcca Ground truth: /home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic/ground_truth_synthetic.csv\n",
      "\ud83e\udd16 Model path: /home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\n",
      "\ud83d\udcc1 Output base: /home/jovyan/nfs_share/tod/LMM_POC/output\n",
      "\ud83c\udfaf Mode: Evaluation mode\n",
      "\ud83d\udd27 Preprocessing: Enabled (adaptive)\n",
      "\ud83c\udfe6 V2 Bank Extraction: Enabled (multi-turn)\n",
      "\ud83d\udcd0 Balance Correction: Enabled\n"
     ]
    }
   ],
   "source": [
    "#Cell 3\n",
    "# Environment-specific base paths\n",
    "ENVIRONMENT_BASES = {\n",
    "    'sandbox': '/home/jovyan/nfs_share/tod',\n",
    "    'efs': '/efs/shared/PoC_data'\n",
    "}\n",
    "base_data_path = ENVIRONMENT_BASES['sandbox']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    # Model settings\n",
    "    # 'MODEL_PATH': \"/efs/shared/PTM/Llama-3.2-11B-Vision-Instruct\",\n",
    "    'MODEL_PATH': \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\",\n",
    "\n",
    "    # Batch settings - Using base path for consistency\n",
    "    'DATA_DIR': f'{base_data_path}/LMM_POC/evaluation_data/synthetic',\n",
    "    'GROUND_TRUTH': f'{base_data_path}/LMM_POC/evaluation_data/synthetic/ground_truth_synthetic.csv',\n",
    "    # 'OUTPUT_BASE': f'{base_data_path}/output',\n",
    "    'OUTPUT_BASE': f'{base_data_path}/LMM_POC/output',\n",
    "    'MAX_IMAGES': None,  # None for all, or set limit\n",
    "    'DOCUMENT_TYPES': None,  # None for all, or ['invoice', 'receipt']\n",
    "    'ENABLE_MATH_ENHANCEMENT': True,  # Enable mathematical correction for bank statements\n",
    "    \n",
    "    # Inference and evaluation mode\n",
    "    'INFERENCE_ONLY': False,  # Default: True (inference-only mode)\n",
    "\n",
    "    # Verbosity control\n",
    "    'VERBOSE': True,\n",
    "    'SHOW_PROMPTS': True,\n",
    "\n",
    "    # L40S optimization settings\n",
    "    'USE_QUANTIZATION': False,\n",
    "    'DEVICE_MAP': 'auto',\n",
    "    'MAX_NEW_TOKENS': 3000,  # Reduced for L40S (was 4000 for V100)\n",
    "    'TORCH_DTYPE': 'bfloat16',\n",
    "    'LOW_CPU_MEM_USAGE': True,\n",
    "    \n",
    "    # ============================================================================\n",
    "    # V2: SOPHISTICATED BANK STATEMENT EXTRACTION\n",
    "    # ============================================================================\n",
    "    # Use multi-turn UnifiedBankExtractor for bank statements instead of\n",
    "    # single-turn extraction. This provides:\n",
    "    # - Turn 0: Header detection (identifies actual column names)\n",
    "    # - Turn 1: Adaptive extraction with structure-dynamic prompts\n",
    "    # - Automatic strategy selection based on detected columns\n",
    "    # - Higher accuracy for bank statements (~85%+ vs ~72%)\n",
    "    #\n",
    "    # Set to False to use original single-turn extraction behavior\n",
    "    # ============================================================================\n",
    "    'USE_SOPHISTICATED_BANK_EXTRACTION': True,\n",
    "    \n",
    "    # Optional: Enable balance-based mathematical correction\n",
    "    # Uses balance column deltas to validate debit/credit values\n",
    "    'ENABLE_BALANCE_CORRECTION': True,\n",
    "    \n",
    "    # ============================================================================\n",
    "    # IMAGE PREPROCESSING SETTINGS\n",
    "    # ============================================================================\n",
    "    # Control optional image preprocessing before model inference\n",
    "    # \n",
    "    # ENABLE_PREPROCESSING: Master switch to enable/disable preprocessing\n",
    "    # PREPROCESSING_MODE: Select preprocessing intensity\n",
    "    #   - 'light' or 'recommended': Gentle enhancement for high-quality scans\n",
    "    #     (upscale if <1500px, moderate sharpening, slight contrast boost)\n",
    "    #   - 'moderate': Stronger enhancement for low-resolution scans\n",
    "    #     (upscale to 2000px, higher sharpening, higher contrast)\n",
    "    #   - 'aggressive': Maximum preprocessing for noisy/poor quality scans\n",
    "    #     (grayscale, denoising, auto-contrast, sharpening)\n",
    "    #   - 'adaptive': Automatically selects 'light' or 'moderate' based on image size\n",
    "    # SAVE_PREPROCESSED: Save preprocessed images to disk for inspection (debugging)\n",
    "    # PREPROCESSED_DIR: Directory for saved preprocessed images (if SAVE_PREPROCESSED=True)\n",
    "    # ============================================================================\n",
    "    'ENABLE_PREPROCESSING': True,  # Set to True to enable preprocessing\n",
    "    'PREPROCESSING_MODE': 'adaptive',  # Options: 'light', 'moderate', 'aggressive', 'adaptive', 'recommended'\n",
    "    'SAVE_PREPROCESSED': False,  # Save preprocessed images for inspection\n",
    "    'PREPROCESSED_DIR': None,  # Directory for preprocessed images (None = auto: 'preprocessed_images')\n",
    "}\n",
    "\n",
    "# Make GROUND_TRUTH conditional based on INFERENCE_ONLY mode\n",
    "if CONFIG['INFERENCE_ONLY']:\n",
    "    CONFIG['GROUND_TRUTH'] = None\n",
    "\n",
    "# ============================================================================\n",
    "# PROMPT CONFIGURATION - Explicit file and key mapping\n",
    "# ============================================================================\n",
    "# This configuration controls which prompt files and keys are used for each\n",
    "# document type. You can explicitly override both the file and the key.\n",
    "#\n",
    "# Structure:\n",
    "#   'extraction_files': Maps document types to YAML prompt files\n",
    "#   'extraction_keys': (Optional) Maps document types to specific keys in those files\n",
    "#\n",
    "# If 'extraction_keys' is not specified for a document type, the key will be\n",
    "# derived from the document type name (e.g., 'INVOICE' -> 'invoice')\n",
    "#\n",
    "# For bank statements, structure classification (_flat or _date_grouped) is \n",
    "# automatically appended UNLESS you provide a full key in 'extraction_keys'\n",
    "#\n",
    "# NOTE: When USE_SOPHISTICATED_BANK_EXTRACTION is True, bank statements bypass\n",
    "# this configuration and use UnifiedBankExtractor with config/bank_prompts.yaml\n",
    "# ============================================================================\n",
    "\n",
    "PROMPT_CONFIG = {\n",
    "    # Document type detection configuration\n",
    "    'detection_file': 'prompts/document_type_detection.yaml',\n",
    "    'detection_key': 'detection',\n",
    "    \n",
    "    # Extraction prompt file mapping (REQUIRED)\n",
    "    'extraction_files': {\n",
    "        'INVOICE': 'prompts/generated/llama_invoice_prompt.yaml',\n",
    "        'RECEIPT': 'prompts/generated/llama_receipt_prompt.yaml',\n",
    "        'BANK_STATEMENT': 'prompts/generated/llama_bank_statement_prompt.yaml'\n",
    "    },\n",
    "    \n",
    "    # Extraction prompt key mapping (OPTIONAL - for explicit control)\n",
    "    # Uncomment and configure to override automatic key derivation\n",
    "    # 'extraction_keys': {\n",
    "    #     'INVOICE': 'invoice',\n",
    "    #     'RECEIPT': 'receipt',\n",
    "    #     'BANK_STATEMENT': 'bank_statement',  # Will auto-append _flat or _date_grouped\n",
    "    #     # Or specify full key to skip automatic structure suffix:\n",
    "    #     # 'BANK_STATEMENT': 'bank_statement_flat',  # Forces flat table prompt\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Example configurations:\n",
    "# ----------------------\n",
    "# Use old prompts:\n",
    "#   'extraction_files': {\n",
    "#       'INVOICE': 'prompts/llama_prompts.yaml',\n",
    "#       'RECEIPT': 'prompts/llama_prompts.yaml',\n",
    "#       'BANK_STATEMENT': 'prompts/llama_prompts.yaml'\n",
    "#   }\n",
    "#\n",
    "# Mix old and new prompts:\n",
    "#   'extraction_files': {\n",
    "#       'INVOICE': 'prompts/generated/llama_invoice_prompt.yaml',\n",
    "#       'RECEIPT': 'prompts/llama_prompts.yaml',\n",
    "#       'BANK_STATEMENT': 'prompts/generated/llama_bank_statement_prompt.yaml'\n",
    "#   }\n",
    "#\n",
    "# Force specific bank statement structure:\n",
    "#   'extraction_keys': {\n",
    "#       'BANK_STATEMENT': 'bank_statement_flat'  # Ignores vision classification\n",
    "#   }\n",
    "\n",
    "print(\"\u2705 Configuration set up successfully\")\n",
    "print(f\"\ud83d\udcc2 Data directory: {CONFIG['DATA_DIR']}\")\n",
    "print(f\"\ud83d\udcca Ground truth: {CONFIG['GROUND_TRUTH']}\")\n",
    "print(f\"\ud83e\udd16 Model path: {CONFIG['MODEL_PATH']}\")\n",
    "print(f\"\ud83d\udcc1 Output base: {CONFIG['OUTPUT_BASE']}\")\n",
    "print(f\"\ud83c\udfaf Mode: {'Inference-only' if CONFIG['INFERENCE_ONLY'] else 'Evaluation mode'}\")\n",
    "print(f\"\ud83d\udd27 Preprocessing: {'Enabled (' + CONFIG['PREPROCESSING_MODE'] + ')' if CONFIG['ENABLE_PREPROCESSING'] else 'Disabled'}\")\n",
    "print(f\"\ud83c\udfe6 V2 Bank Extraction: {'Enabled (multi-turn)' if CONFIG['USE_SOPHISTICATED_BANK_EXTRACTION'] else 'Disabled (single-turn)'}\")\n",
    "print(f\"\ud83d\udcd0 Balance Correction: {'Enabled' if CONFIG['ENABLE_BALANCE_CORRECTION'] else 'Disabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Output Redirection Utility (Optional)\n",
    "\n",
    "Use the `redirect_output_to_file()` context manager to save verbose output to a file instead of displaying in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Output redirection utility loaded\n",
      "\ud83d\udcdd Use: with redirect_output_to_file('path/to/log.txt'): ...\n"
     ]
    }
   ],
   "source": [
    "#Cell 3.5\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "@contextmanager\n",
    "def redirect_output_to_file(filepath):\n",
    "    \"\"\"\n",
    "    Context manager to redirect stdout to a file.\n",
    "    \n",
    "    Usage:\n",
    "        log_path = OUTPUT_DIRS['base'] / f'batch_log_{BATCH_TIMESTAMP}.txt'\n",
    "        with redirect_output_to_file(log_path):\n",
    "            # Your verbose code here\n",
    "            batch_results, processing_times, document_types_found = processor.process_batch(\n",
    "                all_images, verbose=True\n",
    "            )\n",
    "        # Output is back to notebook\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path where output should be saved\n",
    "        \n",
    "    Yields:\n",
    "        File handle for the log file\n",
    "    \"\"\"\n",
    "    log_file = Path(filepath)\n",
    "    log_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    original_stdout = sys.stdout\n",
    "    original_stderr = sys.stderr\n",
    "    \n",
    "    with open(log_file, 'w') as f:\n",
    "        sys.stdout = f\n",
    "        sys.stderr = f\n",
    "        try:\n",
    "            yield f\n",
    "        finally:\n",
    "            sys.stdout = original_stdout\n",
    "            sys.stderr = original_stderr\n",
    "    \n",
    "    print(f\"\u2705 Output saved to: {log_file}\")\n",
    "\n",
    "print(\"\u2705 Output redirection utility loaded\")\n",
    "print(\"\ud83d\udcdd Use: with redirect_output_to_file('path/to/log.txt'): ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 4\n",
    "# Setup output directories - Handle both absolute and relative paths\n",
    "\n",
    "# Convert OUTPUT_BASE to Path and handle absolute/relative paths\n",
    "OUTPUT_BASE = Path(CONFIG['OUTPUT_BASE'])\n",
    "if not OUTPUT_BASE.is_absolute():\n",
    "    # If relative, make it relative to current working directory\n",
    "    OUTPUT_BASE = Path.cwd() / OUTPUT_BASE\n",
    "\n",
    "BATCH_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "OUTPUT_DIRS = {\n",
    "    'base': OUTPUT_BASE,\n",
    "    'batch': OUTPUT_BASE / 'batch_results',\n",
    "    'csv': OUTPUT_BASE / 'csv',\n",
    "    'visualizations': OUTPUT_BASE / 'visualizations',\n",
    "    'reports': OUTPUT_BASE / 'reports'\n",
    "}\n",
    "\n",
    "for dir_path in OUTPUT_DIRS.values():\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Loading model with robust multi-GPU detection...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mLoading model with robust multi-GPU detection\u001b[0m\u001b[1;32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\ud83d\ude80 Loading Llama Vision model with robust multi-GPU optimization...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m\ud83d\ude80 Loading Llama Vision model with robust multi-GPU optimization\u001b[0m\u001b[1;34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Features: Smart quantization, memory management, V100 support</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFeatures: Smart quantization, memory management, V100 support\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83d\udd27 Configuring CUDA memory for Llama...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83d\udd27 Configuring CUDA memory for Llama\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd27 CUDA memory allocation configured: max_split_size_mb:64\n",
      "\ud83d\udca1 Using 64MB memory blocks to reduce fragmentation\n",
      "\ud83d\udcca Initial CUDA state: Allocated=0.00GB, Reserved=0.00GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83d\udd0d Performing robust GPU memory detection...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83d\udd0d Performing robust GPU memory detection\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd0d Starting robust GPU memory detection...\n",
      "\ud83d\udcca Detected 1 GPU(s), analyzing each device...\n",
      "   GPU 0 (NVIDIA L4): 22.0GB total, 22.0GB available\n",
      "\n",
      "======================================================================\n",
      "\ud83d\udd0d ROBUST GPU MEMORY DETECTION REPORT\n",
      "======================================================================\n",
      "\u2705 Success: 1/1 GPUs detected\n",
      "\ud83d\udcca Total Memory: 21.95GB\n",
      "\ud83d\udcbe Available Memory: 21.95GB\n",
      "\u26a1 Allocated Memory: 0.00GB\n",
      "\ud83d\udd04 Reserved Memory: 0.00GB\n",
      "\ud83d\udce6 Fragmentation: 0.00GB\n",
      "\ud83d\udda5\ufe0f  Multi-GPU: No\n",
      "\u2696\ufe0f  Balanced Distribution: Yes\n",
      "\n",
      "\ud83d\udccb Per-GPU Breakdown:\n",
      "   GPU 0 (NVIDIA L4): 22.0GB total, 22.0GB available (0.0% used)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83d\udcca GPU Hardware: NVIDIA L4 </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">1x 22GB = 22GB total</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83d\udcca GPU Hardware: NVIDIA L4 \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34m1x 22GB = 22GB total\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83c\udfd7\ufe0f Architecture: cloud_inference </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">dynamic detection</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83c\udfd7\ufe0f Architecture: cloud_inference \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mdynamic detection\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83c\udfaf Model: Llama-</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3.2</span><span style=\"color: #000080; text-decoration-color: #000080\">-11B-Vision </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">full precision: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">22.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB, threshold: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">24.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83c\udfaf Model: Llama-\u001b[0m\u001b[1;34m3.2\u001b[0m\u001b[34m-11B-Vision \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mfull precision: \u001b[0m\u001b[1;34m22.\u001b[0m\u001b[34m0GB, threshold: \u001b[0m\u001b[1;34m24.\u001b[0m\u001b[34m0GB\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83d\udcbe Available Memory: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">22.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB across </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">GPU(</span><span style=\"color: #000080; text-decoration-color: #000080\">s</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83d\udcbe Available Memory: \u001b[0m\u001b[1;34m22.\u001b[0m\u001b[34m0GB across \u001b[0m\u001b[1;34m1\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mGPU\u001b[0m\u001b[1;34m(\u001b[0m\u001b[34ms\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83d\udca1 Memory sufficient: \u274c No</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83d\udca1 Memory sufficient: \u274c No\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Cloud inference GPU with 22GB - running in full precision as requested</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Cloud inference GPU with 22GB - running in full precision as requested\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">\ud83d\udcca FINAL QUANTIZATION DECISION: DISABLED (full precision)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m\ud83d\udcca FINAL QUANTIZATION DECISION: DISABLED \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mfull precision\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Total GPU Memory: 22GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Total GPU Memory: 22GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Available Memory: 22GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Available Memory: 22GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Full precision needs: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.</span>0GB + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.</span>0GB buffer = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.</span>0GB threshold\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Full precision needs: \u001b[1;36m22.\u001b[0m0GB + \u001b[1;36m2.\u001b[0m0GB buffer = \u001b[1;36m24.\u001b[0m0GB threshold\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Working GPUs: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Working GPUs: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[36m/\u001b[0m\u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\ud83d\ude80 Using </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">16</span><span style=\"color: #008000; text-decoration-color: #008000\">-bit precision for optimal performance</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\ud83d\ude80 Using \u001b[0m\u001b[1;32m16\u001b[0m\u001b[32m-bit precision for optimal performance\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading Llama Vision model...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading Llama Vision model\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0a8d3bb9444600bd1f04f7e61e7d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading processor...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading processor\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Model and processor loaded successfully!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Model and processor loaded successfully!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83d\udcca Single GPU Analysis:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83d\udcca Single GPU Analysis:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">   Device: cu</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">da:0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m   Device: cu\u001b[0m\u001b[1;34mda:0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">   GPU: NVIDIA L4</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m   GPU: NVIDIA L4\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">   Memory: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">19.</span><span style=\"color: #000080; text-decoration-color: #000080\">79GB allocated, </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">20.</span><span style=\"color: #000080; text-decoration-color: #000080\">09GB reserved, 24GB total</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m   Memory: \u001b[0m\u001b[1;34m19.\u001b[0m\u001b[34m79GB allocated, \u001b[0m\u001b[1;34m20.\u001b[0m\u001b[34m09GB reserved, 24GB total\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                            \ud83d\udd27 Llama Vision Model Configuration                            </span>\n",
       "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503<span style=\"font-weight: bold\"> Setting             </span>\u2503<span style=\"font-weight: bold\"> Value                         </span>\u2503<span style=\"font-weight: bold\"> Llama Status                      </span>\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> Model Path          </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> Llama-3.2-11B-Vision-Instruct </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 Valid                          </span>\u2502\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> Device Placement    </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> cuda:0                        </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 Loaded                         </span>\u2502\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> Quantization Method </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> 16-bit                        </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 16-bit (Performance Optimized) </span>\u2502\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> Data Type           </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> bfloat16                      </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 Recommended                    </span>\u2502\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> Max New Tokens      </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> 3000                          </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 Generation Ready               </span>\u2502\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> GPU Configuration   </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> 1 GPU(s)                      </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 Available                      </span>\u2502\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> Model Parameters    </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> 10,670,220,835                </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 Loaded                         </span>\u2502\n",
       "\u2502<span style=\"color: #008080; text-decoration-color: #008080\"> Memory Optimization </span>\u2502<span style=\"color: #808000; text-decoration-color: #808000\"> Llama Robust                  </span>\u2502<span style=\"color: #008000; text-decoration-color: #008000\"> \u2705 V100 Compatible                </span>\u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                            \ud83d\udd27 Llama Vision Model Configuration                            \u001b[0m\n",
       "\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n",
       "\u2503\u001b[1m \u001b[0m\u001b[1mSetting            \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mValue                        \u001b[0m\u001b[1m \u001b[0m\u2503\u001b[1m \u001b[0m\u001b[1mLlama Status                     \u001b[0m\u001b[1m \u001b[0m\u2503\n",
       "\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mModel Path         \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33mLlama-3.2-11B-Vision-Instruct\u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 Valid                         \u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mDevice Placement   \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33mcuda:0                       \u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 Loaded                        \u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mQuantization Method\u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33m16-bit                       \u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 16-bit (Performance Optimized)\u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mData Type          \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33mbfloat16                     \u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 Recommended                   \u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mMax New Tokens     \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33m3000                         \u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 Generation Ready              \u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mGPU Configuration  \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33m1 GPU(s)                     \u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 Available                     \u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mModel Parameters   \u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33m10,670,220,835               \u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 Loaded                        \u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2502\u001b[36m \u001b[0m\u001b[36mMemory Optimization\u001b[0m\u001b[36m \u001b[0m\u2502\u001b[33m \u001b[0m\u001b[33mLlama Robust                 \u001b[0m\u001b[33m \u001b[0m\u2502\u001b[32m \u001b[0m\u001b[32m\u2705 V100 Compatible               \u001b[0m\u001b[32m \u001b[0m\u2502\n",
       "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Running model compatibility test...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mRunning model compatibility test\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Model compatibility test passed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Model compatibility test passed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Performing initial memory cleanup...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mPerforming initial memory cleanup\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\ud83e\uddf9 Memory cleanup completed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\ud83e\uddf9 Memory cleanup completed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\ud83d\udcbe Final state: <span style=\"color: #808000; text-decoration-color: #808000\">Allocated</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.</span>79GB, <span style=\"color: #808000; text-decoration-color: #808000\">Reserved</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.</span>09GB, <span style=\"color: #808000; text-decoration-color: #808000\">Fragmentation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>30GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\ud83d\udcbe Final state: \u001b[33mAllocated\u001b[0m=\u001b[1;36m19\u001b[0m\u001b[1;36m.\u001b[0m79GB, \u001b[33mReserved\u001b[0m=\u001b[1;36m20\u001b[0m\u001b[1;36m.\u001b[0m09GB, \u001b[33mFragmentation\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0m30GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">\ud83c\udf89 Llama Vision model loading and validation complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m\ud83c\udf89 Llama Vision model loading and validation complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\ud83d\udd27 Llama optimizations active: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">16</span><span style=\"color: #000080; text-decoration-color: #000080\">-bit precision, memory management, vision preservation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\ud83d\udd27 Llama optimizations active: \u001b[0m\u001b[1;34m16\u001b[0m\u001b[34m-bit precision, memory management, vision preservation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">\u2705 Model ready for document-aware processing with robust detection</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m\u2705 Model ready for document-aware processing with robust detection\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 5\n",
    "# Load model once for entire batch\n",
    "rprint(\"[bold green]Loading model with robust multi-GPU detection...[/bold green]\")\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=CONFIG['MODEL_PATH'],\n",
    "    use_quantization=CONFIG['USE_QUANTIZATION'],\n",
    "    device_map=CONFIG['DEVICE_MAP'],\n",
    "    max_new_tokens=CONFIG['MAX_NEW_TOKENS'],\n",
    "    torch_dtype=CONFIG['TORCH_DTYPE'],\n",
    "    low_cpu_mem_usage=CONFIG['LOW_CPU_MEM_USAGE'],\n",
    "    verbose=CONFIG['VERBOSE']\n",
    ")\n",
    "\n",
    "# Model and processor will be used directly by DocumentAwareLlamaProcessor in batch processing\n",
    "rprint(\"[bold green]\u2705 Model ready for document-aware processing with robust detection[/bold green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Image Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udd27 Preprocessing </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008080; text-decoration-color: #008080\"> images </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">mode: adaptive</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\ud83d\udd27 Preprocessing \u001b[0m\u001b[1;36m9\u001b[0m\u001b[36m images \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mmode: adaptive\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udcc1 Using temporary directory: /tmp/preprocessed_erkv0ci8</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\ud83d\udcc1 Using temporary directory: \u001b[0m\u001b[36m/tmp/\u001b[0m\u001b[36mpreprocessed_erkv0ci8\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Preprocessing complete </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> images</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Preprocessing complete \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m9\u001b[0m\u001b[32m images\u001b[0m\u001b[1;32m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Ground truth CSV loaded with 9 rows and 20 columns\n",
      "\ud83d\udccb Available columns: ['image_file', 'DOCUMENT_TYPE', 'BUSINESS_ABN', 'BUSINESS_ADDRESS', 'GST_AMOUNT', 'INVOICE_DATE', 'IS_GST_INCLUDED', 'LINE_ITEM_DESCRIPTIONS', 'LINE_ITEM_QUANTITIES', 'LINE_ITEM_PRICES', 'LINE_ITEM_TOTAL_PRICES', 'PAYER_ADDRESS', 'PAYER_NAME', 'STATEMENT_DATE_RANGE', 'SUPPLIER_NAME', 'TOTAL_AMOUNT', 'TRANSACTION_AMOUNTS_PAID', 'TRANSACTION_DATES', 'TRANSACTION_AMOUNTS_RECEIVED', 'ACCOUNT_BALANCE']\n",
      "\u2705 Using 'image_file' as image identifier column\n",
      "\u2705 Ground truth mapping created for 9 images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Ground truth loaded for </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> images</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Ground truth loaded for \u001b[0m\u001b[1;32m9\u001b[0m\u001b[32m images\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Ready to process </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> images</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mReady to process \u001b[0m\u001b[1;32m9\u001b[0m\u001b[1;32m images\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Data directory: /home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mData directory: \u001b[0m\u001b[36m/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/\u001b[0m\u001b[36msynthetic\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Ground truth: /home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic/ground_truth_synthetic.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mGround truth: \u001b[0m\u001b[36m/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic/\u001b[0m\u001b[36mground_truth_synthetic.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Mode: Evaluation mode</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mMode: Evaluation mode\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. cba_amount_balance.png\n",
      "  2. cba_debit_credit.png\n",
      "  3. cba_highligted.png\n",
      "  4. image_001.png\n",
      "  5. image_002.png\n",
      "  ... and 4 more\n"
     ]
    }
   ],
   "source": [
    "#Cell 6\n",
    "# Discover and filter images - Handle both absolute and relative paths\n",
    "\n",
    "# Convert DATA_DIR to Path and handle absolute/relative paths\n",
    "data_dir = Path(CONFIG['DATA_DIR'])\n",
    "if not data_dir.is_absolute():\n",
    "    # If relative, make it relative to current working directory\n",
    "    data_dir = Path.cwd() / data_dir\n",
    "\n",
    "# Discover images from the resolved data directory\n",
    "all_images = discover_images(str(data_dir))\n",
    "\n",
    "# ============================================================================\n",
    "# IMAGE PREPROCESSING (Optional)\n",
    "# ============================================================================\n",
    "# Apply preprocessing if enabled in CONFIG\n",
    "if CONFIG['ENABLE_PREPROCESSING']:\n",
    "    import tempfile\n",
    "    from common.image_preprocessing import (\n",
    "        enhance_statement_quality,\n",
    "        enhance_for_llama,\n",
    "        preprocess_statement_for_llama,\n",
    "        adaptive_enhance,\n",
    "        preprocess_recommended\n",
    "    )\n",
    "    \n",
    "    # Map preprocessing mode to function\n",
    "    preprocess_functions = {\n",
    "        'light': enhance_statement_quality,\n",
    "        'moderate': enhance_for_llama,\n",
    "        'aggressive': preprocess_statement_for_llama,\n",
    "        'adaptive': adaptive_enhance,\n",
    "        'recommended': preprocess_recommended\n",
    "    }\n",
    "    \n",
    "    preprocess_fn = preprocess_functions[CONFIG['PREPROCESSING_MODE']]\n",
    "    preprocessed_images = []\n",
    "    \n",
    "    rprint(f\"[cyan]\ud83d\udd27 Preprocessing {len(all_images)} images (mode: {CONFIG['PREPROCESSING_MODE']})[/cyan]\")\n",
    "    \n",
    "    # Setup output directory for preprocessed images\n",
    "    if CONFIG['SAVE_PREPROCESSED']:\n",
    "        # Save to persistent directory\n",
    "        preprocessed_dir = Path(CONFIG['PREPROCESSED_DIR'] or 'preprocessed_images')\n",
    "        preprocessed_dir.mkdir(parents=True, exist_ok=True)\n",
    "        rprint(f\"[cyan]\ud83d\udcc1 Saving preprocessed images to: {preprocessed_dir}[/cyan]\")\n",
    "    else:\n",
    "        # Save to temporary directory (preserves original filenames)\n",
    "        preprocessed_dir = Path(tempfile.mkdtemp(prefix='preprocessed_'))\n",
    "        rprint(f\"[cyan]\ud83d\udcc1 Using temporary directory: {preprocessed_dir}[/cyan]\")\n",
    "    \n",
    "    # Preprocess each image\n",
    "    for img_path in all_images:\n",
    "        original_filename = Path(img_path).name\n",
    "        \n",
    "        try:\n",
    "            # Apply preprocessing function\n",
    "            preprocessed_img = preprocess_fn(img_path)\n",
    "            \n",
    "            # Save with original filename (either to persistent or temp directory)\n",
    "            preprocessed_path = preprocessed_dir / original_filename\n",
    "            preprocessed_img.save(preprocessed_path)\n",
    "            preprocessed_images.append(str(preprocessed_path))\n",
    "            \n",
    "        except Exception as e:\n",
    "            rprint(f\"[yellow]\u26a0\ufe0f  Preprocessing failed for {original_filename}: {e}[/yellow]\")\n",
    "            rprint(f\"[yellow]   Using original image instead[/yellow]\")\n",
    "            preprocessed_images.append(img_path)  # Fallback to original\n",
    "    \n",
    "    # Replace original image paths with preprocessed paths\n",
    "    all_images = preprocessed_images\n",
    "    rprint(f\"[green]\u2705 Preprocessing complete ({len(preprocessed_images)} images)[/green]\")\n",
    "else:\n",
    "    rprint(\"[dim]\u23ed\ufe0f  Preprocessing disabled - using original images[/dim]\")\n",
    "\n",
    "# ============================================================================\n",
    "# GROUND TRUTH LOADING\n",
    "# ============================================================================\n",
    "# Conditionally load ground truth only when not in inference-only mode\n",
    "ground_truth = {}\n",
    "if not CONFIG['INFERENCE_ONLY'] and CONFIG['GROUND_TRUTH']:\n",
    "    # Convert GROUND_TRUTH to Path and handle absolute/relative paths\n",
    "    ground_truth_path = Path(CONFIG['GROUND_TRUTH'])\n",
    "    if not ground_truth_path.is_absolute():\n",
    "        # If relative, make it relative to current working directory\n",
    "        ground_truth_path = Path.cwd() / ground_truth_path\n",
    "    \n",
    "    # Load ground truth from the resolved path\n",
    "    ground_truth = load_ground_truth(str(ground_truth_path), verbose=CONFIG['VERBOSE'])\n",
    "    \n",
    "    rprint(f\"[green]\u2705 Ground truth loaded for {len(ground_truth)} images[/green]\")\n",
    "else:\n",
    "    rprint(\"[cyan]\ud83d\udccb Running in inference-only mode (no ground truth required)[/cyan]\")\n",
    "\n",
    "# Apply filters (only if ground truth is available)\n",
    "if CONFIG['DOCUMENT_TYPES'] and ground_truth:\n",
    "    filtered = []\n",
    "    for img in all_images:\n",
    "        img_name = Path(img).name\n",
    "        if img_name in ground_truth:\n",
    "            doc_type = ground_truth[img_name].get('DOCUMENT_TYPE', '').lower()\n",
    "            if any(dt.lower() in doc_type for dt in CONFIG['DOCUMENT_TYPES']):\n",
    "                filtered.append(img)\n",
    "    all_images = filtered\n",
    "\n",
    "if CONFIG['MAX_IMAGES']:\n",
    "    all_images = all_images[:CONFIG['MAX_IMAGES']]\n",
    "\n",
    "rprint(f\"[bold green]Ready to process {len(all_images)} images[/bold green]\")\n",
    "rprint(f\"[cyan]Data directory: {data_dir}[/cyan]\")\n",
    "if not CONFIG['INFERENCE_ONLY'] and CONFIG['GROUND_TRUTH']:\n",
    "    rprint(f\"[cyan]Ground truth: {ground_truth_path}[/cyan]\")\n",
    "rprint(f\"[cyan]Mode: {'Inference-only' if CONFIG['INFERENCE_ONLY'] else 'Evaluation mode'}[/cyan]\")\n",
    "for i, img in enumerate(all_images[:5], 1):\n",
    "    print(f\"  {i}. {Path(img).name}\")\n",
    "if len(all_images) > 5:\n",
    "    print(f\"  ... and {len(all_images) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">\ud83c\udfe6 V2: Setting up sophisticated bank statement extraction...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m\ud83c\udfe6 V2: Setting up sophisticated bank statement extraction\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 V2: Sophisticated bank statement extraction enabled</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 V2: Sophisticated bank statement extraction enabled\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Flow: Detection \u2192 Route \u2192 Extract </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">no duplicate processing for bank</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Flow: Detection \u2192 Route \u2192 Extract \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mno duplicate processing for bank\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Bank statements: Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">detect</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\"> \u2192 Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">headers</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\"> \u2192 Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">extract</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Bank statements: Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mdetect\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m \u2192 Turn \u001b[0m\u001b[1;36m1\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mheaders\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m \u2192 Turn \u001b[0m\u001b[1;36m2\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mextract\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Invoice/Receipt: Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080\">detect</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">)</span><span style=\"color: #008080; text-decoration-color: #008080\"> \u2192 Standard extraction</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Invoice/Receipt: Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mdetect\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m \u2192 Standard extraction\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Balance correction: Enabled</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Balance correction: Enabled\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Ground truth CSV loaded with 9 rows and 20 columns\n",
      "\ud83d\udccb Available columns: ['image_file', 'DOCUMENT_TYPE', 'BUSINESS_ABN', 'BUSINESS_ADDRESS', 'GST_AMOUNT', 'INVOICE_DATE', 'IS_GST_INCLUDED', 'LINE_ITEM_DESCRIPTIONS', 'LINE_ITEM_QUANTITIES', 'LINE_ITEM_PRICES', 'LINE_ITEM_TOTAL_PRICES', 'PAYER_ADDRESS', 'PAYER_NAME', 'STATEMENT_DATE_RANGE', 'SUPPLIER_NAME', 'TOTAL_AMOUNT', 'TRANSACTION_AMOUNTS_PAID', 'TRANSACTION_DATES', 'TRANSACTION_AMOUNTS_RECEIVED', 'ACCOUNT_BALANCE']\n",
      "\u2705 Using 'image_file' as image identifier column\n",
      "\u2705 Ground truth mapping created for 9 images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Loaded ground truth for </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> images</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Loaded ground truth for \u001b[0m\u001b[1;32m9\u001b[0m\u001b[32m images\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Sample GT keys: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">'image_001.png'</span><span style=\"color: #008080; text-decoration-color: #008080\">, </span><span style=\"color: #008080; text-decoration-color: #008080\">'image_002.png'</span><span style=\"color: #008080; text-decoration-color: #008080\">, </span><span style=\"color: #008080; text-decoration-color: #008080\">'image_004.png'</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\ud83d\udccb Sample GT keys: \u001b[0m\u001b[1;36m[\u001b[0m\u001b[36m'image_001.png'\u001b[0m\u001b[36m, \u001b[0m\u001b[36m'image_002.png'\u001b[0m\u001b[36m, \u001b[0m\u001b[36m'image_004.png'\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\ud83d\ude80 Starting Batch Processing</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m\ud83d\ude80 Starting Batch Processing\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Batch Extraction</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u001b[0m\u001b[1;32mBatch Extraction\u001b[0m\u001b[92m \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997adc7737054076aa5928b8a62c07d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: cba_amount_balance.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m1\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: cba_amount_balance.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for cba_amount_balance.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for cba_amount_balance.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing cba_amount_balance.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing cba_amount_balance.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: cba_debit_credit.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m2\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: cba_debit_credit.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for cba_debit_credit.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for cba_debit_credit.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing cba_debit_credit.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing cba_debit_credit.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: cba_highligted.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m3\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: cba_highligted.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for cba_highligted.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for cba_highligted.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing cba_highligted.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing cba_highligted.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">4</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: image_001.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m4\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: image_001.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for image_001.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for image_001.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing image_001.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing image_001.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: image_002.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m5\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: image_002.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for image_002.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for image_002.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing image_002.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing image_002.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">6</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: image_004.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m6\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: image_004.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for image_004.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for image_004.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing image_004.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing image_004.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">7</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: image_005.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m7\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: image_005.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for image_005.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for image_005.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing image_005.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing image_005.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">8</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: image_006.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m8\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: image_006.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for image_006.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for image_006.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing image_006.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing image_006.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Processing [</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">/</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">9</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]: image_007.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mProcessing \u001b[0m\u001b[1;34m[\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m/\u001b[0m\u001b[1;34m9\u001b[0m\u001b[1;34m]\u001b[0m\u001b[1;34m: image_007.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udccb Turn </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #008080; text-decoration-color: #008080\">: Document type detection for image_007.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[36m\ud83d\udccb Turn \u001b[0m\u001b[1;36m0\u001b[0m\u001b[36m: Document type detection for image_007.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error in document type detection: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mError in document type detection: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">\u274c Error processing image_007.png: name </span><span style=\"color: #800000; text-decoration-color: #800000\">'torch'</span><span style=\"color: #800000; text-decoration-color: #800000\"> is not defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u274c Error processing image_007.png: name \u001b[0m\u001b[31m'torch'\u001b[0m\u001b[31m is not defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Batch Processing Complete</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u001b[0m\u001b[1;32mBatch Processing Complete\u001b[0m\u001b[92m \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">\u2705 Processed </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> images</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m\u2705 Processed \u001b[0m\u001b[1;32m9\u001b[0m\u001b[1;32m images\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Average time: nans</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAverage time: nans\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Average accuracy: nan%</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAverage accuracy: nan%\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 7\n",
    "# ============================================================================\n",
    "# V2: BATCH PROCESSING WITH SOPHISTICATED BANK STATEMENT EXTRACTION\n",
    "# ============================================================================\n",
    "# This cell initializes the batch processor and sets up document routing:\n",
    "#\n",
    "# Document Flow:\n",
    "# 1. Document type detection (Turn 0) - classify as INVOICE, RECEIPT, or BANK_STATEMENT\n",
    "# 2. If BANK_STATEMENT:\n",
    "#    - Turn 1: Header detection via BankStatementAdapter\n",
    "#    - Turn 2: Adaptive extraction based on detected columns\n",
    "# 3. If INVOICE/RECEIPT:\n",
    "#    - Standard single-turn extraction\n",
    "#\n",
    "# This ensures NO duplicate extraction - each document is processed once.\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize batch processor with simplified, clean architecture\n",
    "batch_processor = BatchDocumentProcessor(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    prompt_config=PROMPT_CONFIG,\n",
    "    ground_truth_csv=CONFIG['GROUND_TRUTH'],  # None in inference-only mode\n",
    "    console=console,\n",
    "    enable_math_enhancement=CONFIG['ENABLE_MATH_ENHANCEMENT']\n",
    ")\n",
    "\n",
    "# V2: Set up sophisticated bank statement extraction if enabled\n",
    "if CONFIG.get('USE_SOPHISTICATED_BANK_EXTRACTION', False):\n",
    "    rprint(\"[bold cyan]\ud83c\udfe6 V2: Setting up sophisticated bank statement extraction...[/bold cyan]\")\n",
    "    \n",
    "    # Create bank adapter for multi-turn extraction\n",
    "    bank_adapter = BankStatementAdapter(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        verbose=CONFIG['VERBOSE'],\n",
    "        use_balance_correction=CONFIG.get('ENABLE_BALANCE_CORRECTION', False),\n",
    "    )\n",
    "    \n",
    "    # Store original processing method for non-bank documents\n",
    "    original_process_llama = batch_processor._process_llama_image\n",
    "    \n",
    "    # Load detection config once for reuse\n",
    "    from pathlib import Path as _Path\n",
    "    import yaml as _yaml\n",
    "    _detection_path = _Path(PROMPT_CONFIG[\"detection_file\"])\n",
    "    with _detection_path.open(\"r\") as _f:\n",
    "        _detection_config = _yaml.safe_load(_f)\n",
    "    _detection_prompt_key = PROMPT_CONFIG.get(\"detection_key\") or _detection_config.get(\"settings\", {}).get(\"default_prompt\", \"detection\")\n",
    "    _doc_type_prompt = _detection_config[\"prompts\"][_detection_prompt_key][\"prompt\"]\n",
    "    _max_tokens = _detection_config.get(\"settings\", {}).get(\"max_new_tokens\", 50)\n",
    "    \n",
    "    def detect_document_type_only(image_path):\n",
    "        \"\"\"\n",
    "        Detection-only function for Llama - returns just the document type.\n",
    "        Does NOT perform extraction.\n",
    "        \"\"\"\n",
    "        import torch\n",
    "        from PIL import Image\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Create message structure\n",
    "        messageDataStructure = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": _doc_type_prompt},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Process input\n",
    "        textInput = processor.apply_chat_template(messageDataStructure, add_generation_prompt=True)\n",
    "        inputs = processor(image, textInput, return_tensors=\"pt\")\n",
    "        \n",
    "        # Move to model device\n",
    "        inputs = inputs.to(model.device)\n",
    "        \n",
    "        # Generate response\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=_max_tokens,\n",
    "                do_sample=False,\n",
    "                temperature=None,\n",
    "                top_p=None,\n",
    "            )\n",
    "        response = processor.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Parse document type from response\n",
    "        response_text = response.split(\"assistant\")[-1].strip() if \"assistant\" in response else response\n",
    "        response_upper = response_text.upper()\n",
    "        \n",
    "        if \"BANK\" in response_upper or \"STATEMENT\" in response_upper:\n",
    "            return \"BANK_STATEMENT\"\n",
    "        elif \"RECEIPT\" in response_upper:\n",
    "            return \"RECEIPT\"\n",
    "        else:\n",
    "            return \"INVOICE\"\n",
    "    \n",
    "    def enhanced_process_llama(image_path, verbose):\n",
    "        \"\"\"\n",
    "        Enhanced processing with proper routing:\n",
    "        - Turn 0: Document type detection (all documents)\n",
    "        - If BANK_STATEMENT: BankStatementAdapter handles extraction (Turn 1 headers + Turn 2 extraction)\n",
    "        - If INVOICE/RECEIPT: Standard extraction via original_process_llama\n",
    "        \n",
    "        NO duplicate extraction - each document processed exactly once.\n",
    "        \"\"\"\n",
    "        from pathlib import Path\n",
    "        \n",
    "        # =====================================================================\n",
    "        # TURN 0: Document Type Detection ONLY (no extraction yet)\n",
    "        # =====================================================================\n",
    "        if verbose:\n",
    "            rprint(f\"\\n[cyan]\ud83d\udccb Turn 0: Document type detection for {Path(image_path).name}[/cyan]\")\n",
    "        \n",
    "        try:\n",
    "            doc_type = detect_document_type_only(image_path)\n",
    "        except Exception as e:\n",
    "            rprint(f\"[red]Error in document type detection: {e}[/red]\")\n",
    "            raise\n",
    "        \n",
    "        if verbose:\n",
    "            rprint(f\"[green]\u2705 Detected: {doc_type}[/green]\")\n",
    "        \n",
    "        # =====================================================================\n",
    "        # ROUTING: Bank statements vs other documents\n",
    "        # =====================================================================\n",
    "        if doc_type.upper() == \"BANK_STATEMENT\":\n",
    "            # -----------------------------------------------------------------\n",
    "            # BANK STATEMENT: Use BankStatementAdapter (Turn 1 + Turn 2)\n",
    "            # -----------------------------------------------------------------\n",
    "            if verbose:\n",
    "                rprint(f\"[cyan]\ud83c\udfe6 Routing to BankStatementAdapter for multi-turn extraction[/cyan]\")\n",
    "            \n",
    "            try:\n",
    "                # BankStatementAdapter handles:\n",
    "                # - Turn 1: Header detection (identifies column names)\n",
    "                # - Turn 2: Adaptive extraction based on detected columns\n",
    "                schema_fields, metadata = bank_adapter.extract_bank_statement(image_path)\n",
    "                \n",
    "                # Build result structure compatible with BatchDocumentProcessor\n",
    "                extraction_result = {\n",
    "                    \"extracted_data\": schema_fields,\n",
    "                    \"raw_response\": metadata.get(\"raw_responses\", {}).get(\"turn1\", \"\"),\n",
    "                    \"field_list\": list(schema_fields.keys()),\n",
    "                    \"metadata\": metadata,\n",
    "                }\n",
    "                \n",
    "                # Create prompt name indicating strategy used\n",
    "                strategy = metadata.get(\"strategy_used\", \"unknown\")\n",
    "                prompt_name = f\"unified_bank_{strategy}\"\n",
    "                \n",
    "                if verbose:\n",
    "                    rprint(f\"[green]  \u2705 Strategy: {strategy}[/green]\")\n",
    "                    tx_count = len(schema_fields.get('TRANSACTION_DATES', '').split('|')) if schema_fields.get('TRANSACTION_DATES') != 'NOT_FOUND' else 0\n",
    "                    rprint(f\"[green]  \u2705 Transactions extracted: {tx_count}[/green]\")\n",
    "                \n",
    "                return doc_type, extraction_result, prompt_name\n",
    "                \n",
    "            except Exception as e:\n",
    "                rprint(f\"[yellow]\u26a0\ufe0f  BankStatementAdapter failed: {e}[/yellow]\")\n",
    "                rprint(f\"[yellow]   Falling back to standard extraction...[/yellow]\")\n",
    "                # Fall through to standard extraction\n",
    "        \n",
    "        # -----------------------------------------------------------------\n",
    "        # INVOICE/RECEIPT (or bank fallback): Standard extraction\n",
    "        # -----------------------------------------------------------------\n",
    "        if verbose:\n",
    "            rprint(f\"[dim]\ud83d\udcc4 Using standard extraction for {doc_type}[/dim]\")\n",
    "        \n",
    "        # Use original process (will re-detect but that's acceptable for non-bank)\n",
    "        return original_process_llama(image_path, verbose)\n",
    "    \n",
    "    # Replace the processing method\n",
    "    batch_processor._process_llama_image = enhanced_process_llama\n",
    "    \n",
    "    rprint(\"[green]\u2705 V2: Sophisticated bank statement extraction enabled[/green]\")\n",
    "    rprint(\"[cyan]   Flow: Detection \u2192 Route \u2192 Extract (no duplicate processing for bank)[/cyan]\")\n",
    "    rprint(\"[cyan]   Bank statements: Turn 0 (detect) \u2192 Turn 1 (headers) \u2192 Turn 2 (extract)[/cyan]\")\n",
    "    rprint(\"[cyan]   Invoice/Receipt: Turn 0 (detect) \u2192 Standard extraction[/cyan]\")\n",
    "    rprint(f\"[cyan]   Balance correction: {'Enabled' if CONFIG.get('ENABLE_BALANCE_CORRECTION', False) else 'Disabled'}[/cyan]\")\n",
    "else:\n",
    "    rprint(\"[dim]\u23ed\ufe0f  V2: Sophisticated bank extraction disabled - using original single-turn[/dim]\")\n",
    "\n",
    "# Process batch with CONFIG verbose setting for detailed field comparison\n",
    "batch_results, processing_times, document_types_found = batch_processor.process_batch(\n",
    "    all_images, verbose=CONFIG['VERBOSE']\n",
    ")\n",
    "\n",
    "# Brief summary\n",
    "rprint(f\"[bold green]\u2705 Processed {len(batch_results)} images[/bold green]\")\n",
    "rprint(f\"[cyan]Average time: {np.mean(processing_times):.2f}s[/cyan]\")\n",
    "if CONFIG['INFERENCE_ONLY']:\n",
    "    rprint(\"[cyan]\ud83d\udccb Inference-only mode: No accuracy evaluation performed[/cyan]\")\n",
    "else:\n",
    "    avg_accuracy = np.mean([r.get('evaluation', {}).get('overall_accuracy', 0) * 100 for r in batch_results if 'evaluation' in r])\n",
    "    rprint(f\"[cyan]Average accuracy: {avg_accuracy:.1f}%[/cyan]\")\n",
    "    \n",
    "    # V2: Show bank statement specific results if sophisticated extraction was used\n",
    "    if CONFIG.get('USE_SOPHISTICATED_BANK_EXTRACTION', False):\n",
    "        bank_results = [r for r in batch_results if r.get('document_type', '').upper() == 'BANK_STATEMENT']\n",
    "        if bank_results:\n",
    "            bank_accuracy = np.mean([r.get('evaluation', {}).get('overall_accuracy', 0) * 100 for r in bank_results if 'evaluation' in r])\n",
    "            rprint(f\"[cyan]\ud83c\udfe6 Bank statement accuracy (V2): {bank_accuracy:.1f}%[/cyan]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">\u2705 Llama model-specific CSV exported:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m\u2705 Llama model-specific CSV exported:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udcc4 File: /home/jovyan/nfs_share/tod/LMM_POC/output/csv/llama_batch_results_20251209_032729.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\ud83d\udcc4 File: \u001b[0m\u001b[36m/home/jovyan/nfs_share/tod/LMM_POC/output/csv/\u001b[0m\u001b[36mllama_batch_results_20251209_032729.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udcca Structure: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #008080; text-decoration-color: #008080\"> rows \u00d7 </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"color: #008080; text-decoration-color: #008080\"> columns</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\ud83d\udcca Structure: \u001b[0m\u001b[1;36m9\u001b[0m\u001b[36m rows \u00d7 \u001b[0m\u001b[1;36m31\u001b[0m\u001b[36m columns\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\ud83d\udd17 Compatible with model_comparison.ipynb pattern: *llama*batch*results*.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\ud83d\udd17 Compatible with model_comparison.ipynb pattern: *llama*batch*results*.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\ud83d\udccb Sample exported data (first </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> rows, key columns):</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m\ud83d\udccb Sample exported data \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mfirst \u001b[0m\u001b[1;34m3\u001b[0m\u001b[1;34m rows, key columns\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>document_type</th>\n",
       "      <th>overall_accuracy</th>\n",
       "      <th>processing_time</th>\n",
       "      <th>found_fields</th>\n",
       "      <th>field_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cba_amount_balance.png</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cba_debit_credit.png</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cba_highligted.png</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_file document_type  overall_accuracy  processing_time  \\\n",
       "0  cba_amount_balance.png                               0                0   \n",
       "1    cba_debit_credit.png                               0                0   \n",
       "2      cba_highligted.png                               0                0   \n",
       "\n",
       "   found_fields  field_coverage  \n",
       "0             0             0.0  \n",
       "1             0             0.0  \n",
       "2             0             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\ud83d\udd0d Accuracy verification:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m\ud83d\udd0d Accuracy verification:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  cba_amount_balance.png: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span> \u2192 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  cba_amount_balance.png: \u001b[1;36m0.0000\u001b[0m \u2192 \u001b[1;36m0.00\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  cba_debit_credit.png: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span> \u2192 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  cba_debit_credit.png: \u001b[1;36m0.0000\u001b[0m \u2192 \u001b[1;36m0.00\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  cba_highligted.png: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0000</span> \u2192 <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  cba_highligted.png: \u001b[1;36m0.0000\u001b[0m \u2192 \u001b[1;36m0.00\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\ud83d\udd0d Data structure verification:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m\ud83d\udd0d Data structure verification:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  cba_amount_balance.png: Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> fields in extracted_data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  cba_amount_balance.png: Found \u001b[1;36m0\u001b[0m fields in extracted_data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  cba_debit_credit.png: Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> fields in extracted_data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  cba_debit_credit.png: Found \u001b[1;36m0\u001b[0m fields in extracted_data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 DataFrames saved to /home/jovyan/nfs_share/tod/LMM_POC/output/csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 DataFrames saved to \u001b[0m\u001b[32m/home/jovyan/nfs_share/tod/LMM_POC/output/\u001b[0m\u001b[32mcsv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\ud83d\udcca Results Summary</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34m\ud83d\udcca Results Summary\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Images</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Successful Extractions</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failed Extractions</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Processing Time (s)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Processing Time (s)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Throughput (images/min)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "Total Images                     9\n",
       "Successful Extractions           0\n",
       "Failed Extractions               9\n",
       "Average Processing Time (s)      0\n",
       "Total Processing Time (s)        0\n",
       "Throughput (images/min)          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 8\n",
    "# Create model-specific CSV file to match InternVL3 structure\n",
    "# Define field columns (excluding validation-only fields for consistency with InternVL3)\n",
    "# Use filtered field list (excludes validation-only fields: TRANSACTION_AMOUNTS_RECEIVED, ACCOUNT_BALANCE)\n",
    "from common.config import get_v4_field_list, filter_evaluation_fields\n",
    "FIELD_COLUMNS = filter_evaluation_fields(get_v4_field_list())\n",
    "\n",
    "# Create comprehensive results data matching InternVL3 structure\n",
    "llama_csv_data = []\n",
    "\n",
    "for i, result in enumerate(batch_results):\n",
    "    # Basic metadata\n",
    "    image_name = Path(result['image_path']).name\n",
    "    doc_type = result.get('document_type', '').lower()\n",
    "    processing_time = processing_times[i] if i < len(processing_times) else 0\n",
    "    \n",
    "    # Extract fields from result\n",
    "    extraction_result = result.get('extraction_result', {})\n",
    "    extracted_fields = extraction_result.get('extracted_data', {})\n",
    "    accuracy_data = result.get('evaluation', {})\n",
    "    \n",
    "    # Count fields\n",
    "    total_fields = len(FIELD_COLUMNS)\n",
    "    found_fields = sum(1 for field in FIELD_COLUMNS if extracted_fields.get(field, 'NOT_FOUND') != 'NOT_FOUND')\n",
    "    field_coverage = (found_fields / total_fields * 100) if total_fields > 0 else 0\n",
    "    \n",
    "    # Handle both inference-only and evaluation modes\n",
    "    if CONFIG['INFERENCE_ONLY'] or accuracy_data.get('inference_only', False):\n",
    "        # Inference-only mode\n",
    "        overall_accuracy = None\n",
    "        fields_extracted = found_fields\n",
    "        fields_matched = 0  # No matching in inference mode\n",
    "        eval_total_fields = total_fields\n",
    "    else:\n",
    "        # Evaluation mode\n",
    "        overall_accuracy = accuracy_data.get('overall_accuracy', 0) * 100 if accuracy_data else 0\n",
    "        fields_extracted = accuracy_data.get('fields_extracted', 0) if accuracy_data else 0\n",
    "        fields_matched = accuracy_data.get('fields_matched', 0) if accuracy_data else 0\n",
    "        eval_total_fields = accuracy_data.get('total_fields', total_fields) if accuracy_data else total_fields\n",
    "    \n",
    "    # Create prompt identifier\n",
    "    prompt_used = f\"llama_{doc_type}\" if doc_type else \"llama_unknown\"\n",
    "    \n",
    "    # Create row data\n",
    "    row_data = {\n",
    "        'image_file': image_name,\n",
    "        'image_name': image_name,\n",
    "        'document_type': doc_type,\n",
    "        'processing_time': processing_time,\n",
    "        'field_count': eval_total_fields,\n",
    "        'found_fields': fields_extracted,\n",
    "        'field_coverage': field_coverage,\n",
    "        'prompt_used': prompt_used,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'fields_extracted': fields_extracted,\n",
    "        'fields_matched': fields_matched,\n",
    "        'total_fields': eval_total_fields,\n",
    "        'inference_only': CONFIG['INFERENCE_ONLY']\n",
    "    }\n",
    "    \n",
    "    # Add all field values\n",
    "    for field in FIELD_COLUMNS:\n",
    "        row_data[field] = extracted_fields.get(field, 'NOT_FOUND')\n",
    "    \n",
    "    llama_csv_data.append(row_data)\n",
    "\n",
    "# Create DataFrame and save\n",
    "llama_df = pd.DataFrame(llama_csv_data)\n",
    "llama_csv_path = OUTPUT_DIRS['csv'] / f\"llama_batch_results_{BATCH_TIMESTAMP}.csv\"\n",
    "llama_df.to_csv(llama_csv_path, index=False)\n",
    "\n",
    "rprint(\"[bold green]\u2705 Llama model-specific CSV exported:[/bold green]\")\n",
    "rprint(f\"[cyan]\ud83d\udcc4 File: {llama_csv_path}[/cyan]\")\n",
    "rprint(f\"[cyan]\ud83d\udcca Structure: {len(llama_df)} rows \u00d7 {len(llama_df.columns)} columns[/cyan]\")\n",
    "rprint(\"[cyan]\ud83d\udd17 Compatible with model_comparison.ipynb pattern: *llama*batch*results*.csv[/cyan]\")\n",
    "\n",
    "# Display sample of the exported data (conditional based on mode)\n",
    "if CONFIG['INFERENCE_ONLY']:\n",
    "    rprint(\"\\n[bold blue]\ud83d\udccb Sample exported data (inference-only mode):[/bold blue]\")\n",
    "    sample_cols = ['image_file', 'document_type', 'processing_time', 'found_fields', 'field_coverage', 'inference_only']\n",
    "    if len(llama_df) > 0:\n",
    "        display(llama_df[sample_cols].head(3))\n",
    "    else:\n",
    "        rprint(\"[yellow]\u26a0\ufe0f No data to display[/yellow]\")\n",
    "else:\n",
    "    rprint(\"\\n[bold blue]\ud83d\udccb Sample exported data (first 3 rows, key columns):[/bold blue]\")\n",
    "    sample_cols = ['image_file', 'document_type', 'overall_accuracy', 'processing_time', 'found_fields', 'field_coverage']\n",
    "    if len(llama_df) > 0:\n",
    "        display(llama_df[sample_cols].head(3))\n",
    "    else:\n",
    "        rprint(\"[yellow]\u26a0\ufe0f No data to display[/yellow]\")\n",
    "\n",
    "    # Verification: Show accuracy values to confirm they're correct (evaluation mode only)\n",
    "    rprint(\"\\n[bold blue]\ud83d\udd0d Accuracy verification:[/bold blue]\")\n",
    "    for i, result in enumerate(batch_results[:3]):  # Show first 3\n",
    "        evaluation = result.get('evaluation', {})\n",
    "        original_accuracy = evaluation.get('overall_accuracy', 0)\n",
    "        percentage_accuracy = original_accuracy * 100\n",
    "        rprint(f\"  {result['image_name']}: {original_accuracy:.4f} \u2192 {percentage_accuracy:.2f}%\")\n",
    "\n",
    "# Debug: Show extraction structure to verify extraction works\n",
    "rprint(\"\\n[bold blue]\ud83d\udd0d Data structure verification:[/bold blue]\")\n",
    "for i, result in enumerate(batch_results[:2]):  # Show first 2\n",
    "    image_name = result['image_name']\n",
    "    extraction_result = result.get('extraction_result', {})\n",
    "    extracted_data = extraction_result.get('extracted_data', {})\n",
    "    found_count = sum(1 for v in extracted_data.values() if v != 'NOT_FOUND')\n",
    "    rprint(f\"  {image_name}: Found {found_count} fields in extracted_data\")\n",
    "    if found_count > 0:\n",
    "        # Show first few found fields\n",
    "        found_fields = [(k, v) for k, v in extracted_data.items() if v != 'NOT_FOUND'][:3]\n",
    "        for field, value in found_fields:\n",
    "            rprint(f\"    {field}: {value}\")\n",
    "\n",
    "# Create analytics\n",
    "analytics = BatchAnalytics(batch_results, processing_times)\n",
    "\n",
    "# Generate and save DataFrames\n",
    "saved_files, df_results, df_summary, df_doctype_stats, df_field_stats = analytics.save_all_dataframes(\n",
    "    OUTPUT_DIRS['csv'], BATCH_TIMESTAMP, verbose=CONFIG['VERBOSE']\n",
    ")\n",
    "\n",
    "# Display key results based on mode\n",
    "rprint(\"\\n[bold blue]\ud83d\udcca Results Summary[/bold blue]\")\n",
    "if CONFIG['INFERENCE_ONLY']:\n",
    "    rprint(\"[cyan]\ud83d\udccb Running in inference-only mode - no accuracy metrics available[/cyan]\")\n",
    "    # Show extraction statistics instead\n",
    "    rprint(f\"[cyan]\u2705 Total images processed: {len(batch_results)}[/cyan]\")\n",
    "    rprint(f\"[cyan]\u2705 Average fields found: {llama_df['found_fields'].mean():.1f}[/cyan]\")\n",
    "    rprint(f\"[cyan]\u2705 Average field coverage: {llama_df['field_coverage'].mean():.1f}%[/cyan]\")\n",
    "else:\n",
    "    display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">\u26a0\ufe0f No data available for dashboard</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m\u26a0\ufe0f No data available for dashboard\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">\u26a0\ufe0f No data available for heatmap</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m\u26a0\ufe0f No data available for heatmap\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 9\n",
    "# Create visualizations\n",
    "visualizer = BatchVisualizer()\n",
    "\n",
    "viz_files = visualizer.create_all_visualizations(\n",
    "    df_results, \n",
    "    df_doctype_stats,\n",
    "    OUTPUT_DIRS['visualizations'],\n",
    "    BATCH_TIMESTAMP,\n",
    "    show=False  # Disable display to reduce output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Generate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Executive summary saved to /home/jovyan/nfs_share/tod/LMM_POC/output/reports/batch_report_20251209_032729.md</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Executive summary saved to \u001b[0m\u001b[32m/home/jovyan/nfs_share/tod/LMM_POC/output/reports/\u001b[0m\u001b[32mbatch_report_20251209_032729.md\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u2705 Complete results exported to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">/home/jovyan/nfs_share/tod/LMM_POC/output/batch_results/batch_results_20251209_032729.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u2705 Complete results exported to \u001b[0m\n",
       "\u001b[32m/home/jovyan/nfs_share/tod/LMM_POC/output/batch_results/\u001b[0m\u001b[32mbatch_results_20251209_032729.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 10\n",
    "# Generate reports\n",
    "reporter = BatchReporter(\n",
    "    batch_results, \n",
    "    processing_times,\n",
    "    document_types_found,\n",
    "    BATCH_TIMESTAMP\n",
    ")\n",
    "\n",
    "# Save all reports using CONFIG verbose setting\n",
    "report_files = reporter.save_all_reports(\n",
    "    OUTPUT_DIRS,\n",
    "    df_results,\n",
    "    df_summary,\n",
    "    df_doctype_stats,\n",
    "    CONFIG['MODEL_PATH'],\n",
    "    {\n",
    "        'data_dir': CONFIG['DATA_DIR'],\n",
    "        'ground_truth': CONFIG['GROUND_TRUTH'],\n",
    "        'max_images': CONFIG['MAX_IMAGES'],\n",
    "        'document_types': CONFIG['DOCUMENT_TYPES']\n",
    "    },\n",
    "    {\n",
    "        'use_quantization': CONFIG['USE_QUANTIZATION'],\n",
    "        'device_map': CONFIG['DEVICE_MAP'],\n",
    "        'max_new_tokens': CONFIG['MAX_NEW_TOKENS'],\n",
    "        'torch_dtype': CONFIG['TORCH_DTYPE'],\n",
    "        'low_cpu_mem_usage': CONFIG['LOW_CPU_MEM_USAGE']\n",
    "    },\n",
    "    verbose=CONFIG['VERBOSE']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Display Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Batch Processing Complete</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u001b[0m\u001b[1;32mBatch Processing Complete\u001b[0m\u001b[92m \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">\u2705 Processed: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> images</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m\u2705 Processed: \u001b[0m\u001b[1;32m9\u001b[0m\u001b[1;32m images\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Success Rate: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"color: #008080; text-decoration-color: #008080\">%</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mSuccess Rate: \u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[36m%\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Average Accuracy: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"color: #008080; text-decoration-color: #008080\">%</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mAverage Accuracy: \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[36m%\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Output: /home/jovyan/nfs_share/tod/LMM_POC/output</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mOutput: \u001b[0m\u001b[36m/home/jovyan/nfs_share/tod/LMM_POC/\u001b[0m\u001b[36moutput\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">\u26a0\ufe0f Dashboard not found in /home/jovyan/nfs_share/tod/LMM_POC/output/visualizations</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[33m\u26a0\ufe0f Dashboard not found in \u001b[0m\u001b[33m/home/jovyan/nfs_share/tod/LMM_POC/output/\u001b[0m\u001b[33mvisualizations\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 11\n",
    "# Display final summary\n",
    "console.rule(\"[bold green]Batch Processing Complete[/bold green]\")\n",
    "\n",
    "total_images = len(batch_results)\n",
    "successful = len([r for r in batch_results if 'error' not in r])\n",
    "avg_accuracy = df_results['overall_accuracy'].mean() if len(df_results) > 0 else 0\n",
    "\n",
    "rprint(f\"[bold green]\u2705 Processed: {total_images} images[/bold green]\")\n",
    "rprint(f\"[cyan]Success Rate: {(successful/total_images*100):.1f}%[/cyan]\")\n",
    "rprint(f\"[cyan]Average Accuracy: {avg_accuracy:.2f}%[/cyan]\")\n",
    "rprint(f\"[cyan]Output: {OUTPUT_BASE}[/cyan]\")\n",
    "\n",
    "# Display dashboard if available\n",
    "dashboard_files = list(OUTPUT_DIRS['visualizations'].glob(f\"dashboard_{BATCH_TIMESTAMP}.png\"))\n",
    "if dashboard_files:\n",
    "    dashboard_path = dashboard_files[0]\n",
    "    rprint(\"\\n[bold blue]\ud83d\udcca Visual Dashboard:[/bold blue]\")\n",
    "    display(Image(str(dashboard_path)))\n",
    "else:\n",
    "    rprint(f\"\\n[yellow]\u26a0\ufe0f Dashboard not found in {OUTPUT_DIRS['visualizations']}[/yellow]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">\u26a0\ufe0f Running in inference-only mode - no accuracy metrics available</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m\u26a0\ufe0f Running in inference-only mode - no accuracy metrics available\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cell 12\n",
    "# Calculate zero accuracy extractions\n",
    "zero_accuracy_count = 0\n",
    "zero_accuracy_images = []\n",
    "total_evaluated = 0\n",
    "\n",
    "for result in batch_results:\n",
    "    # Check if evaluation data exists (not inference-only mode)\n",
    "    evaluation = result.get(\"evaluation\", {})\n",
    "\n",
    "    if evaluation and not evaluation.get(\"inference_only\", False):\n",
    "        total_evaluated += 1\n",
    "        accuracy = evaluation.get(\"overall_accuracy\", 0)\n",
    "\n",
    "        if accuracy == 0.0:\n",
    "            zero_accuracy_count += 1\n",
    "            zero_accuracy_images.append(\n",
    "                {\n",
    "                    \"image_name\": result.get(\"image_name\", \"unknown\"),\n",
    "                    \"document_type\": result.get(\"document_type\", \"unknown\"),\n",
    "                    \"fields_extracted\": evaluation.get(\"fields_extracted\", 0),\n",
    "                    \"total_fields\": evaluation.get(\"total_fields\", 0),\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Display results\n",
    "if total_evaluated > 0:\n",
    "    console.rule(\"[bold red]Zero Accuracy Analysis[/bold red]\")\n",
    "\n",
    "    rprint(f\"[cyan]Total documents evaluated: {total_evaluated}[/cyan]\")\n",
    "    rprint(f\"[red]Documents with 0% accuracy: {zero_accuracy_count}[/red]\")\n",
    "\n",
    "    if zero_accuracy_count > 0:\n",
    "        percentage = (zero_accuracy_count / total_evaluated) * 100\n",
    "        rprint(f\"[red]Zero accuracy rate: {percentage:.1f}%[/red]\")\n",
    "\n",
    "        rprint(\"\\n[bold red]Documents with 0% Accuracy:[/bold red]\")\n",
    "        for i, img_info in enumerate(zero_accuracy_images, 1):\n",
    "            rprint(f\"  {i}. {img_info['image_name']} ({img_info['document_type']})\")\n",
    "            rprint(\n",
    "                f\"     Fields extracted: {img_info['fields_extracted']}/{img_info['total_fields']}\"\n",
    "            )\n",
    "    else:\n",
    "        rprint(\n",
    "            \"[green]\u2705 No documents with 0% accuracy - all extractions had some success![/green]\"\n",
    "        )\n",
    "else:\n",
    "    rprint(\n",
    "        \"[yellow]\u26a0\ufe0f Running in inference-only mode - no accuracy metrics available[/yellow]\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LMM_POC)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}