{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InternVL3-8B: Independent Single-Turn Bank Statement Extraction\n",
    "\n",
    "**Protocol**: Two independent single-turn prompts + Python parsing/filtering\n",
    "\n",
    "**Key Insight**: Multi-turn conversation degrades accuracy. LLM filtering mixes up rows. Use Python for filtering!\n",
    "\n",
    "**Model**: InternVL3-8B with bfloat16 and multi-GPU split_model() for compatibility\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Turn 0: Image + Prompt \u2192 Headers (fresh context)\n",
    "        \u2193 (Python pattern matching)\n",
    "Turn 1: Image + Prompt \u2192 Full Table (fresh context, dynamic markdown example)\n",
    "        \u2193 (Python parsing + filtering)\n",
    "Schema Fields: TRANSACTION_DATES, LINE_ITEM_DESCRIPTIONS, TRANSACTION_AMOUNTS_PAID\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to concepts (Date, Description, Debit, Credit)\n",
    "3. **Turn 1 (LLM)**: Extract full markdown table using **dynamic example** matching detected column structure\n",
    "4. **Python Parsing**: Parse markdown \u2192 Filter for debits \u2192 Extract schema fields\n",
    "\n",
    "### Critical Features:\n",
    "- \u274c **No Turn 2** - LLM filtering mixes up rows!\n",
    "- \u2705 **Python filtering** - Reliable debit/credit separation\n",
    "- \u2705 **Dynamic examples** - Adapt to 3/4/5 column formats\n",
    "- \u2705 **Markdown teaching** - InternVL3 understands markdown format for alignment\n",
    "- \u2705 **Tax accuracy** - Correct Debit/Credit separation critical for identifying purchases\n",
    "\n",
    "### Why This Works:\n",
    "- **Turn 0**: Clean context \u2192 accurate header identification\n",
    "- **Turn 1**: Clean context + dynamic example \u2192 accurate table extraction\n",
    "- **Python**: Reliable filtering for debit transactions (what taxpayer PAID)\n",
    "\n",
    "### Model: InternVL3-8B\n",
    "- **bfloat16 precision** with official multi-GPU split_model() pattern\n",
    "- Higher capacity than 2B variant\n",
    "- Strong vision-language capabilities\n",
    "- Simple API with `model.chat()` method\n",
    "- Multi-GPU: First and last LLM layers anchored to GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "# Add parent directory to path AND change working directory for config file resolution\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get project root (parent of bank_statement/)\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Change working directory to project root so config/field_definitions.yaml is found\n",
    "os.chdir(project_root)\n",
    "print(f\"\ud83d\udcc1 Working directory: {os.getcwd()}\")\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, BitsAndBytesConfig\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# IPython display for rendering markdown\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "CONFIG = {\n",
    "    # Model path - update for your environment\n",
    "    \"MODEL_PATH\": \"/home/jovyan/nfs_share/models/InternVL3-8B\",\n",
    "    \n",
    "    # Generation settings\n",
    "    \"MAX_NEW_TOKENS\": 4096,\n",
    "    \n",
    "    # Image processing - V100 optimized\n",
    "    \"MAX_TILES\": 14,  # V100 optimized (use 18 for A10G, 36 for H200)\n",
    "}\n",
    "\n",
    "print(f\"\u2705 Configuration loaded:\")\n",
    "print(f\"   Model: {CONFIG['MODEL_PATH']}\")\n",
    "print(f\"   Max tiles: {CONFIG['MAX_TILES']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Set random seed\n",
    "\n",
    "from common.reproducibility import set_seed, configure_deterministic_mode\n",
    "set_seed(42)\n",
    "configure_deterministic_mode(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd27 Loading InternVL3-8B with memory-aware strategy...\n",
      "\ud83d\udda5\ufe0f  Detected 2 GPU(s)\n",
      "\ud83d\udcbe GPU 0 free memory: 47.8 GB\n",
      "\ud83d\udcbe GPU 1 free memory: 47.8 GB\n",
      "\ud83d\udcbe Total free memory: 95.6 GB\n",
      "\u2705 Sufficient memory for bfloat16 multi-GPU mode\n",
      "\ud83d\udce5 Loading model with official multi-GPU split_model() pattern...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CONFIG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\u2705 Sufficient memory for bfloat16 multi-GPU mode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\ud83d\udce5 Loading model with official multi-GPU split_model() pattern...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m device_map = split_model(\u001b[43mCONFIG\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mMODEL_PATH\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\ud83d\udd04 Custom device map created with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(device_map)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m entries\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m model = AutoModel.from_pretrained(\n\u001b[32m     82\u001b[39m     CONFIG[\u001b[33m'\u001b[39m\u001b[33mMODEL_PATH\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     83\u001b[39m     torch_dtype=torch.bfloat16,\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m     device_map=device_map\n\u001b[32m     88\u001b[39m ).eval()\n",
      "\u001b[31mNameError\u001b[39m: name 'CONFIG' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load InternVL3-8B model with memory-aware loading strategy\n",
    "# Supports: Multi-GPU bfloat16 OR Single-GPU 8-bit quantization\n",
    "\n",
    "from transformers import AutoConfig, BitsAndBytesConfig\n",
    "\n",
    "print(\"\ud83d\udd27 Loading InternVL3-8B with memory-aware strategy...\")\n",
    "\n",
    "def split_model(model_path):\n",
    "    \"\"\"\n",
    "    Official InternVL3 multi-GPU device mapping function.\n",
    "    \n",
    "    Creates a custom device map that ensures the first and last layers of the\n",
    "    language model stay on the same device (GPU 0) to prevent tensor placement\n",
    "    mismatches during generation.\n",
    "    \n",
    "    From: https://internvl.readthedocs.io/en/latest/internvl3.0/quick_start.html\n",
    "    \"\"\"\n",
    "    device_map = {}\n",
    "    world_size = torch.cuda.device_count()\n",
    "    config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "    num_layers = config.llm_config.num_hidden_layers\n",
    "    \n",
    "    # Since the first GPU will be used for ViT, treat it as half a GPU\n",
    "    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n",
    "    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n",
    "    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n",
    "    \n",
    "    layer_cnt = 0\n",
    "    for i, num_layer in enumerate(num_layers_per_gpu):\n",
    "        for _j in range(num_layer):\n",
    "            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n",
    "            layer_cnt += 1\n",
    "    \n",
    "    # Critical components must stay on GPU 0\n",
    "    device_map['vision_model'] = 0\n",
    "    device_map['mlp1'] = 0\n",
    "    device_map['language_model.model.tok_embeddings'] = 0\n",
    "    device_map['language_model.model.embed_tokens'] = 0\n",
    "    device_map['language_model.output'] = 0\n",
    "    device_map['language_model.model.norm'] = 0\n",
    "    device_map['language_model.model.rotary_emb'] = 0\n",
    "    device_map['language_model.lm_head'] = 0\n",
    "    \n",
    "    # CRITICAL: Force last layer back to GPU 0 to prevent device mismatch\n",
    "    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n",
    "    \n",
    "    return device_map\n",
    "\n",
    "def get_gpu_free_memory(gpu_id=0):\n",
    "    \"\"\"Get free GPU memory in GB.\"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return 0\n",
    "    free_mem = torch.cuda.get_device_properties(gpu_id).total_memory - torch.cuda.memory_allocated(gpu_id)\n",
    "    return free_mem / 1e9\n",
    "\n",
    "# Check available GPU memory\n",
    "world_size = torch.cuda.device_count()\n",
    "print(f\"\ud83d\udda5\ufe0f  Detected {world_size} GPU(s)\")\n",
    "\n",
    "gpu0_free = get_gpu_free_memory(0)\n",
    "gpu1_free = get_gpu_free_memory(1) if world_size > 1 else 0\n",
    "total_free = gpu0_free + gpu1_free\n",
    "\n",
    "print(f\"\ud83d\udcbe GPU 0 free memory: {gpu0_free:.1f} GB\")\n",
    "if world_size > 1:\n",
    "    print(f\"\ud83d\udcbe GPU 1 free memory: {gpu1_free:.1f} GB\")\n",
    "print(f\"\ud83d\udcbe Total free memory: {total_free:.1f} GB\")\n",
    "\n",
    "# Decision: Use bfloat16 multi-GPU if enough memory, otherwise 8-bit quantization\n",
    "# InternVL3-8B needs ~16GB in bfloat16, ~8GB in 8-bit\n",
    "BFLOAT16_REQUIRED = 16.0\n",
    "QUANTIZED_REQUIRED = 10.0\n",
    "\n",
    "if total_free >= BFLOAT16_REQUIRED and world_size > 1:\n",
    "    # Multi-GPU bfloat16 mode\n",
    "    print(f\"\u2705 Sufficient memory for bfloat16 multi-GPU mode\")\n",
    "    print(\"\ud83d\udce5 Loading model with official multi-GPU split_model() pattern...\")\n",
    "    device_map = split_model(CONFIG['MODEL_PATH'])\n",
    "    print(f\"\ud83d\udd04 Custom device map created with {len(device_map)} entries\")\n",
    "    \n",
    "    model = AutoModel.from_pretrained(\n",
    "        CONFIG['MODEL_PATH'],\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_flash_attn=False,  # V100 compatible\n",
    "        trust_remote_code=True,\n",
    "        device_map=device_map\n",
    "    ).eval()\n",
    "    \n",
    "    MODEL_DTYPE = torch.bfloat16\n",
    "    print(\"\u2705 Loaded in bfloat16 with multi-GPU split\")\n",
    "\n",
    "elif total_free >= QUANTIZED_REQUIRED:\n",
    "    # Single-GPU 8-bit quantization mode (lower memory)\n",
    "    print(f\"\u26a0\ufe0f  Limited memory - using 8-bit quantization on single GPU\")\n",
    "    \n",
    "    # Find GPU with most free memory\n",
    "    if world_size > 1 and gpu1_free > gpu0_free:\n",
    "        target_gpu = 1\n",
    "        print(f\"\ud83d\udce5 Loading on GPU 1 (more free memory: {gpu1_free:.1f} GB)\")\n",
    "    else:\n",
    "        target_gpu = 0\n",
    "        print(f\"\ud83d\udce5 Loading on GPU 0 ({gpu0_free:.1f} GB free)\")\n",
    "    \n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        llm_int8_enable_fp32_cpu_offload=False  # Keep on GPU\n",
    "    )\n",
    "    \n",
    "    model = AutoModel.from_pretrained(\n",
    "        CONFIG['MODEL_PATH'],\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_flash_attn=False,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map={\"\": target_gpu}\n",
    "    ).eval()\n",
    "    \n",
    "    MODEL_DTYPE = torch.float16\n",
    "    print(f\"\u2705 Loaded in 8-bit quantization on GPU {target_gpu}\")\n",
    "\n",
    "else:\n",
    "    # Not enough memory - fail with helpful message\n",
    "    raise RuntimeError(\n",
    "        f\"\u274c Insufficient GPU memory!\\n\"\n",
    "        f\"   Available: {total_free:.1f} GB\\n\"\n",
    "        f\"   Required: {QUANTIZED_REQUIRED:.1f} GB (8-bit) or {BFLOAT16_REQUIRED:.1f} GB (bfloat16)\\n\"\n",
    "        f\"   Please free GPU memory by stopping other processes.\"\n",
    "    )\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CONFIG['MODEL_PATH'],\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False\n",
    ")\n",
    "\n",
    "# Set generation config on model\n",
    "model.config.max_new_tokens = CONFIG['MAX_NEW_TOKENS']\n",
    "\n",
    "# Fix pad_token_id to suppress warnings\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Display model information\n",
    "print(\"\u2705 Model and tokenizer loaded successfully!\")\n",
    "\n",
    "# GPU memory check\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    \n",
    "    if device_count > 1 and hasattr(model, 'hf_device_map'):\n",
    "        # Multi-GPU detailed breakdown\n",
    "        print(f\"\ud83d\udd04 Multi-GPU Distribution Analysis ({device_count} GPUs):\")\n",
    "        \n",
    "        total_allocated = 0\n",
    "        for gpu_id in range(device_count):\n",
    "            gpu_allocated = torch.cuda.memory_allocated(gpu_id) / 1e9\n",
    "            gpu_capacity = torch.cuda.get_device_properties(gpu_id).total_memory / 1e9\n",
    "            gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "            \n",
    "            total_allocated += gpu_allocated\n",
    "            usage_pct = (gpu_allocated / gpu_capacity) * 100 if gpu_capacity > 0 else 0\n",
    "            print(f\"   GPU {gpu_id} ({gpu_name}): {gpu_allocated:.1f}GB/{gpu_capacity:.0f}GB ({usage_pct:.1f}%)\")\n",
    "        \n",
    "        from collections import Counter\n",
    "        device_distribution = Counter(model.hf_device_map.values())\n",
    "        print(f\"\u2705 Model distributed: {dict(device_distribution)}\")\n",
    "    else:\n",
    "        # Single GPU\n",
    "        device = next(model.parameters()).device\n",
    "        gpu_id = device.index if device.index is not None else 0\n",
    "        allocated = torch.cuda.memory_allocated(gpu_id) / 1e9\n",
    "        total = torch.cuda.get_device_properties(gpu_id).total_memory / 1e9\n",
    "        gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "        usage_pct = (allocated / total) * 100 if total > 0 else 0\n",
    "        print(f\"\ud83d\udcca GPU {gpu_id} ({gpu_name}): {allocated:.1f}GB/{total:.0f}GB ({usage_pct:.1f}%)\")\n",
    "\n",
    "# Model parameters\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\ud83d\udd22 Model parameters: {param_count:,}\")\n",
    "print(f\"\ud83c\udfaf Data type: {MODEL_DTYPE}\")\n",
    "print(f\"\ud83d\udda5\ufe0f  Device: {next(model.parameters()).device}\")\n",
    "print(f\"\ud83d\udd32 Max Tiles: {CONFIG['MAX_TILES']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load bank statement image\n",
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_amount_balance.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_date_grouped_cont.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_highligted.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/low_contrast_fixed.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/nab_classic_highligted.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/westpac_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/transaction_summary.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/cba_date_grouped.png\"\n",
    "\n",
    "\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/images/image_009.png\"\n",
    "print(\"\ud83d\udcc1 Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"\u2705 Image loaded: {image.size}\")\n",
    "print(f\"\u2705 Images list created with {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the loaded image for visual verification\n",
    "print(\"\ud83d\uddbc\ufe0f  Bank statement image:\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Image preprocessing for InternVL3 (Official implementation)\n",
    "\n",
    "# Official InternVL3 image preprocessing (from docs)\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.229)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    \"\"\"Build image transformation pipeline with ImageNet normalization.\"\"\"\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    \"\"\"Find the closest aspect ratio from target ratios based on image dimensions.\"\"\"\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=None, image_size=448, use_thumbnail=False):\n",
    "    \"\"\"\n",
    "    Dynamically preprocess image by splitting into tiles based on aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        min_num: Minimum number of tiles\n",
    "        max_num: Maximum number of tiles (from CONFIG['MAX_TILES'])\n",
    "        image_size: Size of each tile (448 for InternVL3)\n",
    "        use_thumbnail: Whether to include thumbnail image\n",
    "    \n",
    "    Returns:\n",
    "        List of PIL Image tiles\n",
    "    \"\"\"\n",
    "    # Use CONFIG if max_num not specified\n",
    "    if max_num is None:\n",
    "        max_num = CONFIG['MAX_TILES']\n",
    "    \n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # Generate target aspect ratios\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # Find best aspect ratio\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # Calculate target dimensions\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # Resize and split into tiles\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    \n",
    "    assert len(processed_images) == blocks\n",
    "    \n",
    "    # Add thumbnail if requested\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    \n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=None):\n",
    "    \"\"\"\n",
    "    Load and preprocess image for InternVL3.\n",
    "    \n",
    "    Args:\n",
    "        image_file: Path to image or PIL Image object\n",
    "        input_size: Size of each tile (448 for InternVL3)\n",
    "        max_num: Max number of tiles (uses CONFIG['MAX_TILES'] if None)\n",
    "    \n",
    "    Returns:\n",
    "        pixel_values: Preprocessed tensor ready for model.chat()\n",
    "    \"\"\"\n",
    "    # Use CONFIG if max_num not specified\n",
    "    if max_num is None:\n",
    "        max_num = CONFIG['MAX_TILES']\n",
    "    \n",
    "    # Handle both path string and PIL Image\n",
    "    if isinstance(image_file, str):\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "    else:\n",
    "        image = image_file\n",
    "    \n",
    "    # Build transform and preprocess\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(img) for img in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    \n",
    "    return pixel_values\n",
    "\n",
    "print(\"\u2705 InternVL3 image preprocessing functions defined\")\n",
    "print(f\"\ud83d\udd32 Using max_num={CONFIG['MAX_TILES']} tiles (from CONFIG)\")\n",
    "print(f\"\ud83d\udca1 Image preprocessing: ImageNet normalization + dynamic tiling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Statement Extraction Protocol\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract full table using dynamic markdown example\n",
    "- Python: Parse, filter, and extract schema fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Turn 0 - Identify table headers (prompt)\n",
    "# TURN 0: Identify Table Headers\n",
    "# First, identify the actual column headers used in this specific bank statement\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "IMPORTANT STRUCTURAL NOTE:\n",
    "Some bank statements show dates as section headings with multiple transactions underneath.\n",
    "If you see this structure, remember that each transaction needs its explicit date in the final output.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\ud83d\udcac TURN 0: Identifying actual table headers\")\n",
    "print(\"\ud83e\udd16 Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Turn 0 - Execute and parse headers (InternVL3-8B version)\n",
    "\n",
    "print(\"\ud83d\udcac TURN 0: Identifying actual table headers\")\n",
    "print(\"\ud83e\udd16 Generating response with InternVL3-8B...\")\n",
    "\n",
    "# Load and preprocess image for InternVL3 (uses CONFIG['MAX_TILES'])\n",
    "pixel_values = load_image(imageName, input_size=448)\n",
    "\n",
    "# Move to correct device and dtype (MODEL_DTYPE set in cell-5 based on loading mode)\n",
    "# Vision model is always on GPU 0\n",
    "vision_device = 'cuda:0'\n",
    "pixel_values = pixel_values.to(dtype=MODEL_DTYPE, device=vision_device)\n",
    "\n",
    "# Generate response using chat() method\n",
    "cleanedOutput = model.chat(\n",
    "    tokenizer=tokenizer,\n",
    "    pixel_values=pixel_values,\n",
    "    question=prompt,\n",
    "    generation_config={\n",
    "        \"max_new_tokens\": CONFIG['MAX_NEW_TOKENS'],\n",
    "        \"do_sample\": False  # Greedy decoding for consistency\n",
    "    }\n",
    ")\n",
    "\n",
    "# Clean InternVL3 artifacts:\n",
    "# 1. Remove image markdown placeholder (![...])\n",
    "# 2. Remove markdown code fences (```markdown and ```)\n",
    "lines = cleanedOutput.split(\"\\n\")\n",
    "cleaned_lines = []\n",
    "for line in lines:\n",
    "    stripped = line.strip()\n",
    "    # Skip image markdown, code fences, and empty fence markers\n",
    "    if stripped.startswith(\"![\"):\n",
    "        continue\n",
    "    if stripped in [\"```markdown\", \"```\", \"```md\"]:\n",
    "        continue\n",
    "    cleaned_lines.append(line)\n",
    "\n",
    "cleanedOutput = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "print(\"\u2705 Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CRITICAL: Parse the identified headers for use in subsequent turns\n",
    "# Extract column names from the response\n",
    "header_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\n",
    "identified_headers = []\n",
    "\n",
    "# Look for numbered list or bullet points\n",
    "for line in header_lines:\n",
    "    # Remove common list markers\n",
    "    cleaned = line.lstrip('0123456789.-\u2022* ').strip()\n",
    "    \n",
    "    # Strip markdown bold formatting\n",
    "    cleaned = cleaned.replace('**', '').replace('__', '')\n",
    "    \n",
    "    # Skip section headers (lines ending with colon)\n",
    "    if cleaned.endswith(':'):\n",
    "        continue\n",
    "    \n",
    "    # Skip long sentences (likely explanatory text, not headers)\n",
    "    if len(cleaned) > 40:\n",
    "        continue\n",
    "        \n",
    "    if cleaned and len(cleaned) > 2:  # Ignore very short strings\n",
    "        identified_headers.append(cleaned)\n",
    "\n",
    "print(f\"\\n\ud83d\udccb Parsed {len(identified_headers)} column headers:\")\n",
    "for i, header in enumerate(identified_headers, 1):\n",
    "    print(f\"  {i}. '{header}'\")\n",
    "\n",
    "# Store headers for use in subsequent turns\n",
    "table_headers = identified_headers\n",
    "\n",
    "# Save the table headers\n",
    "output_path = Path(\"ivl3_8b_table_headers.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput)\n",
    "\n",
    "print(f\"\\n\u2705 Table headers saved to: {output_path}\")\n",
    "print(\"\ud83d\udca1 These LITERAL header names will be used in Turn 1 prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 11: Turn 0 - Execute and parse headers\n",
    "# # Process the input using the CORRECT multi-turn pattern\n",
    "# # Based on: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "# textInput = processor.apply_chat_template(\n",
    "#     messageDataStructure, add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "# # CRITICAL: Use named parameter 'images=' with list\n",
    "# inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# # Generate response with deterministic parameters\n",
    "# output = model.generate(\n",
    "#     **inputs,\n",
    "#     max_new_tokens=2000,\n",
    "#     do_sample=False,\n",
    "#     temperature=None,\n",
    "#     top_p=None,\n",
    "# )\n",
    "\n",
    "# # CRITICAL: Trim input tokens from output (this is the key to clean responses!)\n",
    "# generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "# cleanedOutput = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "# print(\"\u2705 Response generated successfully!\")\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "# print(\"=\" * 60)\n",
    "# print(cleanedOutput)\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# # CRITICAL: Parse the identified headers for use in subsequent turns\n",
    "# # Extract column names from the response\n",
    "# header_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\n",
    "# identified_headers = []\n",
    "\n",
    "# # Look for numbered list or bullet points\n",
    "# for line in header_lines:\n",
    "#     # Remove common list markers\n",
    "#     cleaned = line.lstrip('0123456789.-\u2022* ').strip()\n",
    "    \n",
    "#     # Strip markdown bold formatting\n",
    "#     cleaned = cleaned.replace('**', '').replace('__', '')\n",
    "    \n",
    "#     # Skip section headers (lines ending with colon)\n",
    "#     if cleaned.endswith(':'):\n",
    "#         continue\n",
    "    \n",
    "#     # Skip long sentences (likely explanatory text, not headers)\n",
    "#     if len(cleaned) > 40:\n",
    "#         continue\n",
    "        \n",
    "#     if cleaned and len(cleaned) > 2:  # Ignore very short strings\n",
    "#         identified_headers.append(cleaned)\n",
    "\n",
    "# print(f\"\\n\ud83d\udccb Parsed {len(identified_headers)} column headers:\")\n",
    "# for i, header in enumerate(identified_headers, 1):\n",
    "#     print(f\"  {i}. '{header}'\")\n",
    "\n",
    "# # Store headers for use in subsequent turns\n",
    "# table_headers = identified_headers\n",
    "\n",
    "# # Save the table headers\n",
    "# output_path = Path(\"llama_table_headers.txt\")\n",
    "# with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "#     text_file.write(cleanedOutput)\n",
    "\n",
    "# print(f\"\\n\u2705 Table headers saved to: {output_path}\")\n",
    "# print(\"\ud83d\udca1 These LITERAL header names will be used in Turn 1 & 2 prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Pattern Matching - Map headers to generic columns\n",
    "# Pattern Matching: Map extracted headers to generic concepts\n",
    "# This handles variety in bank statement column naming conventions\n",
    "\n",
    "# Pattern keywords for each concept (in priority order)\n",
    "DATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\n",
    "DESCRIPTION_PATTERNS = [\n",
    "    'description', 'details', 'transaction details', 'trans details',\n",
    "    'particulars', 'narrative', 'transaction', 'trans'\n",
    "]\n",
    "DEBIT_PATTERNS = ['debit', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\n",
    "CREDIT_PATTERNS = ['credit', 'deposit', 'deposits', 'received', 'cr']\n",
    "BALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n",
    "\n",
    "# NEW: Pattern for single-column transaction formats (e.g., \"Amount\" instead of separate Debit/Credit)\n",
    "AMOUNT_PATTERNS = ['amount', 'amt', 'value', 'total']\n",
    "\n",
    "def match_header(headers, patterns, fallback=None):\n",
    "    \"\"\"Match a header using pattern keywords.\n",
    "    \n",
    "    Matching strategy:\n",
    "    1. Exact match (case-insensitive)\n",
    "    2. Substring match (only for patterns with length > 2 to avoid false positives)\n",
    "    \"\"\"\n",
    "    headers_lower = [h.lower() for h in headers]\n",
    "    \n",
    "    # Try exact match first\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern == header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    # Try substring match (only for patterns longer than 2 chars)\n",
    "    for pattern in patterns:\n",
    "        if len(pattern) > 2:  # Avoid false positives like 'cr' matching 'description'\n",
    "            for i, header_lower in enumerate(headers_lower):\n",
    "                if pattern in header_lower:\n",
    "                    return headers[i]\n",
    "    \n",
    "    return fallback\n",
    "\n",
    "# Perform pattern matching on extracted headers\n",
    "date_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\n",
    "desc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n",
    "\n",
    "# NEW: First try to match a generic \"Amount\" column (for 4-column formats)\n",
    "amount_col = match_header(table_headers, AMOUNT_PATTERNS, fallback=None)\n",
    "\n",
    "# Use amount_col as fallback if no separate debit/credit columns exist\n",
    "# This handles formats like: Date | Description | Amount | Balance\n",
    "debit_col = match_header(table_headers, DEBIT_PATTERNS, fallback=amount_col if amount_col else 'Debit')\n",
    "credit_col = match_header(table_headers, CREDIT_PATTERNS, fallback=amount_col if amount_col else 'Credit')\n",
    "balance_col = match_header(table_headers, BALANCE_PATTERNS, fallback='Balance')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATTERN MATCHING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\ud83d\udccb Extracted Headers: {table_headers}\")\n",
    "print(f\"\\n\ud83d\udd0d Mapped Columns:\")\n",
    "print(f\"  Date        \u2192 '{date_col}'\")\n",
    "print(f\"  Description \u2192 '{desc_col}'\")\n",
    "print(f\"  Debit       \u2192 '{debit_col}'\")\n",
    "print(f\"  Credit      \u2192 '{credit_col}'\")\n",
    "print(f\"  Balance     \u2192 '{balance_col}'\")\n",
    "if amount_col:\n",
    "    print(f\"\\n\ud83d\udca1 Single-column format detected: '{amount_col}' used for both debit and credit\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n\u2705 These literal column names will be used in Turn 1 and Turn 2\")\n",
    "print(\"\ud83d\udca1 Adjust patterns above if matching fails for your bank statement format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udd11 Independent Single-Turn Pattern (NOT Multi-Turn Conversation)\n",
    "\n",
    "**CRITICAL INSIGHT**: Multi-turn conversation accumulates context and degrades accuracy.\n",
    "\n",
    "We use **two independent single-turn prompts**, each with fresh context:\n",
    "\n",
    "#### Key Principles:\n",
    "\n",
    "1. **No Conversation History**: Each turn is completely independent\n",
    "2. **Fresh Image Attention**: Each turn processes the image directly\n",
    "3. **No Context Accumulation**: Prevents attention dilution\n",
    "4. **Headers as Parameters**: Turn 0 headers used to generate dynamic examples for Turn 1\n",
    "5. **Python Filtering**: LLM filtering mixes up rows - Python is reliable\n",
    "\n",
    "#### Message Structure for Each Turn:\n",
    "\n",
    "Every turn uses fresh structure:\n",
    "```python\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"<prompt with dynamic example>\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "**No assistant responses in history. No conversation accumulation.**\n",
    "\n",
    "#### Why This Works Better:\n",
    "\n",
    "- **Turn 0**: Clean context \u2192 accurate header identification\n",
    "- **Turn 1**: Clean context + dynamic example \u2192 accurate table extraction  \n",
    "- **Python**: Reliable parsing and filtering (no row mixing!)\n",
    "\n",
    "Each turn has **full attention** on the image, not diluted by conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: NO conversation history (independent turns)\n",
    "# \n",
    "# CRITICAL: We do NOT use conversation history in this notebook.\n",
    "# Each turn is completely independent with fresh context.\n",
    "#\n",
    "# Why? Multi-turn conversation accumulates context and degrades accuracy:\n",
    "# - Turn 0: ~50 tokens \u2192 accurate\n",
    "# - Turn 1 with history: ~350 tokens \u2192 attention diluted \u2192 less accurate\n",
    "# - Turn 2 with history: ~2000 tokens \u2192 attention heavily diluted \u2192 row mixing!\n",
    "#\n",
    "# Instead: \n",
    "# - Turn 0: Fresh context \u2192 headers\n",
    "# - Turn 1: Fresh context + dynamic example \u2192 full table\n",
    "# - Python: Parse and filter (no LLM confusion!)\n",
    "\n",
    "print(\"\u2705 Independent turn approach - NO conversation history\")\n",
    "print(\"\ud83d\udca1 Each turn has fresh context with direct image access\")\n",
    "print(\"\ud83d\udc0d Python handles all filtering - no LLM row mixing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Column Aware Extraction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Generate Column Aware Extraction Prompt\n",
    "\n",
    "# Build the header string using LITERAL names from Turn 0\n",
    "header_string = \" | \".join(table_headers)\n",
    "\n",
    "# Build separator row with proper alignment indicators\n",
    "# Date and Description columns: left-aligned (:---)\n",
    "# Debit, Credit, Balance columns: right-aligned (---:)\n",
    "separator_parts = []\n",
    "for h in table_headers:\n",
    "    h_lower = h.lower()\n",
    "    # Right-align numeric columns\n",
    "    if any(keyword in h_lower for keyword in ['debit', 'credit', 'balance', 'amount', 'total']):\n",
    "        separator_parts.append('---:')\n",
    "    else:\n",
    "        # Left-align text columns (Date, Transaction, Description, etc.)\n",
    "        separator_parts.append(':---')\n",
    "\n",
    "separator_row = \" | \".join(separator_parts)\n",
    "\n",
    "# Build dynamic example rows based on detected column structure\n",
    "# CRITICAL: Examples must emphasize correct Debit/Credit column alignment!\n",
    "def build_dynamic_example(headers, date_col, desc_col, debit_col, credit_col, balance_col):\n",
    "    \"\"\"Generate example rows matching detected column structure.\n",
    "    \n",
    "    Emphasizes correct Debit/Credit alignment for tax purposes:\n",
    "    - Debits (purchases/withdrawals) = money OUT = what taxpayer PAID\n",
    "    - Credits (deposits/income) = money IN = NOT purchases\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if we have separate debit/credit columns\n",
    "    has_separate_debit_credit = (debit_col in headers and credit_col in headers and debit_col != credit_col)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    if has_separate_debit_credit:\n",
    "        # 5-column format: Emphasize Debit vs Credit with clear examples\n",
    "        \n",
    "        # Example 1: DEBIT transaction (purchase/withdrawal) - money OUT\n",
    "        row1 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row1.append(\"15 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row1.append(\"ATM Withdrawal City Branch\")\n",
    "            elif h == debit_col:\n",
    "                row1.append(\"200.00\")  # Amount in DEBIT column\n",
    "            elif h == credit_col:\n",
    "                row1.append(\"\")  # Credit column EMPTY\n",
    "            elif h == balance_col:\n",
    "                row1.append(\"$1,500.00 CR\")\n",
    "            else:\n",
    "                row1.append(\"\")\n",
    "        rows.append(\" | \".join(row1))\n",
    "        \n",
    "        # Example 2: CREDIT transaction (deposit) - money IN\n",
    "        row2 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row2.append(\"16 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row2.append(\"Salary Employer Name Ref 12345\")\n",
    "            elif h == debit_col:\n",
    "                row2.append(\"\")  # Debit column EMPTY\n",
    "            elif h == credit_col:\n",
    "                row2.append(\"3,500.00\")  # Amount in CREDIT column\n",
    "            elif h == balance_col:\n",
    "                row2.append(\"$5,000.00 CR\")\n",
    "            else:\n",
    "                row2.append(\"\")\n",
    "        rows.append(\" | \".join(row2))\n",
    "        \n",
    "        # Example 3: Another DEBIT transaction (purchase)\n",
    "        row3 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row3.append(\"17 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row3.append(\"Online Purchase Store Name\")\n",
    "            elif h == debit_col:\n",
    "                row3.append(\"150.00\")  # Amount in DEBIT column\n",
    "            elif h == credit_col:\n",
    "                row3.append(\"\")  # Credit column EMPTY\n",
    "            elif h == balance_col:\n",
    "                row3.append(\"$4,850.00 CR\")\n",
    "            else:\n",
    "                row3.append(\"\")\n",
    "        rows.append(\" | \".join(row3))\n",
    "        \n",
    "    else:\n",
    "        # 4-column format: Single Amount column\n",
    "        row1 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row1.append(\"15 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row1.append(\"ATM Withdrawal City Branch\")\n",
    "            elif h == debit_col:  # This is the Amount column\n",
    "                row1.append(\"200.00\")\n",
    "            elif h == balance_col:\n",
    "                row1.append(\"$1,500.00 CR\")\n",
    "            else:\n",
    "                row1.append(\"\")\n",
    "        rows.append(\" | \".join(row1))\n",
    "        \n",
    "        row2 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row2.append(\"16 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row2.append(\"Salary Employer Name Ref 12345\")\n",
    "            elif h == debit_col:  # This is the Amount column\n",
    "                row2.append(\"3,500.00\")\n",
    "            elif h == balance_col:\n",
    "                row2.append(\"$5,000.00 CR\")\n",
    "            else:\n",
    "                row2.append(\"\")\n",
    "        rows.append(\" | \".join(row2))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def build_multiline_rule(headers):\n",
    "    \"\"\"Generate multi-line extraction rule using ACTUAL column structure from Turn 0.\"\"\"\n",
    "    num_cols = len(headers)\n",
    "    \n",
    "    # Find actual Debit, Credit, and Balance columns by name\n",
    "    debit_idx = None\n",
    "    credit_idx = None\n",
    "    balance_idx = None\n",
    "    \n",
    "    for i, header in enumerate(headers):\n",
    "        h_lower = header.lower()\n",
    "        if any(p in h_lower for p in [\"debit\", \"withdrawal\", \"paid\", \"spent\", \"dr\"]):\n",
    "            debit_idx = i\n",
    "        if any(p in h_lower for p in [\"credit\", \"deposit\", \"received\", \"cr\"]):\n",
    "            credit_idx = i\n",
    "        if any(p in h_lower for p in [\"balance\", \"bal\"]):\n",
    "            balance_idx = i\n",
    "    \n",
    "    if debit_idx is None or credit_idx is None:\n",
    "        return \"Multi-line: combine description lines into single row.\"\n",
    "    \n",
    "    def format_aligned_table(rows):\n",
    "        \"\"\"Format rows with properly aligned vertical pipes.\"\"\"\n",
    "        if not rows:\n",
    "            return []\n",
    "        \n",
    "        num_cols = len(rows[0])\n",
    "        \n",
    "        # Calculate max width for each column\n",
    "        col_widths = [0] * num_cols\n",
    "        for row in rows:\n",
    "            for i, val in enumerate(row):\n",
    "                col_widths[i] = max(col_widths[i], len(val))\n",
    "        \n",
    "        # Find last non-empty column index\n",
    "        last_col = 0\n",
    "        for row in rows:\n",
    "            for i, val in enumerate(row):\n",
    "                if val:\n",
    "                    last_col = max(last_col, i)\n",
    "        \n",
    "        # Ensure empty MIDDLE columns have minimum width\n",
    "        for i in range(1, last_col):  # Skip first column, only middle columns\n",
    "            if col_widths[i] == 0:\n",
    "                col_widths[i] = 7\n",
    "        \n",
    "        # Format each row with proper alignment\n",
    "        formatted = []\n",
    "        for row in rows:\n",
    "            # Determine how many columns to include\n",
    "            end_col = last_col + 2 if last_col < len(row) - 1 else last_col + 1\n",
    "            end_col = min(end_col, len(row))\n",
    "            \n",
    "            # Pad each column value to its width\n",
    "            parts = []\n",
    "            for i in range(end_col):\n",
    "                val = row[i] if i < len(row) else \"\"\n",
    "                parts.append(val.ljust(col_widths[i]))\n",
    "            \n",
    "            line = \" | \".join(parts)\n",
    "            \n",
    "            # CRITICAL: If first column is empty, add leading spaces to align pipes\n",
    "            if not row[0]:\n",
    "                line = \" \" * col_widths[0] + \" | \" + \" | \".join(parts[1:])\n",
    "            \n",
    "            formatted.append(line)\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    # Create example rows using ACTUAL column positions\n",
    "    # Credit example (amount in credit_idx position)\n",
    "    credit_rows = [[\"\"] * num_cols for _ in range(3)]\n",
    "    credit_rows[0][0] = \"a date\"\n",
    "    credit_rows[0][1] = \"line 1\"\n",
    "    credit_rows[0][credit_idx] = \"85.50\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        credit_rows[0][balance_idx] = \"$1,085.50 CR\"\n",
    "    credit_rows[1][0] = \"\"  # Empty date for continuation\n",
    "    credit_rows[1][1] = \"line 2\"\n",
    "    credit_rows[2][0] = \"a date\"\n",
    "    credit_rows[2][1] = \"line 1 line 2\"\n",
    "    credit_rows[2][credit_idx] = \"85.50\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        credit_rows[2][balance_idx] = \"$1,085.50 CR\"\n",
    "    \n",
    "    # Debit example (amount in debit_idx position)\n",
    "    debit_rows = [[\"\"] * num_cols for _ in range(3)]\n",
    "    debit_rows[0][0] = \"a date\"\n",
    "    debit_rows[0][1] = \"line 1\"\n",
    "    debit_rows[0][debit_idx] = \"150.00\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        debit_rows[0][balance_idx] = \"$850.00 CR\"\n",
    "    debit_rows[1][0] = \"\"  # Empty date for continuation\n",
    "    debit_rows[1][1] = \"line 2\"\n",
    "    debit_rows[2][0] = \"a date\"\n",
    "    debit_rows[2][1] = \"line 1 line 2\"\n",
    "    debit_rows[2][debit_idx] = \"150.00\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        debit_rows[2][balance_idx] = \"$850.00 CR\"\n",
    "    \n",
    "    # Format both examples\n",
    "    credit_fmt = format_aligned_table(credit_rows)\n",
    "    debit_fmt = format_aligned_table(debit_rows)\n",
    "    \n",
    "    # Build rule with LABELED examples using actual header names\n",
    "    rule = f\"\"\"  {headers[credit_idx]} example:\n",
    "       {credit_fmt[0]}\n",
    "       {credit_fmt[1]}\n",
    "    you must extract it as:\n",
    "       {credit_fmt[2]}\n",
    "\n",
    "  {headers[debit_idx]} example:\n",
    "       {debit_fmt[0]}\n",
    "       {debit_fmt[1]}\n",
    "    you must extract it as:\n",
    "       {debit_fmt[2]}\"\"\"\n",
    "    \n",
    "    return rule\n",
    "\n",
    "# Generate dynamic example rows\n",
    "example_rows = build_dynamic_example(table_headers, date_col, desc_col, debit_col, credit_col, balance_col)\n",
    "\n",
    "# Build complete example table with proper alignment\n",
    "example_table = f\"\"\"| {header_string} |\n",
    "| {separator_row} |\n",
    "\"\"\" + \"\\n\".join([f\"| {row} |\" for row in example_rows])\n",
    "\n",
    "# Generate dynamic multi-line rule\n",
    "multiline_rule = build_multiline_rule(table_headers)\n",
    "\n",
    "# OPTION D: STRONGER COLUMN REINFORCEMENT\n",
    "follow_up_prompt = f\"\"\"\n",
    "Extract the transaction table from this bank statement image in markdown format.\n",
    "\n",
    "Example showing the format I want:\n",
    "\n",
    "{example_table}\n",
    "\n",
    "## CRITICAL: COLUMN ALIGNMENT\n",
    "\n",
    "Before extracting ANY row, locate the header row with these column names:\n",
    "{\" | \".join(table_headers)}\n",
    "\n",
    "For EACH transaction, you must check which column the amount appears under:\n",
    "\n",
    "**Step-by-step process:**\n",
    "1. Find the header row\n",
    "2. Look at the transaction row\n",
    "3. Draw an imaginary vertical line from the amount UP to the header\n",
    "4. Read which header the amount aligns with\n",
    "5. Put the amount in that SAME column in your markdown table\n",
    "\n",
    "**Column placement rules:**\n",
    "- Amount aligns with \"{debit_col}\" header \u2192 put amount in {debit_col} column, leave {credit_col} EMPTY\n",
    "- Amount aligns with \"{credit_col}\" header \u2192 put amount in {credit_col} column, leave {debit_col} EMPTY\n",
    "\n",
    "**Do NOT guess based on description text. Use visual alignment ONLY.**\n",
    "\n",
    "## OTHER RULES\n",
    "\n",
    "**Multi-line transactions:** Combine description lines into single row:\n",
    "{multiline_rule}\n",
    "\n",
    "**Empty columns:** Leave empty (|  |)\n",
    "\n",
    "**Output:** Markdown table only, no explanations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Turn 1 Extraction Prompt (Option D):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{follow_up_prompt}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17.5: Turn 1 - Extract full table (InternVL3-8B version, INDEPENDENT fresh context)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "def markdown_table_to_html(markdown_text):\n",
    "    \"\"\"Convert markdown table to HTML for reliable Jupyter rendering.\n",
    "\n",
    "    CRITICAL: Markdown tables with empty cells render incorrectly in Jupyter.\n",
    "    HTML tables preserve empty cells and column alignment properly.\n",
    "    \"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "\n",
    "    # Find table lines (contain pipes)\n",
    "    table_lines = [line for line in lines if '|' in line]\n",
    "    if not table_lines:\n",
    "        return f\"<pre>{markdown_text}</pre>\"\n",
    "\n",
    "    html_parts = ['<table border=\"1\" style=\"border-collapse: collapse;\">']\n",
    "\n",
    "    for i, line in enumerate(table_lines):\n",
    "        # Skip separator rows (contain only pipes, hyphens, colons, spaces)\n",
    "        cleaned = line.replace('|', '').replace('-', '').replace(':', '').replace(' ', '')\n",
    "        if not cleaned:\n",
    "            continue\n",
    "\n",
    "        # Parse cells\n",
    "        cells = [c.strip() for c in line.split('|')]\n",
    "        # Remove leading/trailing empty strings from pipe delimiters\n",
    "        if cells and cells[0] == '':\n",
    "            cells = cells[1:]\n",
    "        if cells and cells[-1] == '':\n",
    "            cells = cells[:-1]\n",
    "\n",
    "        # First non-separator row is header\n",
    "        if i == 0:\n",
    "            html_parts.append('<tr style=\"background-color: #f0f0f0;\">')\n",
    "            for cell in cells:\n",
    "                html_parts.append(f'<th style=\"padding: 8px; text-align: left;\">{cell}</th>')\n",
    "            html_parts.append('</tr>')\n",
    "        else:\n",
    "            html_parts.append('<tr>')\n",
    "            for cell in cells:\n",
    "                html_parts.append(f'<td style=\"padding: 8px;\">{cell}</td>')\n",
    "            html_parts.append('</tr>')\n",
    "\n",
    "    html_parts.append('</table>')\n",
    "    return '\\n'.join(html_parts)\n",
    "\n",
    "print(\"\ud83e\udd16 Generating response with InternVL3-8B...\")\n",
    "\n",
    "# CRITICAL: Reload image for fresh context (independent turn, not continuing conversation)\n",
    "# Uses CONFIG['MAX_TILES'] via load_image() default\n",
    "pixel_values = load_image(imageName, input_size=448)\n",
    "\n",
    "# Move to correct device and dtype (MODEL_DTYPE set in cell-5 based on loading mode)\n",
    "# Vision model is always on GPU 0\n",
    "pixel_values = pixel_values.to(dtype=MODEL_DTYPE, device='cuda:0')\n",
    "\n",
    "# Generate response using chat() method with dynamic prompt\n",
    "cleanedOutput2 = model.chat(\n",
    "    tokenizer=tokenizer,\n",
    "    pixel_values=pixel_values,\n",
    "    question=follow_up_prompt,  # Dynamic prompt with column-aware examples from Cell 19\n",
    "    generation_config={\n",
    "        \"max_new_tokens\": CONFIG['MAX_NEW_TOKENS'],\n",
    "        \"do_sample\": False\n",
    "    }\n",
    ")\n",
    "\n",
    "# Clean InternVL3 artifacts:\n",
    "# 1. Remove image markdown placeholder (![...])\n",
    "# 2. Remove markdown code fences (```markdown and ```)\n",
    "lines = cleanedOutput2.split(\"\\n\")\n",
    "cleaned_lines = []\n",
    "for line in lines:\n",
    "    stripped = line.strip()\n",
    "    # Skip image markdown, code fences, and empty fence markers\n",
    "    if stripped.startswith(\"![\"):\n",
    "        continue\n",
    "    if stripped in [\"```markdown\", \"```\", \"```md\"]:\n",
    "        continue\n",
    "    cleaned_lines.append(line)\n",
    "\n",
    "cleanedOutput2 = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "print(\"\\n\u2705 Turn 1 extraction complete!\")\n",
    "\n",
    "# Display the extracted table as HTML for reliable rendering with empty cells\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 1 - EXTRACTED TABLE (HTML Rendered):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Render as HTML table (fixes empty cell rendering issues with Markdown)\n",
    "html_table = markdown_table_to_html(cleanedOutput2)\n",
    "display(HTML(html_table))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 1 - RAW MARKDOWN TEXT:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput2)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save the markdown table\n",
    "output_path = Path(\"ivl3_8b_markdown_table_extraction.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput2)\n",
    "\n",
    "print(f\"\\n\u2705 Markdown table saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Parsing and Filtering\n",
    "\n",
    "Parse the Turn 1 markdown table, filter for debit transactions, and extract schema fields using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser as date_parser\n",
    "\n",
    "\n",
    "def _compute_date_range(dates: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Compute statement date range ensuring chronological order (oldest - newest).\n",
    "    \n",
    "    Bank statements may be in reverse chronological order (newest first),\n",
    "    so we parse and sort dates to ensure correct order.\n",
    "    \"\"\"\n",
    "    if not dates:\n",
    "        return \"NOT_FOUND\"\n",
    "    \n",
    "    parsed_dates = []\n",
    "    for date_str in dates:\n",
    "        if not date_str or not date_str.strip():\n",
    "            continue\n",
    "        try:\n",
    "            parsed = date_parser.parse(date_str.strip(), dayfirst=True)\n",
    "            parsed_dates.append((parsed, date_str.strip()))\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    \n",
    "    if not parsed_dates:\n",
    "        return f\"{dates[0]} - {dates[-1]}\" if len(dates) >= 2 else dates[0]\n",
    "    \n",
    "    parsed_dates.sort(key=lambda x: x[0])\n",
    "    oldest = parsed_dates[0][1]\n",
    "    newest = parsed_dates[-1][1]\n",
    "    \n",
    "    return f\"{oldest} - {newest}\"\n",
    "\n",
    "\n",
    "# Cell 19: Parse Turn 1 markdown table and filter for debits (Python)\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_markdown_table(markdown_text):\n",
    "    \"\"\"Parse markdown table into list of dictionaries.\n",
    "    \n",
    "    CRITICAL: Must preserve empty columns for correct Debit/Credit alignment!\n",
    "    \"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    # Find header row (first line with pipes)\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line:\n",
    "            # Skip separator rows (contain only pipes, hyphens, and spaces)\n",
    "            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n",
    "            if cleaned:  # Has actual content, not just separators\n",
    "                header_idx = i\n",
    "                break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        return []\n",
    "    \n",
    "    # Parse headers - KEEP empty values to preserve column positions\n",
    "    header_line = lines[header_idx]\n",
    "    header_parts = [h.strip() for h in header_line.split('|')]\n",
    "    # Remove leading/trailing empty strings from pipe delimiters\n",
    "    if header_parts and header_parts[0] == '':\n",
    "        header_parts = header_parts[1:]\n",
    "    if header_parts and header_parts[-1] == '':\n",
    "        header_parts = header_parts[:-1]\n",
    "    # Filter out any remaining empty headers\n",
    "    headers = [h for h in header_parts if h]\n",
    "    \n",
    "    print(f\"\ud83d\udd0d Debug: Parsed {len(headers)} headers: {headers}\")\n",
    "    \n",
    "    # Parse data rows (skip header and separator)\n",
    "    rows = []\n",
    "    for idx, line in enumerate(lines[header_idx + 1:], start=header_idx+1):\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "            \n",
    "        # Skip separator rows\n",
    "        cleaned = line.replace(\"|\", \"\").replace(\"-\", \"\").replace(\" \", \"\").replace(\":\", \"\")\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        \n",
    "        # Parse values - KEEP empty values to preserve column positions!\n",
    "        value_parts = [v.strip() for v in line.split('|')]\n",
    "        # Remove leading/trailing empty strings from pipe delimiters\n",
    "        if value_parts and value_parts[0] == '':\n",
    "            value_parts = value_parts[1:]\n",
    "        if value_parts and value_parts[-1] == '':\n",
    "            value_parts = value_parts[:-1]\n",
    "        \n",
    "        print(f\"\ud83d\udd0d Debug row {idx}: {len(value_parts)} values: {value_parts}\")\n",
    "        \n",
    "        # Match to headers length\n",
    "        if len(value_parts) == len(headers):\n",
    "            rows.append(dict(zip(headers, value_parts)))\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f  Row {idx} mismatch: {len(value_parts)} values vs {len(headers)} headers - SKIPPED\")\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def filter_debit_transactions(rows, debit_col):\n",
    "    \"\"\"Filter rows to only those with debit (purchase) amounts.\n",
    "    \n",
    "    CRITICAL: For tax purposes, we only want transactions where taxpayer PAID money (debits).\n",
    "    \"\"\"\n",
    "    debit_rows = []\n",
    "    for row in rows:\n",
    "        debit_value = row.get(debit_col, '').strip()\n",
    "        # Include row if debit column has a value (not empty)\n",
    "        if debit_value:\n",
    "            debit_rows.append(row)\n",
    "    \n",
    "    return debit_rows\n",
    "\n",
    "def extract_schema_fields(rows, date_col, desc_col, debit_col):\n",
    "    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n",
    "    if not rows:\n",
    "        return {\n",
    "            'TRANSACTION_DATES': 'NOT_FOUND',\n",
    "            'LINE_ITEM_DESCRIPTIONS': 'NOT_FOUND',\n",
    "            'TRANSACTION_AMOUNTS_PAID': 'NOT_FOUND',\n",
    "            'STATEMENT_DATE_RANGE': 'NOT_FOUND'\n",
    "        }\n",
    "    \n",
    "    # Extract lists\n",
    "    dates = []\n",
    "    descriptions = []\n",
    "    amounts = []\n",
    "    \n",
    "    for row in rows:\n",
    "        date = row.get(date_col, '').strip()\n",
    "        desc = row.get(desc_col, '').strip()\n",
    "        amount = row.get(debit_col, '').strip()\n",
    "        \n",
    "        if date:\n",
    "            dates.append(date)\n",
    "        if desc:\n",
    "            descriptions.append(desc)\n",
    "        if amount:\n",
    "            amounts.append(amount)\n",
    "    \n",
    "    # Calculate statement date range - use literal date format from image\n",
    "    # No parsing, no year assumption - just \"earliest date - latest date\"\n",
    "    date_range = 'NOT_FOUND'\n",
    "    if dates:\n",
    "        # Use first and last date as-is (same format as in the image)\n",
    "        date_range = _compute_date_range(dates)\n",
    "    \n",
    "    return {\n",
    "        'TRANSACTION_DATES': ' | '.join(dates) if dates else 'NOT_FOUND',\n",
    "        'LINE_ITEM_DESCRIPTIONS': ' | '.join(descriptions) if descriptions else 'NOT_FOUND',\n",
    "        'TRANSACTION_AMOUNTS_PAID': ' | '.join(amounts) if amounts else 'NOT_FOUND',\n",
    "        'STATEMENT_DATE_RANGE': date_range\n",
    "    }\n",
    "\n",
    "# Cell: Balance-Based Debit/Credit Validation Function\n",
    "\n",
    "def detect_document_order(rows, balance_col):\n",
    "    \"\"\"\n",
    "    Detect if document is in chronological or reverse chronological order.\n",
    "    \n",
    "    Logic: If balances generally INCREASE going down the table, the document\n",
    "    is in reverse chronological order (newest first, oldest last).\n",
    "    \n",
    "    Returns:\n",
    "        str: \"chronological\" or \"reverse_chronological\"\n",
    "    \"\"\"\n",
    "    def parse_amount(value):\n",
    "        if not value or value.strip() == \"\":\n",
    "            return 0.0\n",
    "        cleaned = value.replace(\"$\", \"\").replace(\",\", \"\").replace(\"CR\", \"\").replace(\"DR\", \"\").strip()\n",
    "        try:\n",
    "            return float(cleaned)\n",
    "        except ValueError:\n",
    "            return 0.0\n",
    "    \n",
    "    if len(rows) < 3:\n",
    "        return \"chronological\"  # Default assumption\n",
    "    \n",
    "    # Sample multiple balance transitions to determine trend\n",
    "    increases = 0\n",
    "    decreases = 0\n",
    "    \n",
    "    for i in range(1, min(len(rows), 10)):  # Check first 10 rows\n",
    "        prev_balance = parse_amount(rows[i-1].get(balance_col, \"0\"))\n",
    "        curr_balance = parse_amount(rows[i].get(balance_col, \"0\"))\n",
    "        \n",
    "        if curr_balance > prev_balance + 0.01:\n",
    "            increases += 1\n",
    "        elif curr_balance < prev_balance - 0.01:\n",
    "            decreases += 1\n",
    "    \n",
    "    # If balances mostly increase going down \u2192 reverse chronological\n",
    "    if increases > decreases:\n",
    "        return \"reverse_chronological\"\n",
    "    else:\n",
    "        return \"chronological\"\n",
    "\n",
    "\n",
    "def validate_and_correct_alignment(rows, balance_col, debit_col, credit_col, desc_col):\n",
    "    \"\"\"\n",
    "    Use balance changes to validate and correct debit/credit alignment.\n",
    "    \n",
    "    CRITICAL: This provides mathematical proof of correct alignment!\n",
    "    \n",
    "    IMPORTANT: This function now detects document order (chronological vs \n",
    "    reverse chronological) and adjusts validation logic accordingly.\n",
    "    \n",
    "    For CHRONOLOGICAL order (oldest first):\n",
    "    - Balance increase between rows = CREDIT (income/deposit)\n",
    "    - Balance decrease between rows = DEBIT (expense/withdrawal)\n",
    "    \n",
    "    For REVERSE CHRONOLOGICAL order (newest first, like image_008.png):\n",
    "    - Balance increase between rows = DEBIT (going back in time, balance was lower before)\n",
    "    - Balance decrease between rows = CREDIT (going back in time, balance was higher before)\n",
    "    \"\"\"\n",
    "    \n",
    "    def parse_amount(value):\n",
    "        \"\"\"Extract numeric value from formatted currency string.\"\"\"\n",
    "        if not value or value.strip() == \"\":\n",
    "            return 0.0\n",
    "        cleaned = value.replace(\"$\", \"\").replace(\",\", \"\").replace(\"CR\", \"\").replace(\"DR\", \"\").strip()\n",
    "        try:\n",
    "            return float(cleaned)\n",
    "        except ValueError:\n",
    "            return 0.0\n",
    "    \n",
    "    def is_balance_row(row, desc_col):\n",
    "        \"\"\"Check if this row is an opening/closing balance row (not a transaction).\"\"\"\n",
    "        desc = row.get(desc_col, \"\").upper()\n",
    "        return \"OPENING BALANCE\" in desc or \"CLOSING BALANCE\" in desc\n",
    "    \n",
    "    # Check if Balance column exists\n",
    "    if not rows or balance_col not in rows[0]:\n",
    "        print(f\"\u26a0\ufe0f  Balance column '{balance_col}' not found - skipping validation\")\n",
    "        return rows\n",
    "    \n",
    "    # CRITICAL: Detect document order before validation\n",
    "    doc_order = detect_document_order(rows, balance_col)\n",
    "    print(f\"\ud83d\udcca Document order detected: {doc_order.upper()}\")\n",
    "    \n",
    "    if doc_order == \"reverse_chronological\":\n",
    "        print(\"\ud83d\udca1 Reverse chronological: Balance increases going down = transactions went BACK in time\")\n",
    "        print(\"\ud83d\udca1 Validation logic inverted: balance increase \u2192 DEBIT, balance decrease \u2192 CREDIT\")\n",
    "    \n",
    "    corrected_rows = []\n",
    "    corrections_made = 0\n",
    "    start_idx = 0\n",
    "    \n",
    "    # Check if row 0 is an opening balance row\n",
    "    if rows and is_balance_row(rows[0], desc_col):\n",
    "        print(f\"\u2705 Row 0: Opening/closing balance detected - skipping (not a transaction)\")\n",
    "        start_idx = 1\n",
    "    elif rows:\n",
    "        corrected_rows.append(rows[0].copy())\n",
    "        print(f\"\u2705 Row 0: First transaction included without validation (no previous balance to compare)\")\n",
    "        start_idx = 1\n",
    "    \n",
    "    # Validate and correct remaining rows\n",
    "    for i in range(start_idx, len(rows)):\n",
    "        current_row = rows[i].copy()\n",
    "        \n",
    "        if is_balance_row(current_row, desc_col):\n",
    "            print(f\"\u26a0\ufe0f  Row {i}: Opening/closing balance row detected - skipping\")\n",
    "            continue\n",
    "        \n",
    "        prev_idx = i - 1\n",
    "        while prev_idx >= 0 and is_balance_row(rows[prev_idx], desc_col):\n",
    "            prev_idx -= 1\n",
    "        \n",
    "        if prev_idx < 0:\n",
    "            corrected_rows.append(current_row)\n",
    "            print(f\"\u2705 Row {i}: First transaction after balance row - included without validation\")\n",
    "            continue\n",
    "        \n",
    "        prev_balance = parse_amount(rows[prev_idx].get(balance_col, \"0\"))\n",
    "        curr_balance = parse_amount(current_row.get(balance_col, \"0\"))\n",
    "        balance_change = curr_balance - prev_balance\n",
    "        \n",
    "        debit_value = parse_amount(current_row.get(debit_col, \"\"))\n",
    "        credit_value = parse_amount(current_row.get(credit_col, \"\"))\n",
    "        \n",
    "        # CRITICAL: Adjust validation logic based on document order\n",
    "        if doc_order == \"reverse_chronological\":\n",
    "            if balance_change > 0.01:  # Balance increased (reverse chrono = DEBIT)\n",
    "                if credit_value > 0 and debit_value == 0:\n",
    "                    print(f\"\u26a0\ufe0f  Row {i}: Balance increased by ${balance_change:.2f} (reverse chrono \u2192 DEBIT expected) but amount in Credit column\")\n",
    "                    print(f\"   Correction: Moving ${credit_value:.2f} from Credit \u2192 Debit\")\n",
    "                    current_row[debit_col] = current_row[credit_col]\n",
    "                    current_row[credit_col] = \"\"\n",
    "                    corrections_made += 1\n",
    "            elif balance_change < -0.01:  # Balance decreased (reverse chrono = CREDIT)\n",
    "                if debit_value > 0 and credit_value == 0:\n",
    "                    print(f\"\u26a0\ufe0f  Row {i}: Balance decreased by ${abs(balance_change):.2f} (reverse chrono \u2192 CREDIT expected) but amount in Debit column\")\n",
    "                    print(f\"   Correction: Moving ${debit_value:.2f} from Debit \u2192 Credit\")\n",
    "                    current_row[credit_col] = current_row[debit_col]\n",
    "                    current_row[debit_col] = \"\"\n",
    "                    corrections_made += 1\n",
    "        else:\n",
    "            if balance_change > 0.01:  # Balance increased = CREDIT\n",
    "                if debit_value > 0 and credit_value == 0:\n",
    "                    print(f\"\u26a0\ufe0f  Row {i}: Balance increased by ${balance_change:.2f} but amount in Debit column\")\n",
    "                    print(f\"   Correction: Moving ${debit_value:.2f} from Debit \u2192 Credit\")\n",
    "                    current_row[credit_col] = current_row[debit_col]\n",
    "                    current_row[debit_col] = \"\"\n",
    "                    corrections_made += 1\n",
    "            elif balance_change < -0.01:  # Balance decreased = DEBIT\n",
    "                if credit_value > 0 and debit_value == 0:\n",
    "                    print(f\"\u26a0\ufe0f  Row {i}: Balance decreased by ${abs(balance_change):.2f} but amount in Credit column\")\n",
    "                    print(f\"   Correction: Moving ${credit_value:.2f} from Credit \u2192 Debit\")\n",
    "                    current_row[debit_col] = current_row[credit_col]\n",
    "                    current_row[credit_col] = \"\"\n",
    "                    corrections_made += 1\n",
    "        \n",
    "        corrected_rows.append(current_row)\n",
    "    \n",
    "    print(f\"\\n\u2705 Balance validation complete: {corrections_made} corrections made\")\n",
    "    print(f\"\u2705 Total transaction rows processed: {len(corrected_rows)}\")\n",
    "    return corrected_rows\n",
    "\n",
    "print(\"\u2705 Balance validation function defined\")\n",
    "print(\"\ud83d\udca1 This function uses balance mathematics to validate and auto-correct misaligned amounts\")\n",
    "print(\"\ud83d\udca1 Opening/closing balance rows are automatically detected and skipped\")\n",
    "print(\"\ud83d\udca1 Automatically detects reverse chronological documents and adjusts logic\")\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PARSING TURN 1 MARKDOWN TABLE:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Parse the full markdown table from Turn 1\n",
    "all_rows = parse_markdown_table(cleanedOutput2)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Parsed {len(all_rows)} total transactions from Turn 1 markdown table\")\n",
    "\n",
    "if all_rows:\n",
    "    # Show sample parsed row\n",
    "    print(f\"\\n\ud83d\udd0d Sample parsed row:\")\n",
    "    for key, value in all_rows[0].items():\n",
    "        print(f\"  {key}: '{value}'\")\n",
    "\n",
    "# Filter to only debit (purchase) transactions - Python filtering, not LLM!\n",
    "\n",
    "# Apply balance-based validation if Balance column exists\n",
    "if balance_col and balance_col in table_headers:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BALANCE-BASED VALIDATION:\")\n",
    "    print(\"=\" * 60)\n",
    "    all_rows = validate_and_correct_alignment(all_rows, balance_col, debit_col, credit_col, desc_col)\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  No Balance column - skipping balance-based validation\")\n",
    "\n",
    "debit_rows = filter_debit_transactions(all_rows, debit_col)\n",
    "\n",
    "print(f\"\\n\ud83d\udcb0 Filtered to {len(debit_rows)} debit transactions (taxpayer purchases)\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEBIT TRANSACTIONS (WHAT TAXPAYER PAID):\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in enumerate(debit_rows, 1):\n",
    "    print(f\"\\nTransaction {i}:\")\n",
    "    print(f\"  {date_col}: {row.get(date_col, '')}\")\n",
    "    print(f\"  {desc_col}: {row.get(desc_col, '')}\")\n",
    "    print(f\"  {debit_col}: {row.get(debit_col, '')}\")\n",
    "\n",
    "# Extract schema fields using the LITERAL column names from pattern matching\n",
    "schema_fields = extract_schema_fields(debit_rows, date_col, desc_col, debit_col)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTED SCHEMA FIELDS (TAX-RELEVANT DATA):\")\n",
    "print(\"=\" * 60)\n",
    "for field, value in schema_fields.items():\n",
    "    print(f\"{field}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save to file with ivl3_8b prefix\n",
    "output_path = Path(\"ivl3_8b_extracted_fields.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for field, value in schema_fields.items():\n",
    "        f.write(f\"{field}: {value}\\n\")\n",
    "\n",
    "print(f\"\\n\u2705 Schema fields saved to: {output_path}\")\n",
    "print(f\"\ud83d\udca1 Fields extracted from columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")\n",
    "print(f\"\ud83c\udfaf Success: Python parsing + filtering from Turn 1 markdown table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LMM_POC)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}