{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Statement Model Comparison\n",
    "\n",
    "**Comparing Llama-3.2-Vision, InternVL3-8B, and InternVL3.5-8B on Bank Statement Extraction**\n",
    "\n",
    "---\n",
    "\n",
    "This notebook compares the performance of three vision-language models on bank statement field extraction.\n",
    "\n",
    "## Key Questions:\n",
    "1. **Accuracy**: Which model extracts transaction data most accurately?\n",
    "2. **Speed**: Which model processes bank statements faster?\n",
    "3. **Field Performance**: How do models perform on dates, amounts, and descriptions?\n",
    "4. **Recommendation**: Which model is best for bank statement processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration loaded\n",
      "ğŸ“ Output directory: /Users/tod/Desktop/LMM_POC/output\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "console = Console()\n",
    "\n",
    "# Professional styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration - adjust base_path for your environment\n",
    "# base_path = '/home/jovyan/nfs_share/tod/LMM_POC'\n",
    "base_path = '/Users/tod/Desktop/LMM_POC'  # Mac local\n",
    "\n",
    "CONFIG = {\n",
    "    'output_dir': f'{base_path}/output',\n",
    "    'ground_truth_path': f'{base_path}/evaluation_data/bank/ground_truth_bank.csv',\n",
    "    \n",
    "    # File patterns for bank statement batch results\n",
    "    'patterns': {\n",
    "        'Llama-3.2-Vision': 'unified_bank_batch_llama_3_2_vision_*.csv',\n",
    "        'InternVL3-8B': 'unified_bank_batch_internvl3_8b_*.csv',\n",
    "        'InternVL3.5-8B': 'unified_bank_batch_internvl3_5_8b_*.csv',\n",
    "    },\n",
    "    \n",
    "    # Visualization settings\n",
    "    'figure_size': (14, 8),\n",
    "    'dpi': 150,\n",
    "}\n",
    "\n",
    "# Model colors for consistent visualization\n",
    "MODEL_COLORS = {\n",
    "    'Llama-3.2-Vision': '#2ecc71',    # Green\n",
    "    'InternVL3-8B': '#3498db',         # Blue  \n",
    "    'InternVL3.5-8B': '#9b59b6',       # Purple\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration loaded\")\n",
    "print(f\"ğŸ“ Output directory: {CONFIG['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Results Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">ğŸ“Š Loading Bank Statement Results</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mğŸ“Š Loading Bank Statement Results\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Loading Llama-</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3.2</span><span style=\"color: #008000; text-decoration-color: #008000\">-Vision: unified_bank_batch_llama_3_2_vision_20251204_063513.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Loading Llama-\u001b[0m\u001b[1;32m3.2\u001b[0m\u001b[32m-Vision: unified_bank_batch_llama_3_2_vision_20251204_063513.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Loading InternVL3-8B: unified_bank_batch_internvl3_8b_20251205_025606.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Loading InternVL3-8B: unified_bank_batch_internvl3_8b_20251205_025606.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Loading InternVL3.</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\">-8B: unified_bank_batch_internvl3_5_8b_20251205_022950.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Loading InternVL3.\u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m-8B: unified_bank_batch_internvl3_5_8b_20251205_022950.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Combined: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">36</span><span style=\"color: #008000; text-decoration-color: #008000\"> records from </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3</span><span style=\"color: #008000; text-decoration-color: #008000\"> models</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Combined: \u001b[0m\u001b[1;32m36\u001b[0m\u001b[32m records from \u001b[0m\u001b[1;32m3\u001b[0m\u001b[32m models\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_latest_results(output_dir: str, pattern: str, model_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Load the most recent CSV results file matching the pattern.\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    search_path = output_path / pattern\n",
    "    files = glob.glob(str(search_path))\n",
    "    \n",
    "    if not files:\n",
    "        rprint(f\"[yellow]âš ï¸ No files found: {pattern}[/yellow]\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    latest_file = max(files, key=lambda x: Path(x).stat().st_mtime)\n",
    "    rprint(f\"[green]âœ… Loading {model_name}: {Path(latest_file).name}[/green]\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(latest_file)\n",
    "        df['model'] = model_name\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        rprint(f\"[red]âŒ Error loading {model_name}: {e}[/red]\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load all model results\n",
    "rprint(\"[bold blue]ğŸ“Š Loading Bank Statement Results[/bold blue]\")\n",
    "print()\n",
    "\n",
    "dataframes = []\n",
    "for model_name, pattern in CONFIG['patterns'].items():\n",
    "    df = load_latest_results(CONFIG['output_dir'], pattern, model_name)\n",
    "    if not df.empty:\n",
    "        dataframes.append(df)\n",
    "\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print()\n",
    "    rprint(f\"[green]âœ… Combined: {len(combined_df)} records from {combined_df['model'].nunique()} models[/green]\")\n",
    "else:\n",
    "    rprint(\"[red]âŒ No data loaded![/red]\")\n",
    "    combined_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Bank Statement Extraction: Model Comparison                      </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Model                </span>â”ƒ<span style=\"font-weight: bold\">  Avg Accuracy  </span>â”ƒ<span style=\"font-weight: bold\">    Min/Max     </span>â”ƒ<span style=\"font-weight: bold\">   Avg Time   </span>â”ƒ<span style=\"font-weight: bold\"> Documents  </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> InternVL3-8B         </span>â”‚     56.3%      â”‚    20%-100%    â”‚    82.2s     â”‚     12     â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> InternVL3.5-8B       </span>â”‚     84.3%      â”‚    40%-100%    â”‚    106.6s    â”‚     12     â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Llama-3.2-Vision     </span>â”‚     85.9%      â”‚    40%-100%    â”‚    271.7s    â”‚     12     â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                     Bank Statement Extraction: Model Comparison                      \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mModel               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m Avg Accuracy \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Min/Max    \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m  Avg Time  \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mDocuments \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mInternVL3-8B        \u001b[0m\u001b[36m \u001b[0mâ”‚     56.3%      â”‚    20%-100%    â”‚    82.2s     â”‚     12     â”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mInternVL3.5-8B      \u001b[0m\u001b[36m \u001b[0mâ”‚     84.3%      â”‚    40%-100%    â”‚    106.6s    â”‚     12     â”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mLlama-3.2-Vision    \u001b[0m\u001b[36m \u001b[0mâ”‚     85.9%      â”‚    40%-100%    â”‚    271.7s    â”‚     12     â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ† Best Accuracy: Llama-</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3.2</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">-Vision (</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">85.9</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">%)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mğŸ† Best Accuracy: Llama-\u001b[0m\u001b[1;32m3.2\u001b[0m\u001b[1;32m-Vision \u001b[0m\u001b[1;32m(\u001b[0m\u001b[1;32m85.9\u001b[0m\u001b[1;32m%\u001b[0m\u001b[1;32m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">âš¡ Fastest: InternVL3-8B (</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">82.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2s avg)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mâš¡ Fastest: InternVL3-8B \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34m82.\u001b[0m\u001b[1;34m2s avg\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not combined_df.empty:\n",
    "    # Calculate summary statistics\n",
    "    summary = combined_df.groupby('model').agg({\n",
    "        'overall_accuracy': ['mean', 'std', 'min', 'max'],\n",
    "        'processing_time': ['mean', 'std'],\n",
    "        'image_file': 'count'\n",
    "    }).round(4)\n",
    "    \n",
    "    summary.columns = ['Avg Accuracy', 'Std Dev', 'Min Acc', 'Max Acc', \n",
    "                       'Avg Time (s)', 'Time Std', 'Documents']\n",
    "    \n",
    "    # Create executive summary table\n",
    "    table = Table(title=\"Bank Statement Extraction: Model Comparison\", show_header=True)\n",
    "    table.add_column(\"Model\", style=\"cyan\", width=20)\n",
    "    table.add_column(\"Avg Accuracy\", justify=\"center\", width=14)\n",
    "    table.add_column(\"Min/Max\", justify=\"center\", width=14)\n",
    "    table.add_column(\"Avg Time\", justify=\"center\", width=12)\n",
    "    table.add_column(\"Documents\", justify=\"center\", width=10)\n",
    "    \n",
    "    for model in summary.index:\n",
    "        row = summary.loc[model]\n",
    "        acc_str = f\"{row['Avg Accuracy']*100:.1f}%\"\n",
    "        range_str = f\"{row['Min Acc']*100:.0f}%-{row['Max Acc']*100:.0f}%\"\n",
    "        time_str = f\"{row['Avg Time (s)']:.1f}s\"\n",
    "        docs_str = str(int(row['Documents']))\n",
    "        table.add_row(model, acc_str, range_str, time_str, docs_str)\n",
    "    \n",
    "    console.print(table)\n",
    "    \n",
    "    # Determine winner\n",
    "    best_model = summary['Avg Accuracy'].idxmax()\n",
    "    best_acc = summary.loc[best_model, 'Avg Accuracy']\n",
    "    print()\n",
    "    rprint(f\"[bold green]ğŸ† Best Accuracy: {best_model} ({best_acc*100:.1f}%)[/bold green]\")\n",
    "    \n",
    "    fastest_model = summary['Avg Time (s)'].idxmin()\n",
    "    fastest_time = summary.loc[fastest_model, 'Avg Time (s)']\n",
    "    rprint(f\"[bold blue]âš¡ Fastest: {fastest_model} ({fastest_time:.1f}s avg)[/bold blue]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Overall Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not combined_df.empty:\n    fig, axes = plt.subplots(1, 2, figsize=CONFIG['figure_size'])\n    \n    # Box plot of accuracy distribution\n    ax1 = axes[0]\n    models = combined_df['model'].unique()\n    colors = [MODEL_COLORS.get(m, '#95a5a6') for m in models]\n    \n    box_data = [combined_df[combined_df['model'] == m]['overall_accuracy'] * 100 for m in models]\n    bp = ax1.boxplot(box_data, labels=models, patch_artist=True)\n    \n    for patch, color in zip(bp['boxes'], colors):\n        patch.set_facecolor(color)\n        patch.set_alpha(0.7)\n    \n    ax1.set_ylabel('Overall Accuracy (%)', fontsize=12)\n    ax1.set_title('Accuracy Distribution by Model', fontsize=14, fontweight='bold')\n    ax1.tick_params(axis='x', rotation=15)\n    ax1.set_ylim([0, 105])\n    ax1.axhline(y=85, color='red', linestyle='--', alpha=0.5, label='85% threshold')\n    ax1.legend()\n    \n    # Bar chart of mean accuracy\n    ax2 = axes[1]\n    means = combined_df.groupby('model')['overall_accuracy'].mean() * 100\n    stds = combined_df.groupby('model')['overall_accuracy'].std() * 100\n    \n    bars = ax2.bar(means.index, means.values, \n                   color=[MODEL_COLORS.get(m, '#95a5a6') for m in means.index],\n                   alpha=0.8, edgecolor='black')\n    ax2.errorbar(means.index, means.values, yerr=stds.values, \n                 fmt='none', color='black', capsize=5)\n    \n    # Add value labels\n    for bar, val in zip(bars, means.values):\n        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n                f'{val:.1f}%', ha='center', va='bottom', fontweight='bold')\n    \n    ax2.set_ylabel('Mean Accuracy (%)', fontsize=12)\n    ax2.set_title('Mean Accuracy with Std Dev', fontsize=14, fontweight='bold')\n    ax2.tick_params(axis='x', rotation=15)\n    ax2.set_ylim([0, 105])\n    ax2.axhline(y=85, color='red', linestyle='--', alpha=0.5)\n    \n    plt.tight_layout()\n    plt.savefig(f\"{CONFIG['output_dir']}/bank_accuracy_comparison.svg\", bbox_inches='tight')\n    plt.show()\n    print(f\"\\nğŸ“Š Saved: bank_accuracy_comparison.svg\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Processing Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not combined_df.empty:\n    fig, axes = plt.subplots(1, 2, figsize=CONFIG['figure_size'])\n    \n    # Box plot of processing times\n    ax1 = axes[0]\n    models = combined_df['model'].unique()\n    colors = [MODEL_COLORS.get(m, '#95a5a6') for m in models]\n    \n    box_data = [combined_df[combined_df['model'] == m]['processing_time'] for m in models]\n    bp = ax1.boxplot(box_data, labels=models, patch_artist=True)\n    \n    for patch, color in zip(bp['boxes'], colors):\n        patch.set_facecolor(color)\n        patch.set_alpha(0.7)\n    \n    ax1.set_ylabel('Processing Time (seconds)', fontsize=12)\n    ax1.set_title('Processing Time Distribution', fontsize=14, fontweight='bold')\n    ax1.tick_params(axis='x', rotation=15)\n    \n    # Throughput comparison (docs per minute)\n    ax2 = axes[1]\n    avg_times = combined_df.groupby('model')['processing_time'].mean()\n    throughput = 60 / avg_times  # documents per minute\n    \n    bars = ax2.bar(throughput.index, throughput.values,\n                   color=[MODEL_COLORS.get(m, '#95a5a6') for m in throughput.index],\n                   alpha=0.8, edgecolor='black')\n    \n    for bar, val in zip(bars, throughput.values):\n        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n                f'{val:.1f}', ha='center', va='bottom', fontweight='bold')\n    \n    ax2.set_ylabel('Documents per Minute', fontsize=12)\n    ax2.set_title('Throughput Comparison', fontsize=14, fontweight='bold')\n    ax2.tick_params(axis='x', rotation=15)\n    \n    plt.tight_layout()\n    plt.savefig(f\"{CONFIG['output_dir']}/bank_processing_time.svg\", bbox_inches='tight')\n    plt.show()\n    print(f\"\\nğŸ“Š Saved: bank_processing_time.svg\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Field-Level Performance (F1 Scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not combined_df.empty:\n    # Find F1 score columns\n    f1_cols = [col for col in combined_df.columns if col.endswith('_f1')]\n    \n    if f1_cols:\n        # Calculate mean F1 per field per model\n        field_performance = combined_df.groupby('model')[f1_cols].mean() * 100\n        \n        # Rename columns for display\n        field_performance.columns = [col.replace('_f1', '').replace('_', ' ').title() \n                                      for col in field_performance.columns]\n        \n        # Create heatmap\n        fig, ax = plt.subplots(figsize=(12, 6))\n        \n        sns.heatmap(field_performance, annot=True, fmt='.1f', cmap='RdYlGn',\n                    vmin=0, vmax=100, ax=ax, cbar_kws={'label': 'F1 Score (%)'})\n        \n        ax.set_title('Field-Level F1 Scores by Model', fontsize=14, fontweight='bold')\n        ax.set_xlabel('Field', fontsize=12)\n        ax.set_ylabel('Model', fontsize=12)\n        plt.xticks(rotation=45, ha='right')\n        \n        plt.tight_layout()\n        plt.savefig(f\"{CONFIG['output_dir']}/bank_field_f1_heatmap.svg\", bbox_inches='tight')\n        plt.show()\n        print(f\"\\nğŸ“Š Saved: bank_field_f1_heatmap.svg\")\n        \n        # Display as table\n        print(\"\\nğŸ“‹ Field F1 Scores (%):\\n\")\n        display(field_performance.round(1))\n    else:\n        print(\"âš ï¸ No F1 score columns found in data\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Per-Document Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not combined_df.empty:\n    # Pivot to compare models side by side\n    pivot_df = combined_df.pivot_table(\n        index='image_file',\n        columns='model',\n        values='overall_accuracy',\n        aggfunc='first'\n    ) * 100\n    \n    # Sort by average accuracy\n    pivot_df['avg'] = pivot_df.mean(axis=1)\n    pivot_df = pivot_df.sort_values('avg', ascending=False)\n    pivot_df = pivot_df.drop('avg', axis=1)\n    \n    # Create comparison chart\n    fig, ax = plt.subplots(figsize=(14, max(8, len(pivot_df) * 0.4)))\n    \n    x = np.arange(len(pivot_df))\n    width = 0.25\n    \n    models = [col for col in pivot_df.columns if col in MODEL_COLORS]\n    \n    for i, model in enumerate(models):\n        if model in pivot_df.columns:\n            offset = (i - len(models)/2 + 0.5) * width\n            ax.barh(x + offset, pivot_df[model], width,\n                   label=model, color=MODEL_COLORS.get(model, '#95a5a6'), alpha=0.8)\n    \n    ax.set_yticks(x)\n    ax.set_yticklabels(pivot_df.index, fontsize=9)\n    ax.set_xlabel('Accuracy (%)', fontsize=12)\n    ax.set_title('Per-Document Accuracy Comparison', fontsize=14, fontweight='bold')\n    ax.legend(loc='lower right')\n    ax.axvline(x=85, color='red', linestyle='--', alpha=0.5, label='85% threshold')\n    ax.set_xlim([0, 105])\n    \n    plt.tight_layout()\n    plt.savefig(f\"{CONFIG['output_dir']}/bank_per_document.svg\", bbox_inches='tight')\n    plt.show()\n    print(f\"\\nğŸ“Š Saved: bank_per_document.svg\")\n    \n    # Display table\n    print(\"\\nğŸ“‹ Per-Document Accuracy (%):\\n\")\n    display(pivot_df.round(1))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Accuracy vs Speed Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not combined_df.empty:\n    fig, ax = plt.subplots(figsize=(10, 8))\n    \n    for model in combined_df['model'].unique():\n        model_data = combined_df[combined_df['model'] == model]\n        ax.scatter(model_data['processing_time'], \n                  model_data['overall_accuracy'] * 100,\n                  c=MODEL_COLORS.get(model, '#95a5a6'),\n                  label=model, alpha=0.7, s=100, edgecolors='black')\n    \n    # Add means as larger markers\n    for model in combined_df['model'].unique():\n        model_data = combined_df[combined_df['model'] == model]\n        mean_time = model_data['processing_time'].mean()\n        mean_acc = model_data['overall_accuracy'].mean() * 100\n        ax.scatter(mean_time, mean_acc, c=MODEL_COLORS.get(model, '#95a5a6'),\n                  s=300, marker='*', edgecolors='black', linewidths=2)\n    \n    ax.axhline(y=85, color='red', linestyle='--', alpha=0.5, label='85% accuracy threshold')\n    ax.set_xlabel('Processing Time (seconds)', fontsize=12)\n    ax.set_ylabel('Accuracy (%)', fontsize=12)\n    ax.set_title('Accuracy vs Processing Time\\n(star = model mean)', fontsize=14, fontweight='bold')\n    ax.legend(loc='lower right')\n    ax.set_ylim([0, 105])\n    \n    plt.tight_layout()\n    plt.savefig(f\"{CONFIG['output_dir']}/bank_accuracy_vs_time.svg\", bbox_inches='tight')\n    plt.show()\n    print(f\"\\nğŸ“Š Saved: bank_accuracy_vs_time.svg\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Problem Documents Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Documents below 85% accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models Below Threshold</th>\n",
       "      <th>Avg Accuracy (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cba_highligted.png</th>\n",
       "      <td>InternVL3-8B</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_summary.png</th>\n",
       "      <td>InternVL3-8B</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cba_date_grouped_cont.png</th>\n",
       "      <td>InternVL3-8B, InternVL3.5-8B</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cba_debit_credit.png</th>\n",
       "      <td>InternVL3-8B</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_009.png</th>\n",
       "      <td>Llama-3.2-Vision, InternVL3-8B, InternVL3.5-8B</td>\n",
       "      <td>42.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic_reverse_chrono.png</th>\n",
       "      <td>Llama-3.2-Vision, InternVL3-8B, InternVL3.5-8B</td>\n",
       "      <td>43.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic_multiline.png</th>\n",
       "      <td>InternVL3-8B</td>\n",
       "      <td>59.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthetic_chrono.png</th>\n",
       "      <td>Llama-3.2-Vision, InternVL3-8B</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cba_amount_balance.png</th>\n",
       "      <td>InternVL3-8B</td>\n",
       "      <td>82.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Models Below Threshold  \\\n",
       "image_file                                                                     \n",
       "cba_highligted.png                                              InternVL3-8B   \n",
       "transaction_summary.png                                         InternVL3-8B   \n",
       "cba_date_grouped_cont.png                       InternVL3-8B, InternVL3.5-8B   \n",
       "cba_debit_credit.png                                            InternVL3-8B   \n",
       "image_009.png                 Llama-3.2-Vision, InternVL3-8B, InternVL3.5-8B   \n",
       "synthetic_reverse_chrono.png  Llama-3.2-Vision, InternVL3-8B, InternVL3.5-8B   \n",
       "synthetic_multiline.png                                         InternVL3-8B   \n",
       "synthetic_chrono.png                          Llama-3.2-Vision, InternVL3-8B   \n",
       "cba_amount_balance.png                                          InternVL3-8B   \n",
       "\n",
       "                              Avg Accuracy (%)  \n",
       "image_file                                      \n",
       "cba_highligted.png                        20.0  \n",
       "transaction_summary.png                   20.0  \n",
       "cba_date_grouped_cont.png                 33.8  \n",
       "cba_debit_credit.png                      40.0  \n",
       "image_009.png                             42.4  \n",
       "synthetic_reverse_chrono.png              43.3  \n",
       "synthetic_multiline.png                   59.5  \n",
       "synthetic_chrono.png                      64.1  \n",
       "cba_amount_balance.png                    82.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š 9 documents have at least one model below 85%\n"
     ]
    }
   ],
   "source": [
    "if not combined_df.empty:\n",
    "    # Find documents where accuracy < 85%\n",
    "    threshold = 0.85\n",
    "    \n",
    "    problem_docs = combined_df[combined_df['overall_accuracy'] < threshold].copy()\n",
    "    \n",
    "    if len(problem_docs) > 0:\n",
    "        print(f\"âš ï¸ Documents below {threshold*100:.0f}% accuracy:\\n\")\n",
    "        \n",
    "        problem_summary = problem_docs.groupby('image_file').agg({\n",
    "            'model': lambda x: ', '.join(x),\n",
    "            'overall_accuracy': 'mean'\n",
    "        }).sort_values('overall_accuracy')\n",
    "        \n",
    "        problem_summary['overall_accuracy'] = (problem_summary['overall_accuracy'] * 100).round(1)\n",
    "        problem_summary.columns = ['Models Below Threshold', 'Avg Accuracy (%)']\n",
    "        \n",
    "        display(problem_summary)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š {len(problem_summary)} documents have at least one model below {threshold*100:.0f}%\")\n",
    "    else:\n",
    "        rprint(f\"[green]âœ… All documents above {threshold*100:.0f}% accuracy for all models![/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recommendation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BANK STATEMENT EXTRACTION: MODEL RECOMMENDATION\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Results Summary:\n",
      "   â€¢ Documents tested: 12\n",
      "   â€¢ Models compared: 3\n",
      "\n",
      "ğŸ† Best Accuracy: Llama-3.2-Vision\n",
      "   â€¢ 85.9% average accuracy\n",
      "\n",
      "âš¡ Fastest Processing: InternVL3-8B\n",
      "   â€¢ 82.2s average per document\n",
      "\n",
      "ğŸ“ˆ Best Efficiency (accuracy/time): InternVL3.5-8B\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATION:\n",
      "============================================================\n",
      "\n",
      "â€¢ For maximum accuracy: Llama-3.2-Vision\n",
      "  (29.6% more accurate, 3.3x slower)\n",
      "\n",
      "â€¢ For speed priority: InternVL3-8B\n",
      "  (Faster but slightly lower accuracy)\n",
      "\n",
      "â€¢ Best overall value: InternVL3.5-8B\n"
     ]
    }
   ],
   "source": [
    "if not combined_df.empty:\n",
    "    print(\"=\"*60)\n",
    "    print(\"BANK STATEMENT EXTRACTION: MODEL RECOMMENDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Summary stats\n",
    "    stats = combined_df.groupby('model').agg({\n",
    "        'overall_accuracy': 'mean',\n",
    "        'processing_time': 'mean'\n",
    "    })\n",
    "    \n",
    "    best_accuracy = stats['overall_accuracy'].idxmax()\n",
    "    fastest = stats['processing_time'].idxmin()\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Results Summary:\")\n",
    "    print(f\"   â€¢ Documents tested: {combined_df['image_file'].nunique()}\")\n",
    "    print(f\"   â€¢ Models compared: {combined_df['model'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nğŸ† Best Accuracy: {best_accuracy}\")\n",
    "    print(f\"   â€¢ {stats.loc[best_accuracy, 'overall_accuracy']*100:.1f}% average accuracy\")\n",
    "    \n",
    "    print(f\"\\nâš¡ Fastest Processing: {fastest}\")\n",
    "    print(f\"   â€¢ {stats.loc[fastest, 'processing_time']:.1f}s average per document\")\n",
    "    \n",
    "    # Calculate efficiency score (accuracy per second)\n",
    "    stats['efficiency'] = stats['overall_accuracy'] / stats['processing_time']\n",
    "    best_efficiency = stats['efficiency'].idxmax()\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Best Efficiency (accuracy/time): {best_efficiency}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"RECOMMENDATION:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if best_accuracy == fastest:\n",
    "        print(f\"\\nâœ… {best_accuracy} is recommended\")\n",
    "        print(\"   (Best in both accuracy AND speed)\")\n",
    "    else:\n",
    "        acc_diff = (stats.loc[best_accuracy, 'overall_accuracy'] - stats.loc[fastest, 'overall_accuracy']) * 100\n",
    "        time_ratio = stats.loc[best_accuracy, 'processing_time'] / stats.loc[fastest, 'processing_time']\n",
    "        \n",
    "        print(f\"\\nâ€¢ For maximum accuracy: {best_accuracy}\")\n",
    "        print(f\"  ({acc_diff:.1f}% more accurate, {time_ratio:.1f}x slower)\")\n",
    "        print(f\"\\nâ€¢ For speed priority: {fastest}\")\n",
    "        print(f\"  (Faster but slightly lower accuracy)\")\n",
    "        print(f\"\\nâ€¢ Best overall value: {best_efficiency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Executive Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not combined_df.empty:\n    # Create executive dashboard - 3x2 grid with summary table\n    fig = plt.figure(figsize=(16, 14))\n    \n    # Main title\n    fig.suptitle('MODEL PERFORMANCE COMPARISON\\nBank Statement Information Extraction', \n                 fontsize=16, fontweight='bold', y=0.98)\n    \n    # Define grid: 3 rows x 2 columns\n    gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1], hspace=0.3, wspace=0.25)\n    \n    models = list(MODEL_COLORS.keys())\n    colors = [MODEL_COLORS[m] for m in models if m in combined_df['model'].unique()]\n    models_present = [m for m in models if m in combined_df['model'].unique()]\n    \n    # ============ Row 1: Accuracy Box Plot & Processing Time Box Plot ============\n    \n    # 1. Overall Accuracy Comparison (box plot)\n    ax1 = fig.add_subplot(gs[0, 0])\n    box_data = [combined_df[combined_df['model'] == m]['overall_accuracy'] * 100 \n                for m in models_present]\n    bp1 = ax1.boxplot(box_data, labels=models_present, patch_artist=True)\n    for patch, color in zip(bp1['boxes'], colors):\n        patch.set_facecolor(color)\n        patch.set_alpha(0.7)\n    # Add mean markers\n    means = [combined_df[combined_df['model'] == m]['overall_accuracy'].mean() * 100 \n             for m in models_present]\n    ax1.scatter(range(1, len(models_present)+1), means, color='darkgreen', \n                marker='D', s=50, zorder=5, label='Mean')\n    ax1.set_ylabel('Overall Accuracy (%)', fontsize=10)\n    ax1.set_title('Overall Accuracy Comparison', fontsize=12, fontweight='bold')\n    ax1.tick_params(axis='x', rotation=15, labelsize=9)\n    ax1.set_ylim([0, 105])\n    ax1.axhline(y=85, color='red', linestyle='--', alpha=0.5)\n    ax1.legend(loc='lower left', fontsize=8)\n    \n    # 2. Processing Speed Comparison (box plot)\n    ax2 = fig.add_subplot(gs[0, 1])\n    box_data_time = [combined_df[combined_df['model'] == m]['processing_time'] \n                     for m in models_present]\n    bp2 = ax2.boxplot(box_data_time, labels=models_present, patch_artist=True)\n    for patch, color in zip(bp2['boxes'], colors):\n        patch.set_facecolor(color)\n        patch.set_alpha(0.7)\n    ax2.set_ylabel('Processing Time (seconds)', fontsize=10)\n    ax2.set_title('Processing Speed Comparison', fontsize=12, fontweight='bold')\n    ax2.tick_params(axis='x', rotation=15, labelsize=9)\n    \n    # ============ Row 2: Field F1 Heatmap & Per-Image Bar Chart ============\n    \n    # 3. Field-Level F1 Scores (heatmap)\n    ax3 = fig.add_subplot(gs[1, 0])\n    f1_cols = [col for col in combined_df.columns if col.endswith('_f1')]\n    if f1_cols:\n        field_perf = combined_df.groupby('model')[f1_cols].mean() * 100\n        # Reorder rows to match MODEL_COLORS order\n        field_perf = field_perf.reindex([m for m in models_present if m in field_perf.index])\n        field_perf.columns = [col.replace('_f1', '').replace('_', '\\n').title()[:15] \n                              for col in field_perf.columns]\n        sns.heatmap(field_perf, annot=True, fmt='.0f', cmap='RdYlGn',\n                    vmin=0, vmax=100, ax=ax3, cbar_kws={'label': 'F1 %', 'shrink': 0.8},\n                    annot_kws={'size': 9})\n        ax3.set_title('Field-Level F1 Scores', fontsize=12, fontweight='bold')\n        ax3.set_xlabel('')\n        ax3.set_ylabel('')\n        ax3.tick_params(axis='x', rotation=45, labelsize=8)\n        ax3.tick_params(axis='y', labelsize=9)\n    \n    # 4. Per-Image Accuracy (grouped bar)\n    ax4 = fig.add_subplot(gs[1, 1])\n    pivot_df = combined_df.pivot_table(\n        index='image_file', columns='model', values='overall_accuracy', aggfunc='first'\n    ) * 100\n    # Sort by mean and take top 8 for readability\n    pivot_df['avg'] = pivot_df.mean(axis=1)\n    pivot_df = pivot_df.sort_values('avg', ascending=True).tail(10).drop('avg', axis=1)\n    \n    x = np.arange(len(pivot_df))\n    width = 0.25\n    for i, model in enumerate(models_present):\n        if model in pivot_df.columns:\n            offset = (i - len(models_present)/2 + 0.5) * width\n            ax4.barh(x + offset, pivot_df[model], width, label=model, \n                    color=MODEL_COLORS[model], alpha=0.8)\n    ax4.set_yticks(x)\n    ax4.set_yticklabels([f[:20] for f in pivot_df.index], fontsize=8)\n    ax4.set_xlabel('Accuracy (%)', fontsize=10)\n    ax4.set_title('Per-Document Accuracy (Top 10)', fontsize=12, fontweight='bold')\n    ax4.axvline(x=85, color='red', linestyle='--', alpha=0.5)\n    ax4.set_xlim([0, 105])\n    ax4.legend(loc='lower right', fontsize=8)\n    \n    # ============ Row 3: Efficiency Scatter & Summary Table ============\n    \n    # 5. Efficiency Analysis (scatter plot)\n    ax5 = fig.add_subplot(gs[2, 0])\n    for model in models_present:\n        model_data = combined_df[combined_df['model'] == model]\n        ax5.scatter(model_data['processing_time'], \n                   model_data['overall_accuracy'] * 100,\n                   c=MODEL_COLORS[model], label=model, alpha=0.6, s=80, edgecolors='black')\n    # Add iso-efficiency lines\n    for eff in [0.5, 1.0, 2.0, 5.0]:\n        x_line = np.linspace(1, combined_df['processing_time'].max() * 1.1, 100)\n        y_line = eff * x_line\n        ax5.plot(x_line, y_line, '--', color='gray', alpha=0.3, linewidth=1)\n    ax5.set_xlabel('Processing Time (seconds)', fontsize=10)\n    ax5.set_ylabel('Overall Accuracy (%)', fontsize=10)\n    ax5.set_title('Efficiency Analysis: Accuracy vs Processing Time', fontsize=12, fontweight='bold')\n    ax5.legend(loc='upper right', fontsize=8)\n    ax5.set_ylim([0, 105])\n    ax5.set_xlim([0, combined_df['processing_time'].max() * 1.1])\n    \n    # 6. Performance Summary Table\n    ax6 = fig.add_subplot(gs[2, 1])\n    ax6.axis('off')\n    \n    # Calculate summary stats\n    summary_data = []\n    for model in models_present:\n        model_data = combined_df[combined_df['model'] == model]\n        avg_acc = model_data['overall_accuracy'].mean() * 100\n        avg_time = model_data['processing_time'].mean()\n        docs_min = 60 / avg_time\n        std_dev = model_data['overall_accuracy'].std() * 100\n        summary_data.append([model, f'{avg_acc:.1f}%', f'{avg_time:.1f}s', \n                            f'{docs_min:.2f}', f'{std_dev:.1f}%'])\n    \n    # Create table\n    table = ax6.table(\n        cellText=summary_data,\n        colLabels=['Model', 'Avg Acc', 'Avg Time', 'Docs/min', 'Std Dev'],\n        loc='center',\n        cellLoc='center',\n        colColours=['#f0f0f0'] * 5\n    )\n    table.auto_set_font_size(False)\n    table.set_fontsize(10)\n    table.scale(1.2, 1.8)\n    \n    # Color code rows by model\n    for i, model in enumerate(models_present):\n        for j in range(5):\n            table[(i+1, j)].set_facecolor(MODEL_COLORS[model])\n            table[(i+1, j)].set_alpha(0.3)\n    \n    ax6.set_title('Performance Summary Table', fontsize=12, fontweight='bold', pad=20)\n    \n    plt.tight_layout(rect=[0, 0, 1, 0.96])\n    plt.savefig(f\"{CONFIG['output_dir']}/bank_model_dashboard.svg\", bbox_inches='tight', facecolor='white')\n    plt.show()\n    print(f\"\\nğŸ“Š Saved: bank_model_dashboard.svg\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Export Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not combined_df.empty:\n    # Export combined results\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    export_path = f\"{CONFIG['output_dir']}/bank_model_comparison_{timestamp}.csv\"\n    combined_df.to_csv(export_path, index=False)\n    \n    print(f\"ğŸ“ Exported combined results to: {export_path}\")\n    print(f\"\\nğŸ“Š Charts saved to: {CONFIG['output_dir']}/\")\n    print(\"   â€¢ bank_accuracy_comparison.svg\")\n    print(\"   â€¢ bank_processing_time.svg\")\n    print(\"   â€¢ bank_field_f1_heatmap.svg\")\n    print(\"   â€¢ bank_per_document.svg\")\n    print(\"   â€¢ bank_accuracy_vs_time.svg\")\n    print(\"   â€¢ bank_model_dashboard.svg\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "du",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}