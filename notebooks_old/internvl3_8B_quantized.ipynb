{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InternVL3-8B with 8-bit Quantization for 4x V100 (16GB each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"‚úÖ Random seed set to 42 for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Loading InternVL3-8B with 8-bit quantization for 4x V100 GPUs...\n",
      "FlashAttention2 is not installed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c351cf3872e54b18b1df398f8e2563f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and tokenizer loaded successfully with 8-bit quantization\n",
      "‚úÖ Model distributed across devices: {'vision_model': 0, 'language_model.model.embed_tokens': 0, 'language_model.model.layers.0': 0, 'language_model.model.layers.1': 0, 'language_model.model.layers.2': 0, 'language_model.model.layers.3': 0, 'language_model.model.layers.4': 0, 'language_model.model.layers.5': 0, 'language_model.model.layers.6': 0, 'language_model.model.layers.7': 0, 'language_model.model.layers.8': 0, 'language_model.model.layers.9': 1, 'language_model.model.layers.10': 1, 'language_model.model.layers.11': 1, 'language_model.model.layers.12': 1, 'language_model.model.layers.13': 1, 'language_model.model.layers.14': 1, 'language_model.model.layers.15': 1, 'language_model.model.layers.16': 1, 'language_model.model.layers.17': 1, 'language_model.model.layers.18': 1, 'language_model.model.layers.19': 1, 'language_model.model.layers.20': 1, 'language_model.model.layers.21': 1, 'language_model.model.layers.22': 1, 'language_model.model.layers.23': 1, 'language_model.model.layers.24': 1, 'language_model.model.layers.25': 1, 'language_model.model.layers.26': 1, 'language_model.model.layers.27': 1, 'language_model.model.norm': 1, 'language_model.model.rotary_emb': 1, 'language_model.lm_head': 1, 'mlp1': 1}\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your local InternVL3-8B model\n",
    "model_id = \"/home/jovyan/nfs_share/models/InternVL3-8B\"\n",
    "# Update this path to your test image\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/image_008.png\"\n",
    "\n",
    "print(\"üîß Loading InternVL3-8B with 8-bit quantization for 4x V100 GPUs...\")\n",
    "\n",
    "# 8-bit quantization config for V100 memory efficiency\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False,\n",
    ")\n",
    "\n",
    "# Load model with 8-bit quantization and device_map\n",
    "model = AutoModel.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",  # Required for quantization\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id, \n",
    "    trust_remote_code=True, \n",
    "    use_fast=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model and tokenizer loaded successfully with 8-bit quantization\")\n",
    "print(f\"‚úÖ Model distributed across devices: {model.hf_device_map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è  Processing image...\n",
      "üîç Model dtype: torch.float16\n",
      "üéØ Target device: cuda:0\n",
      "‚úÖ Image processed: torch.Size([7, 3, 448, 448])\n",
      "‚úÖ Number of image tiles: 7\n",
      "‚úÖ Pixel values dtype: torch.float16\n",
      "‚úÖ Pixel values on device: cuda:0\n",
      "‚úÖ Vision tokens: 1792\n",
      "‚ùì Question: You are an expert document analyzer specializing in bank statement extraction. Extract the transaction data from this Australian bank statement.\n"
     ]
    }
   ],
   "source": [
    "# Official InternVL3 image preprocessing (from docs)\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "# Process image with proper device handling for 8-bit quantized model\n",
    "print(\"üñºÔ∏è  Processing image...\")\n",
    "\n",
    "# Load image and keep on CPU initially\n",
    "pixel_values = load_image(imageName, input_size=448, max_num=12)\n",
    "\n",
    "# For 8-bit quantized models, we need to match the model's dtype\n",
    "# Check what dtype the vision model expects\n",
    "vision_device = 'cuda:0'  # Vision model is on GPU 0 based on device_map\n",
    "model_dtype = torch.float16\n",
    "\n",
    "print(f\"üîç Model dtype: {model_dtype}\")\n",
    "print(f\"üéØ Target device: {vision_device}\")\n",
    "\n",
    "# Convert to model's expected dtype and device\n",
    "pixel_values = pixel_values.to(device=vision_device, dtype=model_dtype)\n",
    "\n",
    "print(f\"‚úÖ Image processed: {pixel_values.shape}\")\n",
    "print(f\"‚úÖ Number of image tiles: {pixel_values.shape[0]}\")\n",
    "print(f\"‚úÖ Pixel values dtype: {pixel_values.dtype}\")\n",
    "print(f\"‚úÖ Pixel values on device: {pixel_values.device}\")\n",
    "print(f\"‚úÖ Vision tokens: {pixel_values.shape[0] * 256}\")\n",
    "\n",
    "# Visual Question Answering - ask a simple question about the image\n",
    "prompt = 'You are an expert document analyzer specializing in bank statement extraction. Extract the transaction data from this Australian bank statement.'\n",
    "# InternVL3 format: <image>\\n + question\n",
    "formatted_question = f'<image>\\n{prompt}'\n",
    "print(f\"‚ùì Question: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Generating response with InternVL3-8B (8-bit quantized)...\n",
      "üíæ GPU Memory before generation:\n",
      "   GPU 0: 3.51GB allocated, 3.63GB reserved\n",
      "   GPU 1: 5.55GB allocated, 6.09GB reserved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Response generated successfully!\n",
      "\n",
      "============================================================\n",
      "INTERNVL3 RESPONSE:\n",
      "============================================================\n",
      "![](https://i.imgur.com/4ZjKj5r.png)\n",
      "\n",
      "Here's the extracted transaction data from the Commonwealth Bank statement:\n",
      "\n",
      "| Date       | Description                                      | Withdrawal | Deposit | Balance     |\n",
      "|------------|--------------------------------------------------|------------|---------|-------------|\n",
      "| 07/09/2025 | EFTPOS Cash Out PRICELINE PHARMACY MACKAY QLD     | $322.18    |         | $4880.58    |\n",
      "| 08/09/2025 | EFTPOS Purchase OFFICEWORKS BUSINESS ROCKHAMPTO...| $64.33     |         | $4921.76    |\n",
      "| 09/09/2025 | Mortgage Repayment                                | $849.79    |         | $4927.70    |\n",
      "| 03/09/2025 | OSKO Payment to MIKE CHEN 80884985773133          | $1385.43   |         | $4926.88    |\n",
      "| 03/09/2025 | Direct Debit 15595481802039 MHF 42730            | $190.17    |         | $5132.31    |\n",
      "| 02/09/2025 | Salary Payment ATO 287286780782109                |            | $8105.71| $51511.48   |\n",
      "| 02/09/2025 | DD INSURANCE ACME CORP PTY LTD                    | $45.04     |         | $43405.77   |\n",
      "| 02/09/2025 | Auto Payment UTILITIES AGL 67840P85943944         | $257.50    |         | $43450.81   |\n",
      "| 01/09/2025 | DIRECT CREDIT SALARY 60080P6712986                | $37.98     | $4449.44| $43708.31   |\n",
      "| 01/09/2025 | BPAY Payment BILLER 60080P67290 CRN 90130184380   | $2457.87   |         | $39260.85   |\n",
      "| 31/08/2025 | Professional Services Red Energy 68073P1959417    | $270.31    |         | $39154.54   |\n",
      "| 20/08/2025 | Card Purchase RED ROOSTER Paramatta SA             | $1957.09   |         | $41754.72   |\n",
      "| 20/08/2025 | Credit Card Payment 7025993329288                |            |         | $42025.03   |\n",
      "| 27/08/2025 | EFTPOS Cash Out PRICELINE PHARMACY BRISBANE QLD   | $221.60    |         | $43892.12   |\n",
      "| 26/08/2025 | Card Purchase CHEMIST WAREHOUSE DISCOUNT          | $222.56    |         | $44203.72   |\n",
      "| 24/08/2025 | Fortnightly Pay ATO PAYROLL 103235887819         |            | $5679.21| $44426.28   |\n",
      "| 24/08/2025 | PAY RUN ACME CORP PTY LTD 0958498775381           | $4455.48   |         | $38747.07   |\n",
      "| 24/08/2025 | Salary Payment ATO 31715538641491                | $7951.93   |         | $34291.93   |\n",
      "| 23/08/2025 | Online Purchase amazon.com.au                    | $83.78     |         | $26309.68   |\n",
      "| 22/08/2025 | Salary Payment ATO 94514P8040207                 |            | $8013.70| $26423.46   |\n",
      "| 20/08/2025 | Transfer To Vicks Account NatBank 54381P99641102  | $2345.10   |         | $24049.76   |\n",
      "| 20/08/2025 | Salary Payment ATO 94514P8040207                 |            | $3541.27| $22754.86   |\n",
      "| 19/08/2025 | Transfer To Westem Port Marina NatBank From Tod   | $726.48    |         | $19213.59   |\n",
      "| 18/08/2025 | Subscription Netflix 33856877385123              | $201.14    |         | $19940.07   |\n",
      "| 18/08/2025 | Contactless Payment CINEMA CARINS QLD             | $211.28    |         | $19728.81   |\n",
      "| 18/08/2025 | Auto Payment UTILITIES Red Energy 15107P2171655   | $33.24     |         | $20352.40   |\n",
      "| 17/08/2025 | Contactless Payment Restaurant MACKAY OLD         | $145.70    |         | $20385.73   |\n",
      "| 17/08/2025 | Fortnightly Pay ATO PAYROLL 3635879254998        |            | $7201.19| $20531.43   |\n",
      "| 14/08/2025 | Centrlink Payment JobSeeker 59032P50000878        | $27.06     | $2241.39| $13330.24   |\n",
      "| 14/08/2025 | International Transaction Fee                    | $27.06     |         | $11088.85   |\n",
      "| 13/08/2025 | Equipment Purchase OfficeMax Australia 13554P413  | $478.86    |         | $11115.91   |\n",
      "| 13/08/2025 | International ATM USA                            | $280.71    |         | $11594.77   |\n",
      "| 11/08/2025 | Dividend Payment PREMIUM CORP PTY LTD 735354P18...|            | $6395.00| $11855.48   |\n",
      "| 10/08/2025 | Invoice Payment HARVEY NORMAN FLAGSHIP PTY LTD    | $229.39    |         | $5460.39    |\n",
      "| 10/08/2025 | Online Purchase ebay.com.au                       | $257.95    |         | $5689.78    |\n",
      "| 10/08/2025 | Subscription Spotify Monthly                     | $180.22    |         | $5947.73    |\n",
      "| 09/08/2025 | International Transaction 68688P8141679         | $33.83     |         | $6133.95    |\n",
      "| 08/08/2025\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Deterministic generation config with multi-turn support\n",
    "generation_config = dict(\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False  # Pure greedy decoding for deterministic output\n",
    ")\n",
    "\n",
    "# Clear CUDA cache before generation\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Generate response using InternVL3 API\n",
    "print(\"ü§ñ Generating response with InternVL3-8B (8-bit quantized)...\")\n",
    "print(f\"üíæ GPU Memory before generation:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    allocated = torch.cuda.memory_allocated(i) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(i) / 1e9\n",
    "    print(f\"   GPU {i}: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved\")\n",
    "\n",
    "try:\n",
    "    # With device_map, model is not wrapped - call chat() directly\n",
    "    response, history = model.chat(\n",
    "        tokenizer, \n",
    "        pixel_values, \n",
    "        formatted_question, \n",
    "        generation_config,\n",
    "        history=None,\n",
    "        return_history=True\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Response generated successfully!\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INTERNVL3 RESPONSE:\")\n",
    "    print(\"=\"*60)\n",
    "    print(response)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during inference: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    # Clean up GPU memory\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Response saved to: internvl3_8b_quantized_vqa_output.txt\n",
      "üìÑ File size: 4168 bytes\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save response to file\n",
    "try:\n",
    "    output_path = Path(\"internvl3_8b_quantized_output.txt\")\n",
    "    \n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(response)\n",
    "    \n",
    "    print(f\"‚úÖ Response saved to: {output_path}\")\n",
    "    print(f\"üìÑ File size: {output_path.stat().st_size} bytes\")\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Error: 'response' variable not defined.\")\n",
    "    print(\"üí° Please run the previous cell first to generate the response.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation Example\n",
    "\n",
    "InternVL3 supports multi-turn conversations using the history parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Follow-up question: Can you provide the total amount from the document?\n",
      "\n",
      "============================================================\n",
      "FOLLOW-UP RESPONSE:\n",
      "============================================================\n",
      "![](https://i.imgur.com/4ZjKj5r.png)\n",
      "\n",
      "The total amount from the document is $61,339.58. This is the final balance shown on the bank statement.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Second turn conversation (uses history from first turn)\n",
    "try:\n",
    "    follow_up_question = \"Can you provide the total amount from the document?\"\n",
    "    print(f\"‚ùì Follow-up question: {follow_up_question}\")\n",
    "    \n",
    "    # Use history from previous turn\n",
    "    response2, history = model.chat(\n",
    "        tokenizer,\n",
    "        None,  # No new image for follow-up\n",
    "        follow_up_question,\n",
    "        generation_config,\n",
    "        history=history,  # Pass previous history\n",
    "        return_history=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FOLLOW-UP RESPONSE:\")\n",
    "    print(\"=\"*60)\n",
    "    print(response2)\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except NameError:\n",
    "    print(\"‚ùå Error: 'history' variable not defined.\")\n",
    "    print(\"üí° Please run the first generation cell to create conversation history.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during follow-up: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
