{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InternVL3 Simple Key-Value Extraction\n",
    "\n",
    "**Purpose:** Simplified single-image extraction demo for InternVL3 vision-language model\n",
    "\n",
    "This stripped-down notebook:\n",
    "- Loads a single image\n",
    "- Displays the image\n",
    "- Runs InternVL3 extraction\n",
    "- Shows the extracted key-value pairs\n",
    "\n",
    "Perfect for quick testing and understanding the extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# MINIMAL IMPORTS WITH COMPREHENSIVE FIELD METADATA\n# ============================================================================\n\nimport sys\nimport warnings\nfrom pathlib import Path\n\nfrom IPython.display import Image as IPImage\nfrom IPython.display import Markdown, display\nfrom PIL import Image\n\n# Add parent directory to Python path\nproject_root = Path.cwd().parent\nsys.path.insert(0, str(project_root))\n\n# Import essential modules with comprehensive field metadata\nfrom common.config import (\n    DATA_DIR,\n    DATE_FIELDS,\n    EXTRACTION_FIELDS,\n    FIELD_COUNT,\n    FIELD_DESCRIPTIONS,\n    # Field metadata - single source of truth\n    FIELD_INSTRUCTIONS,\n    FIELD_TYPES,\n    INTERNVL3_MODEL_PATH,\n    # Field groupings by type\n    MONETARY_FIELDS,\n    OUTPUT_DIR,\n    TEXT_FIELDS,\n)\nfrom models.internvl3_processor import InternVL3Processor\n\n# Suppress warnings for cleaner output\nwarnings.filterwarnings(\"ignore\")\n\n# Schema-driven field configuration ready\nprint(\"‚úÖ Simple InternVL3 Key-Value Extractor Ready\")\nprint(f\"üìã Will extract {FIELD_COUNT} fields from business documents\")\nprint(f\"üí∞ Monetary fields: {len(MONETARY_FIELDS)}\")\nprint(f\"üìÖ Date fields: {len(DATE_FIELDS)}\")\nprint(f\"üî§ Text fields: {len(TEXT_FIELDS)}\")\nprint(\"‚ú® All configurations loaded from schema - Phase 2 complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INITIALIZE INTERNVL3 MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üöÄ Initializing InternVL3 Model...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize processor\n",
    "processor = InternVL3Processor(model_path=INTERNVL3_MODEL_PATH)\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"üìç Model path: {INTERNVL3_MODEL_PATH}\")\n",
    "print(f\"üéØ Ready to extract {FIELD_COUNT} business fields\")\n",
    "\n",
    "# Show extraction fields\n",
    "print(\"\\nüìã Fields to extract:\")\n",
    "for i, field in enumerate(EXTRACTION_FIELDS, 1):\n",
    "    print(f\"  {i:2d}. {field}\")\n",
    "    if i == 5:  # Show first 5 fields then ellipsis\n",
    "        print(f\"  ... and {FIELD_COUNT - 5} more fields\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SELECT IMAGE TO PROCESS\n",
    "# ============================================================================\n",
    "\n",
    "# Default to first sample invoice\n",
    "# CHANGE THIS PATH to test different images\n",
    "image_path = Path(DATA_DIR) / \"synthetic_invoice_001.jpeg\"\n",
    "\n",
    "# Alternative: specify your own image path\n",
    "# image_path = Path(\"/path/to/your/image.jpeg\")\n",
    "\n",
    "# Verify image exists\n",
    "if not image_path.exists():\n",
    "    print(f\"‚ùå Image not found: {image_path}\")\n",
    "    print(f\"\\nüìÅ Available images in {DATA_DIR}:\")\n",
    "    for img in sorted(Path(DATA_DIR).glob(\"*.jpeg\"))[:5]:\n",
    "        print(f\"   - {img.name}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Selected image: {image_path.name}\")\n",
    "    print(f\"üìÅ Full path: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISPLAY THE IMAGE\n",
    "# ============================================================================\n",
    "\n",
    "if image_path.exists():\n",
    "    # Load image with PIL to get dimensions\n",
    "    pil_image = Image.open(image_path)\n",
    "    width, height = pil_image.size\n",
    "\n",
    "    print(f\"üìê Image dimensions: {width} x {height} pixels\")\n",
    "    print(f\"üìÑ Image type: {pil_image.format}\")\n",
    "    print(f\"üé® Image mode: {pil_image.mode}\")\n",
    "\n",
    "    # Display the image\n",
    "    print(\"\\nüñºÔ∏è Document Image:\")\n",
    "    display(IPImage(str(image_path), width=600))  # Adjust width as needed\n",
    "else:\n",
    "    print(\"‚ùå Cannot display - image file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üîç Running InternVL3 Extraction...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Process the image\n",
    "result = processor.process_single_image(str(image_path))\n",
    "\n",
    "# Extract key information\n",
    "extracted_data = result[\"extracted_data\"]\n",
    "processing_time = result[\"processing_time\"]\n",
    "extracted_count = result[\"extracted_fields_count\"]\n",
    "raw_response = result[\"raw_response\"]\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction completed in {processing_time:.2f} seconds\")\n",
    "print(f\"üìä Extracted {extracted_count}/{FIELD_COUNT} fields with values\")\n",
    "print(f\"üìù Response length: {len(raw_response)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# DISPLAY EXTRACTED KEY-VALUE PAIRS WITH FIELD METADATA\n# ============================================================================\n\ndisplay(Markdown(\"## üìã Extracted Key-Value Pairs\"))\n\n# Group fields by extraction status and type\nextracted_fields = {}\nmissing_fields = []\nfield_type_stats = {}\n\nfor field in EXTRACTION_FIELDS:\n    value = extracted_data.get(field, \"N/A\")\n    if value != \"N/A\" and value:\n        extracted_fields[field] = value\n    else:\n        missing_fields.append(field)\n\n    # Track field type statistics\n    field_type = FIELD_TYPES[field]\n    if field_type not in field_type_stats:\n        field_type_stats[field_type] = {\"extracted\": 0, \"total\": 0}\n    field_type_stats[field_type][\"total\"] += 1\n    if value != \"N/A\" and value:\n        field_type_stats[field_type][\"extracted\"] += 1\n\n# Display extracted fields grouped by type\nif extracted_fields:\n    display(Markdown(\"### ‚úÖ Successfully Extracted Fields:\"))\n\n    # Group by field type for display\n    monetary_extracted = {k: v for k, v in extracted_fields.items() if k in MONETARY_FIELDS}\n    date_extracted = {k: v for k, v in extracted_fields.items() if k in DATE_FIELDS}\n    text_extracted = {k: v for k, v in extracted_fields.items() if k in TEXT_FIELDS}\n    other_extracted = {k: v for k, v in extracted_fields.items() \n                      if k not in MONETARY_FIELDS and k not in DATE_FIELDS and k not in TEXT_FIELDS}\n\n    if monetary_extracted:\n        print(\"üí∞ MONETARY FIELDS:\")\n        print(\"-\" * 60)\n        for field, value in monetary_extracted.items():\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"üí∞ {field:<20} : {value}\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n    if date_extracted:\n        print(\"üìÖ DATE FIELDS:\")\n        print(\"-\" * 60)\n        for field, value in date_extracted.items():\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"üìÖ {field:<20} : {value}\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n    if text_extracted:\n        print(\"üî§ TEXT FIELDS:\")\n        print(\"-\" * 60)\n        for field, value in text_extracted.items():\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"üî§ {field:<20} : {value}\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n    if other_extracted:\n        print(\"üîç OTHER FIELDS:\")\n        print(\"-\" * 60)\n        for field, value in other_extracted.items():\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"üîç {field:<20} : {value}\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n# Display missing fields grouped by type\nif missing_fields:\n    display(Markdown(\"### ‚ùå Fields Not Found:\"))\n\n    monetary_missing = [f for f in missing_fields if f in MONETARY_FIELDS]\n    date_missing = [f for f in missing_fields if f in DATE_FIELDS]\n    text_missing = [f for f in missing_fields if f in TEXT_FIELDS]\n    other_missing = [f for f in missing_fields \n                    if f not in MONETARY_FIELDS and f not in DATE_FIELDS and f not in TEXT_FIELDS]\n\n    if monetary_missing:\n        print(\"üí∞ MISSING MONETARY FIELDS:\")\n        print(\"-\" * 60)\n        for field in monetary_missing:\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"‚ùå {field:<20} : N/A\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n    if date_missing:\n        print(\"üìÖ MISSING DATE FIELDS:\")\n        print(\"-\" * 60)\n        for field in date_missing:\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"‚ùå {field:<20} : N/A\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n    if text_missing:\n        print(\"üî§ MISSING TEXT FIELDS:\")\n        print(\"-\" * 60)\n        for field in text_missing:\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"‚ùå {field:<20} : N/A\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n    if other_missing:\n        print(\"üîç MISSING OTHER FIELDS:\")\n        print(\"-\" * 60)\n        for field in other_missing:\n            field_type = FIELD_TYPES[field]\n            description = (\n                FIELD_DESCRIPTIONS[field][:40] + \"...\"\n                if len(FIELD_DESCRIPTIONS[field]) > 40\n                else FIELD_DESCRIPTIONS[field]\n            )\n            print(f\"‚ùå {field:<20} : N/A\")\n            print(f\"   üìù {field_type:<15} | {description}\")\n            print()\n\n# Enhanced summary statistics with field type breakdown\ndisplay(Markdown(\"### üìä Extraction Summary:\"))\nprint(f\"Total fields expected:    {FIELD_COUNT}\")\nprint(f\"Fields with values:       {len(extracted_fields)}\")\nprint(f\"Missing fields:           {len(missing_fields)}\")\nprint(f\"Extraction rate:          {(len(extracted_fields) / FIELD_COUNT) * 100:.1f}%\")\nprint(f\"Processing time:          {processing_time:.2f} seconds\")\n\nprint(\"\\nüìà Field Type Performance:\")\nprint(\"-\" * 50)\nfor field_type, stats in field_type_stats.items():\n    rate = (stats[\"extracted\"] / stats[\"total\"]) * 100 if stats[\"total\"] > 0 else 0\n    print(\n        f\"{field_type.upper():<15} : {stats['extracted']}/{stats['total']} ({rate:.1f}%)\"\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OPTIONAL: VIEW RAW RESPONSE\n",
    "# ============================================================================\n",
    "\n",
    "# Uncomment the lines below to see the raw model response\n",
    "\n",
    "# display(Markdown(\"## üìù Raw Model Response\"))\n",
    "# print(\"Raw output from InternVL3:\")\n",
    "# print(\"=\" * 50)\n",
    "# print(raw_response)\n",
    "# print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# QUICK TEST WITH DIFFERENT IMAGE (USING DYNAMIC FIELD METADATA)\n# ============================================================================\n\n# This cell allows you to quickly test another image without re-running everything\n\n\ndef quick_extract(image_file):\n    \"\"\"Quick extraction function for testing multiple images with field metadata.\"\"\"\n    print(f\"\\nüîç Processing: {Path(image_file).name}\")\n    print(\"=\" * 50)\n\n    # Check if file exists\n    if not Path(image_file).exists():\n        print(f\"‚ùå File not found: {image_file}\")\n        return\n\n    # Process image\n    result = processor.process_single_image(str(image_file))\n\n    # Extract key information\n    extracted_data = result[\"extracted_data\"]\n    processing_time = result[\"processing_time\"]\n    extracted_count = result[\"extracted_fields_count\"]\n\n    print(f\"\\n‚úÖ Extraction completed in {processing_time:.2f} seconds\")\n    print(f\"üìä Extracted {extracted_count}/{FIELD_COUNT} fields with values\\n\")\n\n    # Group fields by extraction status and type\n    extracted_fields = {}\n    missing_fields = []\n    field_type_stats = {}\n\n    for field in EXTRACTION_FIELDS:\n        value = extracted_data.get(field, \"N/A\")\n        if value != \"N/A\" and value:\n            extracted_fields[field] = value\n        else:\n            missing_fields.append(field)\n\n        # Track field type statistics\n        field_type = FIELD_TYPES[field]\n        if field_type not in field_type_stats:\n            field_type_stats[field_type] = {\"extracted\": 0, \"total\": 0}\n        field_type_stats[field_type][\"total\"] += 1\n        if value != \"N/A\" and value:\n            field_type_stats[field_type][\"extracted\"] += 1\n\n    # Display extracted fields grouped by type\n    if extracted_fields:\n        print(\"‚úÖ Successfully Extracted Fields:\")\n        print(\"-\" * 60)\n\n        # Group by field type for display\n        monetary_extracted = {k: v for k, v in extracted_fields.items() if k in MONETARY_FIELDS}\n        date_extracted = {k: v for k, v in extracted_fields.items() if k in DATE_FIELDS}\n        text_extracted = {k: v for k, v in extracted_fields.items() if k in TEXT_FIELDS}\n        other_extracted = {k: v for k, v in extracted_fields.items() \n                          if k not in MONETARY_FIELDS and k not in DATE_FIELDS and k not in TEXT_FIELDS}\n\n        if monetary_extracted:\n            print(\"üí∞ MONETARY:\")\n            for field, value in monetary_extracted.items():\n                field_type = FIELD_TYPES[field]\n                print(f\"üí∞ {field:<20} : {value} ({field_type})\")\n\n        if date_extracted:\n            print(\"\\nüìÖ DATE:\")\n            for field, value in date_extracted.items():\n                field_type = FIELD_TYPES[field]\n                print(f\"üìÖ {field:<20} : {value} ({field_type})\")\n\n        if text_extracted:\n            print(\"\\nüî§ TEXT:\")\n            for field, value in text_extracted.items():\n                field_type = FIELD_TYPES[field]\n                print(f\"üî§ {field:<20} : {value} ({field_type})\")\n\n        if other_extracted:\n            print(\"\\nüîç OTHER:\")\n            for field, value in other_extracted.items():\n                field_type = FIELD_TYPES[field]\n                print(f\"üîç {field:<20} : {value} ({field_type})\")\n\n    # Display missing fields by type\n    if missing_fields:\n        print(\"\\n‚ùå Fields Not Found:\")\n        print(\"-\" * 60)\n\n        monetary_missing = [f for f in missing_fields if f in MONETARY_FIELDS]\n        date_missing = [f for f in missing_fields if f in DATE_FIELDS]\n        text_missing = [f for f in missing_fields if f in TEXT_FIELDS]\n        other_missing = [f for f in missing_fields \n                        if f not in MONETARY_FIELDS and f not in DATE_FIELDS and f not in TEXT_FIELDS]\n\n        if monetary_missing:\n            print(\"üí∞ MISSING MONETARY:\")\n            for field in monetary_missing:\n                field_type = FIELD_TYPES[field]\n                print(f\"‚ùå {field:<20} : N/A ({field_type})\")\n\n        if date_missing:\n            print(\"\\nüìÖ MISSING DATE:\")\n            for field in date_missing:\n                field_type = FIELD_TYPES[field]\n                print(f\"‚ùå {field:<20} : N/A ({field_type})\")\n\n        if text_missing:\n            print(\"\\nüî§ MISSING TEXT:\")\n            for field in text_missing:\n                field_type = FIELD_TYPES[field]\n                print(f\"‚ùå {field:<20} : N/A ({field_type})\")\n\n        if other_missing:\n            print(\"\\nüîç MISSING OTHER:\")\n            for field in other_missing:\n                field_type = FIELD_TYPES[field]\n                print(f\"‚ùå {field:<20} : N/A ({field_type})\")\n\n    # Enhanced summary statistics\n    print(\"\\nüìä Extraction Summary:\")\n    print(\"-\" * 60)\n    print(f\"Total fields expected:    {FIELD_COUNT}\")\n    print(f\"Fields with values:       {len(extracted_fields)}\")\n    print(f\"Missing fields:           {len(missing_fields)}\")\n    print(\n        f\"Extraction rate:          {(len(extracted_fields) / FIELD_COUNT) * 100:.1f}%\"\n    )\n    print(f\"Processing time:          {processing_time:.2f} seconds\")\n\n    # Field type performance\n    print(\"\\nüìà Field Type Performance:\")\n    for field_type, stats in field_type_stats.items():\n        rate = (stats[\"extracted\"] / stats[\"total\"]) * 100 if stats[\"total\"] > 0 else 0\n        print(\n            f\"   {field_type.upper():<12} : {stats['extracted']}/{stats['total']} ({rate:.1f}%)\"\n        )\n\n    return extracted_data\n\n\n# Example: Test with another invoice\n# Uncomment and modify the path below to test\n# test_result = quick_extract(Path(DATA_DIR) / \"synthetic_invoice_002.jpeg\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# BATCH PROCESS ALL JPEGS AND CREATE CSV (WITH VRAM MANAGEMENT & FIELD METADATA)\n# ============================================================================\n\nimport gc\nfrom datetime import datetime\n\nimport pandas as pd\nimport torch\n\nprint(\"üöÄ Batch Processing All JPEG Images with VRAM Management & Field Metadata\")\nprint(\"=\" * 70)\n\n# Import GPU optimization utilities\nfrom common.gpu_optimization import (\n    clear_model_caches,\n    comprehensive_memory_cleanup,\n    handle_memory_fragmentation,\n)\n\n# Find all JPEG files in DATA_DIR\njpeg_files = sorted(Path(DATA_DIR).glob(\"*.jpeg\"))\nprint(f\"üìÅ Found {len(jpeg_files)} JPEG files to process\")\n\n# Determine batch size based on model\nis_8b = \"8B\" in str(INTERNVL3_MODEL_PATH)\nbatch_size = 1 if is_8b else 2  # Conservative batch sizes for V100\nprint(f\"üéØ Using batch size: {batch_size} (Model: {'8B' if is_8b else '2B'})\")\nprint(\"‚ö° VRAM optimization: ENABLED\")\nprint(f\"üìã Field configuration: {FIELD_COUNT} extraction fields\")\nprint()\n\nif jpeg_files:\n    # Initialize results list and comprehensive statistics\n    all_results = []\n    global_field_type_stats = {}\n\n    # Initialize field type statistics\n    for field_type in set(FIELD_TYPES.values()):\n        global_field_type_stats[field_type] = {\"extracted\": 0, \"total\": 0}\n\n    # Process images in batches for better memory management\n    for batch_idx in range(0, len(jpeg_files), batch_size):\n        batch_end = min(batch_idx + batch_size, len(jpeg_files))\n        batch_files = jpeg_files[batch_idx:batch_end]\n\n        print(\n            f\"\\n[Batch {batch_idx // batch_size + 1}] Processing images {batch_idx + 1}-{batch_end} of {len(jpeg_files)}\"\n        )\n\n        # Pre-batch memory cleanup\n        if batch_idx > 0:  # Skip cleanup before first batch\n            handle_memory_fragmentation(threshold_gb=1.0, aggressive=True)\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                torch.cuda.synchronize()\n\n        # Process each image in the batch\n        for image_file in batch_files:\n            print(f\"  üìÑ Processing: {image_file.name}\")\n\n            try:\n                # Process the image with proper error handling\n                result = processor.process_single_image(str(image_file))\n                extracted_data = result[\"extracted_data\"]\n\n                # Create row dictionary with image name first\n                row = {\"image_name\": image_file.name}\n\n                # Add all fields in alphabetical order as requested\n                # Use \"NOT_FOUND\" instead of \"N/A\" to prevent pandas conversion to NaN\n                for field in sorted(EXTRACTION_FIELDS):\n                    value = extracted_data.get(field, \"N/A\")\n                    # Replace \"N/A\" with \"NOT_FOUND\" to prevent pandas NaN conversion\n                    if value == \"N/A\" or value == \"\" or value is None:\n                        row[field] = \"NOT_FOUND\"\n                    else:\n                        row[field] = value\n\n                    # Update global statistics by field type\n                    field_type = FIELD_TYPES[field]\n                    global_field_type_stats[field_type][\"total\"] += 1\n\n                    # Count extractions (not N/A or NOT_FOUND)\n                    if value not in [\"N/A\", \"\", None]:\n                        global_field_type_stats[field_type][\"extracted\"] += 1\n\n                all_results.append(row)\n\n                # Show quick stats\n                extracted_count = sum(\n                    1 for v in extracted_data.values() if v not in [\"N/A\", \"\", None]\n                )\n                print(f\"     ‚úÖ Extracted {extracted_count}/{FIELD_COUNT} fields\")\n\n            except torch.cuda.OutOfMemoryError as oom_error:\n                print(\"     ‚ö†Ô∏è OOM Error - Attempting recovery...\")\n\n                # Emergency cleanup\n                if torch.cuda.is_available():\n                    torch.cuda.empty_cache()\n                    torch.cuda.synchronize()\n                clear_model_caches(processor.model, processor.tokenizer)\n                handle_memory_fragmentation(threshold_gb=0.5, aggressive=True)\n                gc.collect()\n\n                # Add error row with all ERROR_OOM values\n                row = {\"image_name\": image_file.name}\n                for field in sorted(EXTRACTION_FIELDS):\n                    row[field] = \"ERROR_OOM\"\n                all_results.append(row)\n\n            except Exception as e:\n                print(f\"     ‚ùå Error: {e}\")\n                # Add error row with all NOT_FOUND values\n                row = {\"image_name\": image_file.name}\n                for field in sorted(EXTRACTION_FIELDS):\n                    row[field] = \"NOT_FOUND\"\n                all_results.append(row)\n\n        # Post-batch cleanup - CRITICAL for V100\n        if torch.cuda.is_available():\n            # Comprehensive cleanup after each batch\n            comprehensive_memory_cleanup(processor.model, processor.tokenizer)\n\n            # Extra aggressive cleanup for 8B model\n            if is_8b:\n                handle_memory_fragmentation(threshold_gb=0.5, aggressive=True)\n                torch.cuda.empty_cache()\n                torch.cuda.synchronize()\n                print(\n                    f\"  üßπ Aggressive memory cleanup after batch {batch_idx // batch_size + 1}\"\n                )\n            else:\n                print(f\"  üßπ Memory cleanup after batch {batch_idx // batch_size + 1}\")\n\n        # Force garbage collection\n        gc.collect()\n\n    # Create DataFrame with alphabetical field ordering\n    print(\"\\nüìä Creating DataFrame with alphabetical field ordering...\")\n    df = pd.DataFrame(all_results)\n\n    # Ensure columns are in correct order: image_name first, then all fields alphabetically\n    column_order = [\"image_name\"] + sorted(EXTRACTION_FIELDS)\n    df = df[column_order]\n\n    # Generate timestamp for unique filename\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    csv_filename = f\"internvl3_extraction_results_{timestamp}.csv\"\n    csv_path = Path(OUTPUT_DIR) / csv_filename\n\n    # Ensure output directory exists\n    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n\n    # Save main CSV with explicit na_rep to prevent NaN conversion\n    df.to_csv(csv_path, index=False, na_rep=\"NOT_FOUND\")\n\n    # Create field metadata CSV for reference\n    field_metadata = []\n    for field in sorted(EXTRACTION_FIELDS):\n        field_metadata.append(\n            {\n                \"field_name\": field,\n                \"field_type\": FIELD_TYPES[field],\n                \"description\": FIELD_DESCRIPTIONS[field],\n                \"instruction\": FIELD_INSTRUCTIONS[field],\n            }\n        )\n\n    metadata_df = pd.DataFrame(field_metadata)\n    metadata_csv_path = Path(OUTPUT_DIR) / f\"field_metadata_{timestamp}.csv\"\n    metadata_df.to_csv(metadata_csv_path, index=False)\n\n    print(\"\\nüíæ Files saved:\")\n    print(f\"   üìä Main results: {csv_filename}\")\n    print(f\"   üìã Field metadata: field_metadata_{timestamp}.csv\")\n    print(\"   üìù Missing values shown as: NOT_FOUND (prevents pandas NaN conversion)\")\n\n    # Enhanced summary statistics with field metadata\n    print(\"\\nüìà Comprehensive Extraction Analysis:\")\n    print(\"=\" * 70)\n    print(f\"Total images processed: {len(jpeg_files)}\")\n    print(\n        f\"Total columns in CSV: {len(df.columns)} (1 image_name + {FIELD_COUNT} fields)\"\n    )\n\n    # Count OOM errors if any\n    oom_count = df.apply(lambda row: (row == \"ERROR_OOM\").any(), axis=1).sum()\n    if oom_count > 0:\n        print(f\"‚ö†Ô∏è OOM errors encountered: {oom_count} images\")\n\n    # Field type performance analysis\n    print(\"\\nüìä Field Type Performance Analysis:\")\n    print(\"-\" * 70)\n    for field_type, stats in global_field_type_stats.items():\n        if stats[\"total\"] > 0:\n            rate = (stats[\"extracted\"] / stats[\"total\"]) * 100\n            print(\n                f\"{field_type.upper():<15} : {stats['extracted']:,}/{stats['total']:,} fields ({rate:.1f}%)\"\n            )\n\n    # Individual field performance analysis\n    individual_field_stats = {}\n    for field in sorted(EXTRACTION_FIELDS):\n        valid_rows = df[field].apply(lambda x: x not in [\"NOT_FOUND\", \"ERROR_OOM\", \"\"])\n        extracted = valid_rows.sum()\n        total_valid = df[field].apply(lambda x: x != \"ERROR_OOM\").sum()\n        if total_valid > 0:\n            individual_field_stats[field] = (extracted / total_valid) * 100\n        else:\n            individual_field_stats[field] = 0\n\n    sorted_fields = sorted(\n        individual_field_stats.items(), key=lambda x: x[1], reverse=True\n    )\n\n    print(\"\\nüèÜ Top 5 Best Performing Fields:\")\n    print(\"-\" * 70)\n    for field, rate in sorted_fields[:5]:\n        field_type = FIELD_TYPES[field]\n        print(f\"   {field:<25} : {rate:.1f}% success | {field_type}\")\n\n    print(\"\\n‚ö†Ô∏è Top 5 Most Challenging Fields:\")\n    print(\"-\" * 70)\n    for field, rate in sorted_fields[-5:]:\n        field_type = FIELD_TYPES[field]\n        print(f\"   {field:<25} : {rate:.1f}% success | {field_type}\")\n\n    # Display CSV structure\n    print(\"\\nüìã CSV Structure:\")\n    print(\"-\" * 70)\n    print(\"Column order: image_name + all fields in alphabetical order\")\n    print(f\"Fields (alphabetical): {', '.join(sorted(EXTRACTION_FIELDS)[:5])}...\")\n    print(\"Missing values: NOT_FOUND (readable, won't convert to NaN)\")\n\n    # Final memory cleanup\n    if torch.cuda.is_available():\n        print(\"\\nüßπ Final memory cleanup...\")\n        comprehensive_memory_cleanup(processor.model, processor.tokenizer)\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n\n        # Show final memory status\n        free_memory = (\n            torch.cuda.get_device_properties(0).total_memory\n            - torch.cuda.memory_allocated()\n        )\n        print(f\"‚úÖ Free VRAM after processing: {free_memory / 1e9:.2f} GB\")\n\n    print(f\"\\nüéâ Batch processing completed! Check output directory: {OUTPUT_DIR}\")\n\nelse:\n    print(\"‚ùå No JPEG files found in DATA_DIR\")\n    print(f\"   Please check: {DATA_DIR}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Vision Notebooks)",
   "language": "python",
   "name": "vision_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}