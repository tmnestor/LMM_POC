{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Imports and Configuration\nfrom pathlib import Path\nimport pandas as pd\nfrom PIL import Image\nfrom IPython.display import display\nfrom rich import print as rprint\nfrom rich.console import Console\nfrom rich.table import Table\n\n# Import evaluation system and document-aware field loader\nfrom common.simple_model_evaluator import SimpleModelEvaluator\nfrom common.batch_processor import load_document_field_definitions\n\nconsole = Console()\n\n# Base directories\nBASE_DIR = Path('/home/jovyan/nfs_share/tod')\nCSV_PATH = BASE_DIR / \"evaluation_data\" / \"ground_truth.csv\"\nUPDATES_CSV_PATH = BASE_DIR / \"evaluation_data\" / \"ground_truth_updates.csv\"\nIMAGE_DIR = BASE_DIR / \"evaluation_data\"\nOUTPUT_DIR = BASE_DIR / \"output\" / \"csv\"\n\n# Initialize evaluator\nevaluator = SimpleModelEvaluator()\n\n# Load document-aware field definitions\ndoc_field_definitions = load_document_field_definitions()\n\nprint(f\"Ground Truth CSV: {CSV_PATH}\")\nprint(f\"Updates CSV: {UPDATES_CSV_PATH}\")\nprint(f\"Image Directory: {IMAGE_DIR}\")\nprint(f\"Output Directory: {OUTPUT_DIR}\")\nprint(f\"Ground truth exists: {CSV_PATH.exists()}\")\nprint(f\"Updates file exists: {UPDATES_CSV_PATH.exists()}\")\nprint(f\"Image dir exists: {IMAGE_DIR.exists()}\")\nprint(f\"Output dir exists: {OUTPUT_DIR.exists()}\")\nprint(\"✅ Evaluation system loaded\")\nprint(f\"✅ Document-aware field definitions loaded:\")\nprint(f\"   - Invoice: {len(doc_field_definitions['invoice'])} fields\")\nprint(f\"   - Receipt: {len(doc_field_definitions['receipt'])} fields\")\nprint(f\"   - Bank Statement: {len(doc_field_definitions['bank_statement'])} fields\")"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available model result files:\n",
      "1. internvl3_non_quantized_batch_results_20250930_234054.csv\n",
      "2. internvl3_batch_results_20250930_234346.csv\n",
      "3. llama_batch_results_20250930_235426.csv\n",
      "4. internvl3_non_quantized_batch_results_20251001_014926.csv\n",
      "5. llama_batch_results_20251001_025145.csv\n",
      "6. llama_batch_results_20251001_030022.csv\n",
      "7. internvl3_non_quantized_batch_results_20251001_054744.csv\n",
      "8. internvl3_non_quantized_batch_results_20251005_233614.csv\n",
      "9. internvl3_batch_results_20251005_234335.csv\n",
      "10. internvl3_non_quantized_batch_results_20251006_200849.csv\n",
      "11. internvl3_non_quantized_batch_results_20251006_213136.csv\n",
      "\n",
      "Using: internvl3_non_quantized_batch_results_20251006_213136.csv\n",
      "Loaded 9 model predictions\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Model Results (Optional - for comparison)\n",
    "# Find available model result files\n",
    "model_files = list(OUTPUT_DIR.glob(\"*batch_results*.csv\"))\n",
    "\n",
    "if model_files:\n",
    "    print(\"\\nAvailable model result files:\")\n",
    "    for i, f in enumerate(model_files, 1):\n",
    "        print(f\"{i}. {f.name}\")\n",
    "    \n",
    "    # Select which model results to load (default: most recent)\n",
    "    MODEL_RESULTS_FILE = max(model_files, key=lambda x: x.stat().st_mtime)  # Most recent\n",
    "    print(f\"\\nUsing: {MODEL_RESULTS_FILE.name}\")\n",
    "    \n",
    "    # Load model results\n",
    "    model_df = pd.read_csv(MODEL_RESULTS_FILE)\n",
    "    print(f\"Loaded {len(model_df)} model predictions\")\n",
    "else:\n",
    "    print(\"⚠️ No model result files found in output/csv/\")\n",
    "    print(\"Comparison feature will be disabled.\")\n",
    "    model_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with: image_003.png\n",
      "Image exists: True\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define Image Name\n",
    "# Change this to the image you want to inspect/edit\n",
    "IMAGE_NAME = 'image_003.png'\n",
    "\n",
    "image_path = IMAGE_DIR / IMAGE_NAME\n",
    "print(f\"Working with: {IMAGE_NAME}\")\n",
    "print(f\"Image exists: {image_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">📋 Document Type: BANK_STATEMENT</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m📋 Document Type: BANK_STATEMENT\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">📊 Evaluating </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #008080; text-decoration-color: #008080\"> bank_statement-specific fields</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m📊 Evaluating \u001b[0m\u001b[1;36m7\u001b[0m\u001b[36m bank_statement-specific fields\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Field-by-Field Comparison (Document-Aware Evaluation)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m────────────────────────────── \u001b[0m\u001b[1;34mField-by-Field Comparison \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mDocument-Aware Evaluation\u001b[0m\u001b[1;34m)\u001b[0m\u001b[92m ──────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Field                        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Ground Truth                       </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Model Prediction                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Match   </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> DOCUMENT_TYPE                </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> BANK_STATEMENT                     </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> BANK_STATEMENT                    </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ✅ 1.0  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> STATEMENT_DATE_RANGE         </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 03/05/2025 to 10/05/2025           </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 03/05/2025 to 10/05/2025          </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ✅ 1.0  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> LINE_ITEM_DESCRIPTIONS       </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> ONLINE PURCHASE AMAZON AU | EFTPO  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> ONLINE PURCHASE AMAZON AU | EFTPO </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ❌ 0.0  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> TRANSACTION_DATES            </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> 03/05/2025 | 04/05/2025 | 05/05/2  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> 03/05/2025 | 04/05/2025 | 05/05/2 </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ❌ 0.0  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> TRANSACTION_AMOUNTS_PAID     </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> $288.03 | $22.50 | $114.66 | $187  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> $288.03 | $22.50 | $114.66 | NOT_ </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ❌ 0.0  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> TRANSACTION_AMOUNTS_RECEIVED </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> NOT_FOUND                          </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> NOT_FOUND | $33497.47 | NOT_FOUND </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ✅ 1.0  </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> ACCOUNT_BALANCE              </span>│<span style=\"color: #008000; text-decoration-color: #008000\"> $13387.44 | $13344.94 | $13230.27  </span>│<span style=\"color: #808000; text-decoration-color: #808000\"> $13367.44 | $13344.94 | $13230.27 </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> ✅ 1.0  </span>│\n",
       "└──────────────────────────────┴────────────────────────────────────┴───────────────────────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mField                       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mGround Truth                      \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mModel Prediction                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMatch  \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36mDOCUMENT_TYPE               \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mBANK_STATEMENT                    \u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mBANK_STATEMENT                   \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m✅ 1.0 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mSTATEMENT_DATE_RANGE        \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m03/05/2025 to 10/05/2025          \u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m03/05/2025 to 10/05/2025         \u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m✅ 1.0 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mLINE_ITEM_DESCRIPTIONS      \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mONLINE PURCHASE AMAZON AU | EFTPO \u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mONLINE PURCHASE AMAZON AU | EFTPO\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m❌ 0.0 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTRANSACTION_DATES           \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m03/05/2025 | 04/05/2025 | 05/05/2 \u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m03/05/2025 | 04/05/2025 | 05/05/2\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m❌ 0.0 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTRANSACTION_AMOUNTS_PAID    \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m$288.03 | $22.50 | $114.66 | $187 \u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m$288.03 | $22.50 | $114.66 | NOT_\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m❌ 0.0 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mTRANSACTION_AMOUNTS_RECEIVED\u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32mNOT_FOUND                         \u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33mNOT_FOUND | $33497.47 | NOT_FOUND\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m✅ 1.0 \u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mACCOUNT_BALANCE             \u001b[0m\u001b[36m \u001b[0m│\u001b[32m \u001b[0m\u001b[32m$13387.44 | $13344.94 | $13230.27 \u001b[0m\u001b[32m \u001b[0m│\u001b[33m \u001b[0m\u001b[33m$13367.44 | $13344.94 | $13230.27\u001b[0m\u001b[33m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m✅ 1.0 \u001b[0m\u001b[37m \u001b[0m│\n",
       "└──────────────────────────────┴────────────────────────────────────┴───────────────────────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">Overall Accuracy: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40.0</span><span style=\"font-weight: bold\">%</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1mOverall Accuracy: \u001b[0m\u001b[1;36m40.0\u001b[0m\u001b[1m%\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Correct Fields: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Correct Fields: \u001b[1;36m2\u001b[0m/\u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Missing Fields: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Missing Fields: \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Incorrect Fields: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Incorrect Fields: \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">Legend: ✅ Exact match </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">1.0</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> | ≈ Fuzzy match </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">≥</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">0.8</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> | ❌ No match </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">0.8</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[2mLegend: ✅ Exact match \u001b[0m\u001b[1;2m(\u001b[0m\u001b[1;2;36m1.0\u001b[0m\u001b[1;2m)\u001b[0m\u001b[2m | ≈ Fuzzy match \u001b[0m\u001b[1;2m(\u001b[0m\u001b[2m≥\u001b[0m\u001b[1;2;36m0.8\u001b[0m\u001b[1;2m)\u001b[0m\u001b[2m | ❌ No match \u001b[0m\u001b[1;2m(\u001b[0m\u001b[2m<\u001b[0m\u001b[1;2;36m0.8\u001b[0m\u001b[1;2m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: Load CSV and Compare with Model Predictions (Using Document-Aware Evaluation)\n",
    "gt_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Find the row for this image\n",
    "gt_row = gt_df[gt_df['image_file'] == IMAGE_NAME]\n",
    "\n",
    "if gt_row.empty:\n",
    "    print(f\"⚠️ No ground truth row found for {IMAGE_NAME}\")\n",
    "    print(\"\\nAvailable images (first 10):\")\n",
    "    print(gt_df['image_file'].head(10).tolist())\n",
    "else:\n",
    "    # Get document type from ground truth or infer from DOCUMENT_TYPE field\n",
    "    if 'document_type' in gt_row.columns:\n",
    "        document_type = str(gt_row['document_type'].iloc[0]).upper()\n",
    "    elif 'DOCUMENT_TYPE' in gt_row.columns:\n",
    "        document_type = str(gt_row['DOCUMENT_TYPE'].iloc[0]).upper()\n",
    "    else:\n",
    "        # Can't determine document type - use all fields\n",
    "        console.print(f\"[yellow]⚠️ No document_type column found in ground truth CSV[/yellow]\")\n",
    "        console.print(f\"[yellow]⚠️ Available columns: {list(gt_row.columns)}[/yellow]\\n\")\n",
    "        skip_fields = {'image_name', 'image_file', 'processing_time', \n",
    "                       'field_count', 'found_fields', 'field_coverage', 'prompt_used', \n",
    "                       'timestamp', 'overall_accuracy', 'fields_extracted', 'fields_matched',\n",
    "                       'total_fields', 'inference_only'}\n",
    "        extraction_fields = [col for col in gt_df.columns if col not in skip_fields]\n",
    "        document_type = \"UNKNOWN\"\n",
    "    \n",
    "    # Get document-aware field list if we have a valid document type\n",
    "    if document_type != \"UNKNOWN\":\n",
    "        doc_type_lower = document_type.lower()\n",
    "        if doc_type_lower in doc_field_definitions:\n",
    "            extraction_fields = doc_field_definitions[doc_type_lower]\n",
    "            console.print(f\"[cyan]📋 Document Type: {document_type}[/cyan]\")\n",
    "            console.print(f\"[cyan]📊 Evaluating {len(extraction_fields)} {doc_type_lower}-specific fields[/cyan]\\n\")\n",
    "        else:\n",
    "            # Fallback to all fields if document type not recognized\n",
    "            skip_fields = {'image_name', 'image_file', 'document_type', 'DOCUMENT_TYPE', 'processing_time', \n",
    "                           'field_count', 'found_fields', 'field_coverage', 'prompt_used', \n",
    "                           'timestamp', 'overall_accuracy', 'fields_extracted', 'fields_matched',\n",
    "                           'total_fields', 'inference_only'}\n",
    "            extraction_fields = [col for col in gt_df.columns if col not in skip_fields]\n",
    "            console.print(f\"[yellow]⚠️ Unknown document type: {document_type}, using all fields[/yellow]\\n\")\n",
    "    \n",
    "    # Try to find model prediction\n",
    "    model_row = None\n",
    "    if model_df is not None:\n",
    "        # Try exact match first\n",
    "        model_row = model_df[model_df['image_name'] == IMAGE_NAME]\n",
    "        \n",
    "        # Try without extension if exact match fails\n",
    "        if model_row.empty:\n",
    "            image_stem = Path(IMAGE_NAME).stem\n",
    "            model_row = model_df[model_df['image_name'].str.contains(image_stem, na=False)]\n",
    "        \n",
    "        if model_row.empty:\n",
    "            print(f\"⚠️ No model prediction found for {IMAGE_NAME}\")\n",
    "            model_row = None\n",
    "        else:\n",
    "            model_row = model_row.iloc[0]  # Get first row as Series\n",
    "    \n",
    "    if model_row is not None:\n",
    "        # Use the evaluation system for proper comparison\n",
    "        console.rule(\"[bold blue]Field-by-Field Comparison (Document-Aware Evaluation)[/bold blue]\")\n",
    "        \n",
    "        # Prepare ground truth dict - ONLY document-aware fields\n",
    "        ground_truth = {field: str(gt_row[field].iloc[0]) for field in extraction_fields if field in gt_row.columns}\n",
    "        \n",
    "        # Prepare extracted data dict (from model) - ONLY document-aware fields\n",
    "        extracted_data = {field: str(model_row[field]) if field in model_row.index else \"NOT_FOUND\" \n",
    "                         for field in extraction_fields}\n",
    "        \n",
    "        # Run evaluation\n",
    "        eval_result = evaluator.evaluate_extraction(extracted_data, ground_truth, IMAGE_NAME)\n",
    "        \n",
    "        # Display comparison table with evaluation results\n",
    "        table = Table(show_header=True, header_style=\"bold magenta\")\n",
    "        table.add_column(\"Field\", style=\"cyan\", width=30)\n",
    "        table.add_column(\"Ground Truth\", style=\"green\", width=35)\n",
    "        table.add_column(\"Model Prediction\", style=\"yellow\", width=35)\n",
    "        table.add_column(\"Match\", style=\"white\", width=8)\n",
    "        \n",
    "        # Add rows with evaluation results - ONLY document-aware fields\n",
    "        for field in extraction_fields:\n",
    "            if field not in gt_row.columns:\n",
    "                continue\n",
    "                \n",
    "            gt_value = str(gt_row[field].iloc[0])[:33]  # Truncate for display\n",
    "            model_value = str(model_row[field])[:33] if field in model_row.index else \"NOT_FOUND\"\n",
    "            \n",
    "            # Determine match status by checking if field is in correct/incorrect/missing lists\n",
    "            if field in eval_result.missing_fields:\n",
    "                match_symbol = \"❌ 0.0\"\n",
    "            elif field in eval_result.incorrect_fields:\n",
    "                # Use evaluator's _values_match to check if it's a fuzzy match\n",
    "                full_gt = str(gt_row[field].iloc[0])\n",
    "                full_extracted = str(model_row[field]) if field in model_row.index else \"NOT_FOUND\"\n",
    "                is_match = evaluator._values_match(full_extracted, full_gt)\n",
    "                match_symbol = \"≈ 0.8\" if is_match else \"❌ 0.0\"\n",
    "            else:\n",
    "                # Field is in correct list (exact match)\n",
    "                match_symbol = \"✅ 1.0\"\n",
    "            \n",
    "            table.add_row(field, gt_value, model_value, match_symbol)\n",
    "        \n",
    "        console.print(table)\n",
    "        \n",
    "        # Display evaluation summary\n",
    "        accuracy_pct = eval_result.accuracy * 100\n",
    "        console.print(f\"\\n[bold]Overall Accuracy: {accuracy_pct:.1f}%[/bold]\")\n",
    "        console.print(f\"Correct Fields: {eval_result.correct_fields}/{eval_result.total_fields}\")\n",
    "        console.print(f\"Missing Fields: {len(eval_result.missing_fields)}\")\n",
    "        console.print(f\"Incorrect Fields: {len(eval_result.incorrect_fields)}\")\n",
    "        \n",
    "        console.print(\"\\n[dim]Legend: ✅ Exact match (1.0) | ≈ Fuzzy match (≥0.8) | ❌ No match (<0.8)[/dim]\")\n",
    "        console.rule()\n",
    "    else:\n",
    "        # No model predictions available - just show ground truth\n",
    "        console.rule(\"[bold blue]Ground Truth Data (Document-Aware Fields)[/bold blue]\")\n",
    "        print(f\"\\nGround truth for {IMAGE_NAME} ({document_type}):\")\n",
    "        print(\"=\" * 80)\n",
    "        for field in extraction_fields:\n",
    "            if field in gt_row.columns:\n",
    "                value = gt_row[field].iloc[0]\n",
    "                print(f\"{field:30s}: {value}\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: Edit Row Data\n# Modify the values below based on your inspection of the image\n\n# Get the row index\nrow_idx = gt_df[gt_df['image_file'] == IMAGE_NAME].index[0]\n\n# Mark that this row has been updated (for tracking)\nrow_updated = False\n\n# Uncomment and edit the fields you want to update:\n# gt_df.at[row_idx, 'SUPPLIER_NAME'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'BUSINESS_ADDRESS'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'BUSINESS_ABN'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'INVOICE_DATE'] = '24/08/2022'\n# row_updated = True\n\n# gt_df.at[row_idx, 'PAYER_NAME'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'PAYER_ADDRESS'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'STATEMENT_DATE_RANGE'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'GST_AMOUNT'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'IS_GST_INCLUDED'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'TOTAL_AMOUNT'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'LINE_ITEM_DESCRIPTIONS'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'TRANSACTION_DATES'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'LINE_ITEM_PRICES'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'LINE_ITEM_QUANTITIES'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'LINE_ITEM_TOTAL_PRICES'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'TRANSACTION_AMOUNTS_PAID'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'TRANSACTION_AMOUNTS_RECEIVED'] = 'New Value'\n# row_updated = True\n\n# gt_df.at[row_idx, 'ACCOUNT_BALANCE'] = 'New Value'\n# row_updated = True\n\n# Display updated row\nif row_updated:\n    print(f\"✅ Updated data for {IMAGE_NAME}:\")\n    print(\"=\" * 80)\n    updated_row = gt_df.loc[row_idx]\n    for col in gt_df.columns:\n        print(f\"{col:30s}: {updated_row[col]}\")\n    print(\"=\" * 80)\nelse:\n    print(f\"⚠️ No changes made to {IMAGE_NAME}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Save Updated Row to Updates File\n# Save ONLY the updated row to ground_truth_updates.csv\n\nif row_updated:\n    # Get the updated row\n    updated_row_df = gt_df.loc[[row_idx]]\n    \n    # Check if updates file exists\n    if UPDATES_CSV_PATH.exists():\n        # Load existing updates\n        existing_updates = pd.read_csv(UPDATES_CSV_PATH)\n        \n        # Check if this image already has an update entry\n        if IMAGE_NAME in existing_updates['image_file'].values:\n            # Replace existing update for this image\n            existing_updates = existing_updates[existing_updates['image_file'] != IMAGE_NAME]\n            updates_df = pd.concat([existing_updates, updated_row_df], ignore_index=True)\n            print(f\"✅ Replaced existing update for {IMAGE_NAME}\")\n        else:\n            # Append new update\n            updates_df = pd.concat([existing_updates, updated_row_df], ignore_index=True)\n            print(f\"✅ Added new update for {IMAGE_NAME}\")\n    else:\n        # Create new updates file\n        updates_df = updated_row_df\n        print(f\"✅ Created new updates file with {IMAGE_NAME}\")\n    \n    # Save updates file\n    updates_df.to_csv(UPDATES_CSV_PATH, index=False)\n    print(f\"✅ Saved to: {UPDATES_CSV_PATH}\")\n    print(f\"📊 Total updates in file: {len(updates_df)}\")\n    \n    print(f\"\\n⚠️ Original ground_truth.csv remains UNTOUCHED\")\nelse:\n    print(f\"⚠️ No updates to save (row_updated = False)\")"
  },
  {
   "cell_type": "code",
   "source": "# Cell 7: Copy Images of Updated Rows to Separate Location\n# Copies images corresponding to all rows in ground_truth_updates.csv\n\nimport shutil\n\n# Define destination directory for updated images\nUPDATED_IMAGES_DIR = BASE_DIR / \"evaluation_data\" / \"updated_images\"\n\nif UPDATES_CSV_PATH.exists():\n    # Load all updates\n    updates_df = pd.read_csv(UPDATES_CSV_PATH)\n    \n    # Create destination directory if it doesn't exist\n    UPDATED_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n    \n    print(f\"📁 Copying {len(updates_df)} updated images to: {UPDATED_IMAGES_DIR}\")\n    print(\"=\" * 80)\n    \n    copied_count = 0\n    missing_count = 0\n    \n    for idx, row in updates_df.iterrows():\n        image_file = row['image_file']\n        source_path = IMAGE_DIR / image_file\n        dest_path = UPDATED_IMAGES_DIR / image_file\n        \n        if source_path.exists():\n            shutil.copy2(source_path, dest_path)\n            print(f\"✅ Copied: {image_file}\")\n            copied_count += 1\n        else:\n            print(f\"❌ Missing: {image_file}\")\n            missing_count += 1\n    \n    print(\"=\" * 80)\n    print(f\"📊 Summary:\")\n    print(f\"   - Copied: {copied_count} images\")\n    print(f\"   - Missing: {missing_count} images\")\n    print(f\"   - Destination: {UPDATED_IMAGES_DIR}\")\nelse:\n    print(f\"⚠️ No updates file found at: {UPDATES_CSV_PATH}\")\n    print(f\"⚠️ Run Cell 6 first to create updates\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}