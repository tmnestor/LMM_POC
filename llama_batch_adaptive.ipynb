{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Llama Document-Type-Aware Adaptive Extraction\n",
    "\n",
    "Processes all images using multi-stage adaptive extraction:\n",
    "1. **Stage 0**: Classify document type (INVOICE/RECEIPT/BANK_STATEMENT)\n",
    "2. **Stage 1**: Classify structure (if BANK_STATEMENT: FLAT/GROUPED)\n",
    "3. **Stage 2**: Apply document-type and structure-specific extraction prompt\n",
    "\n",
    "Outputs compatible with model_comparison.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import gc\nimport json\nimport random\nimport time\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport yaml\nfrom PIL import Image\nfrom rich import print as rprint\nfrom rich.console import Console\nfrom rich.progress import track\nfrom transformers import AutoProcessor, MllamaForConditionalGeneration\n\n# Initialize console for rich output\nconsole = Console()\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\nrprint(\"[green]✅ Imports loaded[/green]\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# Environment-specific base paths\nENVIRONMENT_BASES = {\n    'sandbox': '/home/jovyan/nfs_share/tod',\n    'efs': '/efs/shared/PoC_data'\n}\nbase_data_path = ENVIRONMENT_BASES['sandbox']\n\nCONFIG = {\n    # Model settings\n    # 'MODEL_PATH': \"/efs/shared/PTM/Llama-3.2-11B-Vision-Instruct\",\n    'MODEL_PATH': \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\",\n    \n    # Data paths - Using base path for consistency\n    'DATA_DIR': f'{base_data_path}/LMM_POC/evaluation_data',\n    'GROUND_TRUTH': f'{base_data_path}/LMM_POC/evaluation_data/ground_truth.csv',\n    \n    # Prompt files - Using base path for consistency\n    'PROMPT_FILE_DOCTYPE': f'{base_data_path}/LMM_POC/prompts/document_type_detection.yaml',\n    'PROMPT_FILE_INVOICE': f'{base_data_path}/LMM_POC/prompts/generated/llama_invoice_prompt.yaml',\n    'PROMPT_FILE_RECEIPT': f'{base_data_path}/LMM_POC/prompts/generated/llama_receipt_prompt.yaml',\n    'PROMPT_FILE_BANK': f'{base_data_path}/LMM_POC/prompts/generated/llama_bank_statement_prompt.yaml',\n    \n    # Output directory - Using base path for consistency\n    'OUTPUT_DIR': f'{base_data_path}/LMM_POC/output',\n    \n    # Token limits\n    'MAX_NEW_TOKENS_DOCTYPE': 50,\n    'MAX_NEW_TOKENS_STRUCTURE': 50,\n    'MAX_NEW_TOKENS_EXTRACT': 2000,\n    \n    # Verbosity control\n    'VERBOSE': True,  # Show stage-by-stage progress\n    'SHOW_PROMPTS': False,  # Show actual prompts being used\n}\n\n# Create output directory\noutput_dir = Path(CONFIG['OUTPUT_DIR'])\noutput_dir.mkdir(exist_ok=True)\n\n# Timestamp for output files\nTIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\nrprint(\"[green]✅ Configuration loaded[/green]\")\nrprint(f\"[cyan]  Environment: {[k for k, v in ENVIRONMENT_BASES.items() if v == base_data_path][0]}[/cyan]\")\nrprint(f\"[cyan]  Base path: {base_data_path}[/cyan]\")\nrprint(f\"[cyan]  Output directory: {output_dir}[/cyan]\")\nrprint(f\"[cyan]  Timestamp: {TIMESTAMP}[/cyan]\")\nrprint(f\"[cyan]  Verbosity: {'ON' if CONFIG['VERBOSE'] else 'OFF'}[/cyan]\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">🔧 Loading Llama model...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m🔧 Loading Llama model\u001b[0m\u001b[1;32m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d99008965c4d15b3a040ff0bebbbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ Model loaded</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✅ Model loaded\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "rprint(\"[bold green]🔧 Loading Llama model...[/bold green]\")\n",
    "\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    CONFIG['MODEL_PATH'],\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(CONFIG['MODEL_PATH'])\n",
    "\n",
    "rprint(\"[green]✅ Model loaded[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Load All Prompts\n",
    "\n",
    "Loading prompts for:\n",
    "- Document type detection\n",
    "- Invoice extraction\n",
    "- Receipt extraction  \n",
    "- Bank statement extraction (flat and grouped variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ All prompts loaded</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✅ All prompts loaded\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  Document type detection: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">197</span><span style=\"color: #008080; text-decoration-color: #008080\"> chars</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  Document type detection: \u001b[0m\u001b[1;36m197\u001b[0m\u001b[36m chars\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  Invoice extraction: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span><span style=\"color: #008080; text-decoration-color: #008080\"> chars</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  Invoice extraction: \u001b[0m\u001b[1;36m2138\u001b[0m\u001b[36m chars\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  Receipt extraction: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2138</span><span style=\"color: #008080; text-decoration-color: #008080\"> chars</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  Receipt extraction: \u001b[0m\u001b[1;36m2138\u001b[0m\u001b[36m chars\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  Bank flat extraction: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3056</span><span style=\"color: #008080; text-decoration-color: #008080\"> chars</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  Bank flat extraction: \u001b[0m\u001b[1;36m3056\u001b[0m\u001b[36m chars\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  Bank grouped extraction: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3282</span><span style=\"color: #008080; text-decoration-color: #008080\"> chars</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  Bank grouped extraction: \u001b[0m\u001b[1;36m3282\u001b[0m\u001b[36m chars\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all prompts\n",
    "\n",
    "# Document type detection prompt\n",
    "with open(CONFIG['PROMPT_FILE_DOCTYPE'], 'r') as f:\n",
    "    doctype_data = yaml.safe_load(f)\n",
    "    DOCTYPE_PROMPT = doctype_data['prompts']['detection']['prompt']\n",
    "\n",
    "# Invoice extraction prompt\n",
    "with open(CONFIG['PROMPT_FILE_INVOICE'], 'r') as f:\n",
    "    invoice_data = yaml.safe_load(f)\n",
    "    INVOICE_PROMPT = invoice_data['prompts']['invoice']['prompt']\n",
    "\n",
    "# Receipt extraction prompt\n",
    "with open(CONFIG['PROMPT_FILE_RECEIPT'], 'r') as f:\n",
    "    receipt_data = yaml.safe_load(f)\n",
    "    RECEIPT_PROMPT = receipt_data['prompts']['receipt']['prompt']\n",
    "\n",
    "# Bank statement extraction prompts\n",
    "with open(CONFIG['PROMPT_FILE_BANK'], 'r') as f:\n",
    "    bank_data = yaml.safe_load(f)\n",
    "    BANK_PROMPTS = {\n",
    "        'flat': bank_data['prompts']['bank_statement_flat']['prompt'],\n",
    "        'date_grouped': bank_data['prompts']['bank_statement_date_grouped']['prompt']\n",
    "    }\n",
    "\n",
    "# Bank statement structure classification prompt\n",
    "STRUCTURE_CLASSIFICATION_PROMPT = \"\"\"Look at how dates are displayed in this bank statement's transaction list.\n",
    "\n",
    "Answer with ONLY one word:\n",
    "- FLAT (if dates appear as the FIRST COLUMN in a table row, like: \"05/05/2025 | Purchase | $22.50\")\n",
    "- GROUPED (if dates appear as SECTION HEADERS above transactions, like: \"Thu 05 Sep 2025\" followed by indented transaction details below)\n",
    "\n",
    "The key difference: FLAT has dates IN the table columns, GROUPED has dates AS headers ABOVE the rows.\n",
    "\n",
    "Answer (one word only):\"\"\"\n",
    "\n",
    "rprint(\"[green]✅ All prompts loaded[/green]\")\n",
    "rprint(f\"[cyan]  Document type detection: {len(DOCTYPE_PROMPT)} chars[/cyan]\")\n",
    "rprint(f\"[cyan]  Invoice extraction: {len(INVOICE_PROMPT)} chars[/cyan]\")\n",
    "rprint(f\"[cyan]  Receipt extraction: {len(RECEIPT_PROMPT)} chars[/cyan]\")\n",
    "rprint(f\"[cyan]  Bank flat extraction: {len(BANK_PROMPTS['flat'])} chars[/cyan]\")\n",
    "rprint(f\"[cyan]  Bank grouped extraction: {len(BANK_PROMPTS['date_grouped'])} chars[/cyan]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Multi-Turn Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ Chat function defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✅ Chat function defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chat_with_mllm(model, processor, prompt, images, messages=None, max_new_tokens=2000, do_sample=False):\n",
    "    \"\"\"Multi-turn chat using working pattern from Medium article.\"\"\"\n",
    "    if messages is None:\n",
    "        messages = []\n",
    "    \n",
    "    if len(messages) == 0:\n",
    "        messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": prompt}]}]\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]})\n",
    "    \n",
    "    text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(images=images, text=text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Deterministic generation: explicitly disable sampling parameters\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        \"do_sample\": do_sample,\n",
    "        \"temperature\": None if not do_sample else 0.6,\n",
    "        \"top_p\": None if not do_sample else 0.9\n",
    "    }\n",
    "    generate_ids = model.generate(**inputs, **generation_args)\n",
    "    \n",
    "    # Trim input tokens from output\n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:-1]\n",
    "    generated_texts = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "    \n",
    "    messages.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": generated_texts}]})\n",
    "    \n",
    "    return generated_texts, messages\n",
    "\n",
    "rprint(\"[green]✅ Chat function defined[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Parser Functions\n",
    "\n",
    "Functions to parse VLM responses:\n",
    "- Document type classification\n",
    "- Bank statement structure classification\n",
    "- Field extraction parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ Parser functions defined</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✅ Parser functions defined\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def parse_document_type(response):\n",
    "    \"\"\"Parse document type from VLM response.\"\"\"\n",
    "    response = response.strip().upper()\n",
    "    if \"INVOICE\" in response:\n",
    "        return \"INVOICE\"\n",
    "    elif \"RECEIPT\" in response:\n",
    "        return \"RECEIPT\"\n",
    "    elif \"BANK\" in response or \"STATEMENT\" in response:\n",
    "        return \"BANK_STATEMENT\"\n",
    "    else:\n",
    "        return \"INVOICE\"  # Default fallback\n",
    "\n",
    "def parse_structure_type(response):\n",
    "    \"\"\"Parse bank statement structure type from VLM response.\"\"\"\n",
    "    response = response.strip().upper()\n",
    "    if \"FLAT\" in response:\n",
    "        return \"flat\"\n",
    "    elif \"GROUPED\" in response or \"DATE\" in response:\n",
    "        return \"date_grouped\"\n",
    "    else:\n",
    "        return \"flat\"  # Default fallback\n",
    "\n",
    "def parse_extraction(extraction_text):\n",
    "    \"\"\"Parse extraction text into field dictionary.\"\"\"\n",
    "    extracted_fields = {}\n",
    "    \n",
    "    for line in extraction_text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if ':' in line and not line.startswith('#'):\n",
    "            parts = line.split(':', 1)\n",
    "            if len(parts) == 2:\n",
    "                field_name = parts[0].strip()\n",
    "                field_value = parts[1].strip()\n",
    "                extracted_fields[field_name] = field_value if field_value else 'NOT_FOUND'\n",
    "    \n",
    "    return extracted_fields\n",
    "\n",
    "rprint(\"[green]✅ Parser functions defined[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Discover Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ Found </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">9</span><span style=\"color: #008000; text-decoration-color: #008000\"> images to process</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✅ Found \u001b[0m\u001b[1;32m9\u001b[0m\u001b[32m images to process\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Images to process:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;34mImages to process:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_001.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_001.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_002.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_002.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_003.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_003.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_004.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_004.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_005.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_005.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_006.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_006.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_007.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_007.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_008.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_008.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  - image_009.png</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  - image_009.png\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Discover all images (no filtering by document type)\n",
    "data_dir = Path(CONFIG['DATA_DIR'])\n",
    "image_files = sorted(data_dir.glob(\"*.png\"))\n",
    "\n",
    "rprint(f\"[green]✅ Found {len(image_files)} images to process[/green]\")\n",
    "\n",
    "rprint(\"\\n[bold blue]Images to process:[/bold blue]\")\n",
    "for img in image_files:\n",
    "    rprint(f\"[cyan]  - {img.name}[/cyan]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Multi-Stage Batch Processing\n",
    "\n",
    " - **Stage 0**: Document Type Classification (INVOICE/RECEIPT/BANK_STATEMENT)\n",
    " - **Stage 1**: Structure Classification (for BANK_STATEMENT only: FLAT/GROUPED)\n",
    " - **Stage 2**: Document-Type-Aware Extraction (using appropriate prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# Multi-stage adaptive extraction with explicit stages (InternVL3-style)\nresults = []\nprocessing_times = []\ndoctype_counts = {'INVOICE': 0, 'RECEIPT': 0, 'BANK_STATEMENT': 0}\nstructure_counts = {'flat': 0, 'date_grouped': 0}\n\nrprint(\"\\n[bold green]🚀 Starting multi-stage adaptive extraction...[/bold green]\\n\")\n\nfor idx, image_path in enumerate(track(image_files, description=\"Processing images\"), 1):\n    image_name = image_path.name\n    \n    try:\n        start_time = time.time()\n        \n        # Load image\n        image = Image.open(image_path)\n        images = [image]\n        messages = []\n        \n        # ===================================================================\n        # STAGE 0: Document Type Classification\n        # ===================================================================\n        if CONFIG['VERBOSE']:\n            rprint(f\"\\n[bold blue]Processing [{idx}/{len(image_files)}]: {image_name}[/bold blue]\")\n            rprint(\"[dim]Stage 0: Document type detection...[/dim]\")\n        \n        doctype_answer, messages = chat_with_mllm(\n            model, processor, DOCTYPE_PROMPT, images, messages,\n            max_new_tokens=CONFIG['MAX_NEW_TOKENS_DOCTYPE']\n        )\n        \n        # Parse document type\n        document_type = parse_document_type(doctype_answer)\n        doctype_counts[document_type] += 1\n        \n        # ===================================================================\n        # STAGE 1: Structure Classification (only for BANK_STATEMENT)\n        # ===================================================================\n        structure_type = \"N/A\"\n        structure_answer = \"N/A\"\n        \n        if document_type == \"BANK_STATEMENT\":\n            if CONFIG['VERBOSE']:\n                rprint(\"[dim]Stage 1: Bank statement structure classification...[/dim]\")\n            \n            structure_answer, messages = chat_with_mllm(\n                model, processor, STRUCTURE_CLASSIFICATION_PROMPT, images, messages,\n                max_new_tokens=CONFIG['MAX_NEW_TOKENS_STRUCTURE']\n            )\n            structure_type = parse_structure_type(structure_answer)\n            structure_counts[structure_type] += 1\n            extraction_prompt = BANK_PROMPTS[structure_type]\n            prompt_key = f\"bank_statement_{structure_type}\"\n            \n        elif document_type == \"INVOICE\":\n            extraction_prompt = INVOICE_PROMPT\n            prompt_key = \"invoice\"\n            \n        elif document_type == \"RECEIPT\":\n            extraction_prompt = RECEIPT_PROMPT\n            prompt_key = \"receipt\"\n        \n        # ===================================================================\n        # STAGE 2: Document-Type-Aware Extraction\n        # ===================================================================\n        if CONFIG['VERBOSE']:\n            rprint(f\"[dim]Stage 2: Extraction using {prompt_key}...[/dim]\")\n        \n        extraction_result, messages = chat_with_mllm(\n            model, processor, extraction_prompt, images, messages,\n            max_new_tokens=CONFIG['MAX_NEW_TOKENS_EXTRACT']\n        )\n        \n        # Parse extraction\n        extracted_fields = parse_extraction(extraction_result)\n        \n        # Store results\n        result = {\n            'image_file': image_name,\n            'document_type': document_type,\n            'structure_type': structure_type,\n            'prompt_used': prompt_key,\n            'doctype_classification': doctype_answer.strip(),\n            'structure_classification': structure_answer.strip() if isinstance(structure_answer, str) else structure_answer,\n            'extraction_raw': extraction_result,\n            **extracted_fields\n        }\n        results.append(result)\n        \n        processing_time = time.time() - start_time\n        processing_times.append(processing_time)\n        \n        structure_display = structure_type if structure_type != 'N/A' else 'direct'\n        rprint(f\"[green]✅ {image_name}: {document_type} ({structure_display}) - {processing_time:.2f}s[/green]\")\n        \n    except Exception as e:\n        rprint(f\"[red]❌ {image_name}: Error - {e}[/red]\")\n        results.append({\n            'image_file': image_name,\n            'document_type': 'ERROR',\n            'structure_type': 'ERROR',\n            'error': str(e)\n        })\n        processing_times.append(0)\n    \n    finally:\n        # Memory cleanup after each image\n        if 'image' in locals():\n            image.close()\n        \n        # Clear GPU cache to prevent OOM on large batches\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        \n        # Periodic garbage collection every 3 images\n        if idx % 3 == 0:\n            gc.collect()\n\nconsole.rule(\"[bold green]Batch Processing Complete[/bold green]\")\n\n# Display summary statistics\nrprint(f\"\\n[bold blue]📊 Document Type Classification Summary:[/bold blue]\")\nrprint(f\"[cyan]  Invoices: {doctype_counts['INVOICE']}[/cyan]\")\nrprint(f\"[cyan]  Receipts: {doctype_counts['RECEIPT']}[/cyan]\")\nrprint(f\"[cyan]  Bank Statements: {doctype_counts['BANK_STATEMENT']}[/cyan]\")\n\nif doctype_counts['BANK_STATEMENT'] > 0:\n    rprint(f\"\\n[bold blue]📊 Bank Statement Structure Summary:[/bold blue]\")\n    rprint(f\"[cyan]  Flat table: {structure_counts['flat']}[/cyan]\")\n    rprint(f\"[cyan]  Date-grouped: {structure_counts['date_grouped']}[/cyan]\")"
  },
  {
   "cell_type": "markdown",
   "id": "4d8be0a2",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "xl0quiwnpv",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ CSV saved to: /home/jovyan/nfs_share/tod/LMM_POC/output/llama_adaptive_batch_results_20251021_085153.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✅ CSV saved to: \u001b[0m\u001b[32m/home/jovyan/nfs_share/tod/LMM_POC/output/\u001b[0m\u001b[32mllama_adaptive_batch_results_20251021_085153.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  Rows: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  Rows: \u001b[0m\u001b[1;36m9\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">  Columns: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m  Columns: \u001b[0m\u001b[1;36m24\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅ JSON saved to: /home/jovyan/nfs_share/tod/LMM_POC/output/llama_adaptive_batch_results_20251021_085153.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m✅ JSON saved to: \u001b[0m\u001b[32m/home/jovyan/nfs_share/tod/LMM_POC/output/\u001b[0m\u001b[32mllama_adaptive_batch_results_20251021_085153.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV (compatible with model_comparison.ipynb)\n",
    "csv_output = output_dir / f\"llama_adaptive_batch_results_{TIMESTAMP}.csv\"\n",
    "df.to_csv(csv_output, index=False)\n",
    "\n",
    "rprint(f\"[green]✅ CSV saved to: {csv_output}[/green]\")\n",
    "rprint(f\"[cyan]  Rows: {len(df)}[/cyan]\")\n",
    "rprint(f\"[cyan]  Columns: {len(df.columns)}[/cyan]\")\n",
    "\n",
    "# Save detailed JSON results\n",
    "json_output = output_dir / f\"llama_adaptive_batch_results_{TIMESTAMP}.json\"\n",
    "with open(json_output, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "rprint(f\"[green]✅ JSON saved to: {json_output}[/green]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9635a4c6",
   "metadata": {},
   "source": [
    "## Display Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "o54rhvnj18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Sample Results</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0m\u001b[1;34mSample Results\u001b[0m\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   image_file  document_type structure_type                 prompt_used\n",
       "image_001.png        RECEIPT            N/A                     receipt\n",
       "image_002.png        RECEIPT            N/A                     receipt\n",
       "image_003.png BANK_STATEMENT           flat         bank_statement_flat\n",
       "image_004.png        RECEIPT            N/A                     receipt\n",
       "image_005.png        INVOICE            N/A                     invoice\n",
       "image_006.png        INVOICE            N/A                     invoice\n",
       "image_007.png        INVOICE            N/A                     invoice\n",
       "image_008.png BANK_STATEMENT   date_grouped bank_statement_date_grouped\n",
       "image_009.png BANK_STATEMENT   date_grouped bank_statement_date_grouped\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   image_file  document_type structure_type                 prompt_used\n",
       "image_001.png        RECEIPT            N/A                     receipt\n",
       "image_002.png        RECEIPT            N/A                     receipt\n",
       "image_003.png BANK_STATEMENT           flat         bank_statement_flat\n",
       "image_004.png        RECEIPT            N/A                     receipt\n",
       "image_005.png        INVOICE            N/A                     invoice\n",
       "image_006.png        INVOICE            N/A                     invoice\n",
       "image_007.png        INVOICE            N/A                     invoice\n",
       "image_008.png BANK_STATEMENT   date_grouped bank_statement_date_grouped\n",
       "image_009.png BANK_STATEMENT   date_grouped bank_statement_date_grouped\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display sample results\n",
    "console.rule(\"[bold blue]Sample Results[/bold blue]\")\n",
    "\n",
    "display_cols = ['image_file', 'document_type', 'structure_type', 'prompt_used']\n",
    "\n",
    "rprint(df[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3291f2",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 DOCUMENT-TYPE-AWARE ADAPTIVE EXTRACTION SUMMARY\n",
      "================================================================================\n",
      "Total images processed: 9\n",
      "Successful extractions: 9\n",
      "Errors: 0\n",
      "\n",
      "Document Type Classification:\n",
      "  Invoices: 3\n",
      "  Receipts: 3\n",
      "  Bank Statements: 3\n",
      "\n",
      "Bank Statement Structure Classification:\n",
      "  Flat table format: 1\n",
      "  Date-grouped format: 2\n",
      "\n",
      "Prompts Used:\n",
      "  bank_statement_date_grouped: 2\n",
      "  bank_statement_flat: 1\n",
      "  invoice: 3\n",
      "  receipt: 3\n",
      "================================================================================\n",
      "\n",
      "📈 Field Extraction Coverage:\n",
      "  DOCUMENT_TYPE: 9/9 (100.0%)\n",
      "  BUSINESS_ABN: 6/9 (66.7%)\n",
      "  SUPPLIER_NAME: 6/9 (66.7%)\n",
      "  BUSINESS_ADDRESS: 6/9 (66.7%)\n",
      "  PAYER_NAME: 6/9 (66.7%)\n",
      "  PAYER_ADDRESS: 6/9 (66.7%)\n",
      "  INVOICE_DATE: 6/9 (66.7%)\n",
      "  LINE_ITEM_DESCRIPTIONS: 9/9 (100.0%)\n",
      "  LINE_ITEM_QUANTITIES: 6/9 (66.7%)\n",
      "  LINE_ITEM_PRICES: 6/9 (66.7%)\n",
      "  LINE_ITEM_TOTAL_PRICES: 6/9 (66.7%)\n",
      "  IS_GST_INCLUDED: 6/9 (66.7%)\n",
      "  GST_AMOUNT: 6/9 (66.7%)\n",
      "  TOTAL_AMOUNT: 6/9 (66.7%)\n",
      "  STATEMENT_DATE_RANGE: 3/9 (33.3%)\n",
      "  TRANSACTION_DATES: 3/9 (33.3%)\n",
      "  TRANSACTION_AMOUNTS_PAID: 3/9 (33.3%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📊 DOCUMENT-TYPE-AWARE ADAPTIVE EXTRACTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total images processed: {len(results)}\")\n",
    "print(f\"Successful extractions: {len([r for r in results if 'error' not in r])}\")\n",
    "print(f\"Errors: {len([r for r in results if 'error' in r])}\")\n",
    "\n",
    "print(\"\\nDocument Type Classification:\")\n",
    "print(f\"  Invoices: {doctype_counts['INVOICE']}\")\n",
    "print(f\"  Receipts: {doctype_counts['RECEIPT']}\")\n",
    "print(f\"  Bank Statements: {doctype_counts['BANK_STATEMENT']}\")\n",
    "\n",
    "if doctype_counts['BANK_STATEMENT'] > 0:\n",
    "    print(\"\\nBank Statement Structure Classification:\")\n",
    "    print(f\"  Flat table format: {structure_counts['flat']}\")\n",
    "    print(f\"  Date-grouped format: {structure_counts['date_grouped']}\")\n",
    "\n",
    "print(\"\\nPrompts Used:\")\n",
    "prompt_usage = {}\n",
    "for result in results:\n",
    "    if 'prompt_used' in result:\n",
    "        prompt = result['prompt_used']\n",
    "        prompt_usage[prompt] = prompt_usage.get(prompt, 0) + 1\n",
    "\n",
    "for prompt, count in sorted(prompt_usage.items()):\n",
    "    print(f\"  {prompt}: {count}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Field extraction statistics\n",
    "if len(df) > 0:\n",
    "    field_cols = [col for col in df.columns if col not in [\n",
    "        'image_file', 'document_type', 'structure_type', 'prompt_used', \n",
    "        'doctype_classification', 'structure_classification', 'extraction_raw', 'error'\n",
    "    ]]\n",
    "    \n",
    "    if field_cols:\n",
    "        print(\"\\n📈 Field Extraction Coverage:\")\n",
    "        for field in field_cols:\n",
    "            if field in df.columns:\n",
    "                found_count = df[field].notna().sum()\n",
    "                coverage = (found_count / len(df)) * 100\n",
    "                print(f\"  {field}: {found_count}/{len(df)} ({coverage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## View Individual Extraction\n",
    "\n",
    "Uncomment and run to view detailed extraction for a specific image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Detailed Extraction: image_003.png\n",
      "================================================================================\n",
      "Document Type: BANK_STATEMENT\n",
      "Structure Type: flat\n",
      "Prompt Used: bank_statement_flat\n",
      "\n",
      "Document Type Classification Response:\n",
      "This is a bank statement.\n",
      "\n",
      "Structure Classification Response:\n",
      "FLAT\n",
      "\n",
      "Extraction Result:\n",
      "DOCUMENT_TYPE: BANK_STATEMENT\n",
      "STATEMENT_DATE_RANGE: 03/05/2025 to 10/05/2025\n",
      "TRANSACTION_DATES: 03/05/2025 | 04/05/2025 | 05/05/2025 | 06/05/2025 | 07/05/2025 | 08/05/2025 | 09/05/2025 | 10/05/2025\n",
      "LINE_ITEM_DESCRIPTIONS: ONLINE PURCHASE AMAZON AU | EFTPOS PURCHASE COLES EXP | EFTPOS PURCHASE COLES EXP | DIRECT CREDIT SALARY | ATM WITHDRAWAL ANZ ATM | EFTPOS PURCHASE COLES EXP | INTEREST PAYMENT | ATM WITHDRAWAL ANZ ATM\n",
      "TRANSACTION_AMOUNTS_PAID: $288.03 | $22.50 | $114.66 | $187.59 | $112.50 | $5.16 | $146.72\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# View detailed extraction for specific image\n",
    "image_to_view = \"image_003.png\"  # Change this\n",
    "\n",
    "result = next((r for r in results if r['image_file'] == image_to_view), None)\n",
    "\n",
    "if result:\n",
    "    print(f\"\\n🔍 Detailed Extraction: {image_to_view}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Document Type: {result['document_type']}\")\n",
    "    print(f\"Structure Type: {result['structure_type']}\")\n",
    "    print(f\"Prompt Used: {result['prompt_used']}\")\n",
    "    print(f\"\\nDocument Type Classification Response:\")\n",
    "    print(result.get('doctype_classification', 'N/A'))\n",
    "    print(f\"\\nStructure Classification Response:\")\n",
    "    print(result.get('structure_classification', 'N/A'))\n",
    "    print(f\"\\nExtraction Result:\")\n",
    "    print(result.get('extraction_raw', 'N/A'))\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(f\"Image {image_to_view} not found in results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}