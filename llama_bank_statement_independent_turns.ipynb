{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 Vision: Independent Single-Turn Bank Statement Extraction\n",
    "\n",
    "**Protocol**: Three independent single-turn prompts + Python parsing/filtering\n",
    "\n",
    "**Key Insight**: Multi-turn conversation degrades accuracy. LLM filtering mixes up rows. Use Python for filtering!\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Turn 0: Image + Prompt ‚Üí Headers (fresh context)\n",
    "        ‚Üì (Python pattern matching)\n",
    "Turn 0.5: Image + Prompt ‚Üí Date Format Classification (fresh context)\n",
    "        ‚Üì (Classification: \"Date-per-row\" vs \"Date-grouped\")\n",
    "Turn 1: Image + Prompt ‚Üí Full Table (fresh context, format-specific example)\n",
    "        ‚Üì (Python parsing + filtering + balance validation)\n",
    "Schema Fields: TRANSACTION_DATES, LINE_ITEM_DESCRIPTIONS, TRANSACTION_AMOUNTS_PAID\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to concepts (Date, Description, Debit, Credit)\n",
    "3. **Turn 0.5 (LLM)**: Classify date format (\"Date-per-row\" vs \"Date-grouped\")\n",
    "4. **Turn 1 (LLM)**: Extract full markdown table using **format-specific example**\n",
    "5. **Balance Validation (Python)**: Auto-correct misalignments using balance mathematics\n",
    "6. **Python Parsing**: Parse markdown ‚Üí Filter for debits ‚Üí Extract schema fields\n",
    "\n",
    "### Critical Features:\n",
    "- ‚úÖ **Format Detection** - Auto-detect date-per-row vs date-grouped formats\n",
    "- ‚úÖ **Format-Specific Examples** - Adapt extraction pattern to detected format\n",
    "- ‚úÖ **Balance Validation** - Mathematical proof of correct debit/credit alignment\n",
    "- ‚úÖ **Python filtering** - Reliable debit/credit separation\n",
    "- ‚úÖ **Dynamic examples** - Adapt to 3/4/5 column formats\n",
    "- ‚úÖ **Tax accuracy** - Correct Debit/Credit separation critical for identifying purchases\n",
    "\n",
    "### Date Format Types:\n",
    "- **Date-per-row** (CBA style): Each transaction row has its own date\n",
    "- **Date-grouped** (NAB style): Dates as section headers, expanded to each transaction\n",
    "\n",
    "### Why This Works:\n",
    "- **Turn 0**: Clean context ‚Üí accurate header identification\n",
    "- **Turn 0.5**: Clean context ‚Üí accurate format classification\n",
    "- **Turn 1**: Format-specific example ‚Üí accurate date handling and table extraction\n",
    "- **Balance Validation**: Mathematical proof ‚Üí auto-correct misalignments\n",
    "- **Python**: Reliable Validation/Correction and filtering for debit transactions (what taxpayer PAID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "\n",
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "from IPython.display import display, Markdown\n",
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Llama-3.2-Vision model\n",
    "# Update this path to your local Llama model\n",
    "model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "# model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"üîß Loading Llama-3.2-Vision model...\")\n",
    "# model = MllamaForConditionalGeneration.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_id,\n",
    "    use_quantization=False,\n",
    "    device_map='auto',\n",
    "    max_new_tokens=2000,\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Add tie_weights() call\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    print(\"‚úÖ Model weights tied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è tie_weights() warning: {e}\")\n",
    "\n",
    "# processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Load bank statement image\n",
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_amount_balance.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_date_grouped_cont.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_highligted.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/low_contrast_fixed.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/nab_classic_highligted.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/westpac_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/transaction_summary.png\"\n",
    "\n",
    "\n",
    "\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/images/image_009.png\"\n",
    "print(\"üìÅ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"‚úÖ Image loaded: {image.size}\")\n",
    "print(f\"‚úÖ Images list created with {len(images)} image(s)\")\n",
    "\n",
    "# Display the loaded image for visual verification\n",
    "print(\"üñºÔ∏è  Bank statement image:\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Statement Extraction Protocol\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract full table using dynamic markdown example\n",
    "- Python: Parse, filter, and extract schema fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Turn 0 - Identify table headers (prompt)\n",
    "# TURN 0: Identify Table Headers\n",
    "# First, identify the actual column headers used in this specific bank statement\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "IMPORTANT STRUCTURAL NOTE:\n",
    "Some bank statements show dates as section headings with multiple transactions underneath.\n",
    "If you see this structure, remember that each transaction needs its explicit date in the final output.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üí¨ TURN 0: Identifying actual table headers\")\n",
    "print(\"ü§ñ Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Turn 0 - Execute and parse headers\n",
    "# Process the input using the CORRECT multi-turn pattern\n",
    "# Based on: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' with list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response with deterministic parameters\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output (this is the key to clean responses!)\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"‚úÖ Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CRITICAL: Parse the identified headers for use in subsequent turns\n",
    "# Extract column names from the response\n",
    "header_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\n",
    "identified_headers = []\n",
    "\n",
    "# Look for numbered list or bullet points\n",
    "for line in header_lines:\n",
    "    # Remove common list markers\n",
    "    cleaned = line.lstrip('0123456789.-‚Ä¢* ').strip()\n",
    "    \n",
    "    # Strip markdown bold formatting\n",
    "    cleaned = cleaned.replace('**', '').replace('__', '')\n",
    "    \n",
    "    # Skip section headers (lines ending with colon)\n",
    "    if cleaned.endswith(':'):\n",
    "        continue\n",
    "    \n",
    "    # Skip long sentences (likely explanatory text, not headers)\n",
    "    if len(cleaned) > 40:\n",
    "        continue\n",
    "        \n",
    "    if cleaned and len(cleaned) > 2:  # Ignore very short strings\n",
    "        identified_headers.append(cleaned)\n",
    "\n",
    "print(f\"\\nüìã Parsed {len(identified_headers)} column headers:\")\n",
    "for i, header in enumerate(identified_headers, 1):\n",
    "    print(f\"  {i}. '{header}'\")\n",
    "\n",
    "# Store headers for use in subsequent turns\n",
    "table_headers = identified_headers\n",
    "\n",
    "# Save the table headers\n",
    "output_path = Path(\"llama_table_headers.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput)\n",
    "\n",
    "print(f\"\\n‚úÖ Table headers saved to: {output_path}\")\n",
    "print(\"üí° These LITERAL header names will be used in Turn 1 & 2 prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 0.5: Date Format Classification\n",
    "\n",
    "Classify whether this statement uses:\n",
    "- **Date-per-row**: Each transaction row has its own date value\n",
    "- **Date-grouped**: Dates appear as section headers with multiple transactions underneath\n",
    "\n",
    "This determines which extraction example to use in Turn 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 11: Turn 0.5 - Classify date format (INDEPENDENT turn)\n\n# Build DYNAMIC classification examples using ACTUAL headers from Turn 0\nheader_string = \" | \".join(table_headers)\n\ndef format_example_table(rows, headers):\n    \"\"\"Format example table with proper column alignment.\"\"\"\n    if not rows or not headers:\n        return \"No data\"\n    \n    # Calculate max width for each column\n    num_cols = len(headers)\n    col_widths = [len(h) for h in headers]  # Start with header widths\n    \n    for row in rows:\n        for col_idx, val in enumerate(row):\n            if col_idx < len(col_widths):\n                col_widths[col_idx] = max(col_widths[col_idx], len(str(val)))\n    \n    # Build formatted table\n    formatted = []\n    \n    # Header row\n    header_parts = [headers[i].ljust(col_widths[i]) for i in range(num_cols)]\n    formatted.append(\"  | \" + \" | \".join(header_parts) + \" |\")\n    \n    # Data rows\n    for row in rows:\n        row_parts = [str(row[i]).ljust(col_widths[i]) for i in range(num_cols)]\n        formatted.append(\"  | \" + \" | \".join(row_parts) + \" |\")\n    \n    return \"\\n\".join(formatted)\n\n\n# Build example rows for Date-per-row format\ndate_per_row_rows = []\n\n# Row 1: Debit transaction\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"15 Jan\")\n    elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n        row.append(\"Transaction\")\n    elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n        row.append(\"50.00\")\n    elif 'credit' in h.lower() or 'deposit' in h.lower():\n        row.append(\"\")\n    elif 'balance' in h.lower():\n        row.append(\"$950 CR\")\n    elif 'amount' in h.lower():\n        row.append(\"50.00\")\n    else:\n        row.append(\"\")\ndate_per_row_rows.append(row)\n\n# Row 2: Credit transaction (shows in Credit column)\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"16 Jan\")\n    elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n        row.append(\"Transaction\")\n    elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n        row.append(\"\")  # Empty - this is a credit\n    elif 'credit' in h.lower() or 'deposit' in h.lower():\n        row.append(\"3,500.00\")\n    elif 'balance' in h.lower():\n        row.append(\"$4,450 CR\")\n    elif 'amount' in h.lower():\n        row.append(\"3,500.00\")\n    else:\n        row.append(\"\")\ndate_per_row_rows.append(row)\n\n# Row 3: Debit transaction (different amount)\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"17 Jan\")\n    elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n        row.append(\"Transaction\")\n    elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n        row.append(\"150.00\")\n    elif 'credit' in h.lower() or 'deposit' in h.lower():\n        row.append(\"\")\n    elif 'balance' in h.lower():\n        row.append(\"$4,300 CR\")\n    elif 'amount' in h.lower():\n        row.append(\"150.00\")\n    else:\n        row.append(\"\")\ndate_per_row_rows.append(row)\n\ndate_per_row_example = format_example_table(date_per_row_rows, table_headers)\n\n# Build example rows for Date-grouped format\ndate_grouped_rows = []\n\n# Row 1: Date header (15 Jan)\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"15 Jan\")\n    else:\n        row.append(\"\")\ndate_grouped_rows.append(row)\n\n# Row 2: First transaction under 15 Jan\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"\")\n    elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n        row.append(\"Transaction\")\n    elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n        row.append(\"50.00\")\n    elif 'credit' in h.lower() or 'deposit' in h.lower():\n        row.append(\"\")\n    elif 'balance' in h.lower():\n        row.append(\"$950 CR\")\n    elif 'amount' in h.lower():\n        row.append(\"50.00\")\n    else:\n        row.append(\"\")\ndate_grouped_rows.append(row)\n\n# Row 3: Second transaction under 15 Jan (balance continues to decrease)\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"\")\n    elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n        row.append(\"Transaction\")\n    elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n        row.append(\"75.00\")\n    elif 'credit' in h.lower() or 'deposit' in h.lower():\n        row.append(\"\")\n    elif 'balance' in h.lower():\n        row.append(\"$875 CR\")\n    elif 'amount' in h.lower():\n        row.append(\"75.00\")\n    else:\n        row.append(\"\")\ndate_grouped_rows.append(row)\n\n# Row 4: Date header (16 Jan)\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"16 Jan\")\n    else:\n        row.append(\"\")\ndate_grouped_rows.append(row)\n\n# Row 5: Transaction under 16 Jan (credit increases balance)\nrow = []\nfor h in table_headers:\n    if h.lower() in ['date', 'day']:\n        row.append(\"\")\n    elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n        row.append(\"Transaction\")\n    elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n        row.append(\"\")\n    elif 'credit' in h.lower() or 'deposit' in h.lower():\n        row.append(\"200.00\")\n    elif 'balance' in h.lower():\n        row.append(\"$1,075 CR\")\n    elif 'amount' in h.lower():\n        row.append(\"200.00\")\n    else:\n        row.append(\"\")\ndate_grouped_rows.append(row)\n\ndate_grouped_example = format_example_table(date_grouped_rows, table_headers)\n\n# Build classification prompt with YAML header + DYNAMIC examples\nformat_classification_prompt = f\"\"\"Analyze this bank statement image and classify its structural layout.\n\nLook at how transactions are organized:\n\nFLAT TABLE: Transactions are in a continuous table format with column headers\n- All transactions are in one continuous table\n- Clear column structure throughout\n- No date section headers breaking up the table\n\nExample of FLAT TABLE structure:\n{date_per_row_example}\n\nDATE-GROUPED: Transactions are grouped under date section headers\n- Date headers separate different transaction sections\n- Transactions are grouped by date sections\n- Look for date headers that separate groups of transactions\n\nExample of DATE-GROUPED structure:\n{date_grouped_example}\n\nDoes each transaction have its own date value, or are the transactions grouped by date?\n\nIf each transaction has its own individual date in a table: Respond with \"Date-per-row\"\nIf transactions are grouped under shared date headers: Respond with \"Date-grouped\"\n\nResponse:\"\"\"\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"CLASSIFICATION PROMPT:\")\nprint(\"=\" * 60)\nprint(format_classification_prompt)\nprint(\"=\" * 60 + \"\\n\")\n\n# CRITICAL: Create FRESH message structure (independent turn)\nmessageDataStructure_format = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\"},\n            {\"type\": \"text\", \"text\": format_classification_prompt}\n        ]\n    }\n]\n\nprint(\"üí¨ TURN 0.5: Classifying date format\")\nprint(\"ü§ñ Generating response with Llama-3.2-Vision...\")\n\n# Process with FRESH context\ntextInput = processor.apply_chat_template(\n    messageDataStructure_format, add_generation_prompt=True\n)\n\ninputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n\noutput = model.generate(\n    **inputs,\n    max_new_tokens=100,\n    do_sample=False,\n    temperature=None,\n    top_p=None,\n)\n\ngenerate_ids = output[:, inputs['input_ids'].shape[1]:-1]\nformat_response = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False).strip()\n\nprint(\"‚úÖ Response generated successfully!\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 0.5 - DATE FORMAT CLASSIFICATION:\")\nprint(\"=\" * 60)\nprint(format_response)\nprint(\"=\" * 60)\n\n# Parse classification\ndate_format = \"Date-per-row\"\nif \"Date-grouped\" in format_response or \"date-grouped\" in format_response:\n    date_format = \"Date-grouped\"\nelif \"Date-per-row\" in format_response or \"date-per-row\" in format_response:\n    date_format = \"Date-per-row\"\n\nprint(f\"\\nüìä Detected Format: {date_format}\")\n\n# Save classification result\noutput_path = Path(\"llama_date_format_classification.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as f:\n    f.write(f\"Classification: {date_format}\\n\")\n    f.write(f\"Raw response: {format_response}\\n\")\n\nprint(f\"‚úÖ Classification saved to: {output_path}\")\nprint(f\"üí° This format will determine the Turn 1 extraction example\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 13: Pattern Matching - Map headers to generic columns\n# Pattern Matching: Map extracted headers to generic concepts\n# This handles variety in bank statement column naming conventions\n\n# Pattern keywords for each concept (in priority order)\nDATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\nDESCRIPTION_PATTERNS = [\n    'description', 'details', 'transaction details', 'trans details',\n    'particulars', 'narrative', 'transaction', 'trans'\n]\nDEBIT_PATTERNS = ['debit', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\nCREDIT_PATTERNS = ['credit', 'deposit', 'deposits', 'received', 'cr']\nBALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n\n# NEW: Pattern for single-column transaction formats (e.g., \"Amount\" instead of separate Debit/Credit)\nAMOUNT_PATTERNS = ['amount', 'amt', 'value', 'total']\n\ndef match_header(headers, patterns, fallback=None):\n    \"\"\"Match a header using pattern keywords.\n    \n    Matching strategy:\n    1. Exact match (case-insensitive)\n    2. Substring match (only for patterns with length > 2 to avoid false positives)\n    \"\"\"\n    headers_lower = [h.lower() for h in headers]\n    \n    # Try exact match first\n    for pattern in patterns:\n        for i, header_lower in enumerate(headers_lower):\n            if pattern == header_lower:\n                return headers[i]\n    \n    # Try substring match (only for patterns longer than 2 chars)\n    for pattern in patterns:\n        if len(pattern) > 2:  # Avoid false positives like 'cr' matching 'description'\n            for i, header_lower in enumerate(headers_lower):\n                if pattern in header_lower:\n                    return headers[i]\n    \n    return fallback\n\n# Perform pattern matching on extracted headers\ndate_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\ndesc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n\n# NEW: First try to match a generic \"Amount\" column (for 4-column formats)\namount_col = match_header(table_headers, AMOUNT_PATTERNS, fallback=None)\n\n# Use amount_col as fallback if no separate debit/credit columns exist\n# This handles formats like: Date | Description | Amount | Balance\ndebit_col = match_header(table_headers, DEBIT_PATTERNS, fallback=amount_col if amount_col else 'Debit')\ncredit_col = match_header(table_headers, CREDIT_PATTERNS, fallback=amount_col if amount_col else 'Credit')\nbalance_col = match_header(table_headers, BALANCE_PATTERNS, fallback='Balance')\n\nprint(\"=\" * 60)\nprint(\"PATTERN MATCHING RESULTS:\")\nprint(\"=\" * 60)\nprint(f\"üìã Extracted Headers: {table_headers}\")\nprint(f\"\\nüîç Mapped Columns:\")\nprint(f\"  Date        ‚Üí '{date_col}'\")\nprint(f\"  Description ‚Üí '{desc_col}'\")\nprint(f\"  Debit       ‚Üí '{debit_col}'\")\nprint(f\"  Credit      ‚Üí '{credit_col}'\")\nprint(f\"  Balance     ‚Üí '{balance_col}'\")\nif amount_col:\n    print(f\"\\nüí° Single-column format detected: '{amount_col}' used for both debit and credit\")\nprint(\"=\" * 60)\nprint(\"\\n‚úÖ These literal column names will be used in Turn 1 and Turn 2\")\nprint(\"üí° Adjust patterns above if matching fails for your bank statement format\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë Independent Single-Turn Pattern (NOT Multi-Turn Conversation)\n",
    "\n",
    "**CRITICAL INSIGHT**: Multi-turn conversation accumulates context and degrades accuracy.\n",
    "\n",
    "We use **two independent single-turn prompts**, each with fresh context:\n",
    "\n",
    "#### Key Principles:\n",
    "\n",
    "1. **No Conversation History**: Each turn is completely independent\n",
    "2. **Fresh Image Attention**: Each turn processes the image directly\n",
    "3. **No Context Accumulation**: Prevents attention dilution\n",
    "4. **Headers as Parameters**: Turn 0 headers used to generate dynamic examples for Turn 1\n",
    "5. **Python Filtering**: LLM filtering mixes up rows - Python is reliable\n",
    "\n",
    "#### Message Structure for Each Turn:\n",
    "\n",
    "Every turn uses fresh structure:\n",
    "```python\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"<prompt with dynamic example>\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "**No assistant responses in history. No conversation accumulation.**\n",
    "\n",
    "#### Why This Works Better:\n",
    "\n",
    "- **Turn 0**: Clean context ‚Üí accurate header identification\n",
    "- **Turn 1**: Clean context + dynamic example ‚Üí accurate table extraction  \n",
    "- **Python**: Reliable parsing and filtering (no row mixing!)\n",
    "\n",
    "Each turn has **full attention** on the image, not diluted by conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 15: NO conversation history (independent turns)\n# \n# CRITICAL: We do NOT use conversation history in this notebook.\n# Each turn is completely independent with fresh context.\n#\n# Why? Multi-turn conversation accumulates context and degrades accuracy:\n# - Turn 0: ~50 tokens ‚Üí accurate\n# - Turn 1 with history: ~350 tokens ‚Üí attention diluted ‚Üí less accurate\n# - Turn 2 with history: ~2000 tokens ‚Üí attention heavily diluted ‚Üí row mixing!\n#\n# Instead: \n# - Turn 0: Fresh context ‚Üí headers\n# - Turn 1: Fresh context + dynamic example ‚Üí full table\n# - Python: Parse and filter (no LLM confusion!)\n\nprint(\"‚úÖ Independent turn approach - NO conversation history\")\nprint(\"üí° Each turn has fresh context with direct image access\")\nprint(\"üêç Python handles all filtering - no LLM row mixing!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Column Aware Extraction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 17: Generate Minimal Extraction Prompt (Format-Specific)\n\ndef format_aligned_table(rows_data, headers):\n    \"\"\"Format table with aligned vertical pipes (for date-grouped transformation clarity).\"\"\"\n    if not rows_data or not headers:\n        return \"No data\"\n    \n    # Calculate max width for each column\n    num_cols = len(headers)\n    col_widths = [len(h) for h in headers]\n    \n    for row in rows_data:\n        for col_idx, val in enumerate(row):\n            if col_idx < num_cols:\n                col_widths[col_idx] = max(col_widths[col_idx], len(str(val)))\n    \n    # Build formatted table\n    formatted = []\n    \n    # Header row\n    header_parts = [headers[i].ljust(col_widths[i]) for i in range(num_cols)]\n    formatted.append(\"| \" + \" | \".join(header_parts) + \" |\")\n    \n    # Data rows\n    for row in rows_data:\n        row_parts = [str(row[i]).ljust(col_widths[i]) for i in range(num_cols)]\n        formatted.append(\"| \" + \" | \".join(row_parts) + \" |\")\n    \n    return \"\\n\".join(formatted)\n\ndef build_minimal_date_per_row_extraction(headers):\n    \"\"\"Minimal extraction example for date-per-row format.\"\"\"\n    rows = []\n    \n    for date, desc, deb, cred, bal in [\n        (\"15 Jan\", \"ATM Withdrawal\", \"200.00\", \"\", \"$1,500.00 CR\"),\n        (\"16 Jan\", \"Salary Payment\", \"\", \"3,500.00\", \"$5,000.00 CR\"),\n        (\"17 Jan\", \"Online Purchase\", \"150.00\", \"\", \"$4,850.00 CR\")\n    ]:\n        row = []\n        for h in headers:\n            if h.lower() in ['date', 'day']:\n                row.append(date)\n            elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n                row.append(desc)\n            elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n                row.append(deb)\n            elif 'credit' in h.lower() or 'deposit' in h.lower():\n                row.append(cred)\n            elif 'balance' in h.lower():\n                row.append(bal)\n            elif 'amount' in h.lower():\n                row.append(deb if deb else cred)\n            else:\n                row.append(\"\")\n        rows.append(\"| \" + \" | \".join(row) + \" |\")\n    \n    return rows\n\ndef build_date_grouped_source(headers):\n    \"\"\"Show how date-grouped appears in the image (with empty date cells).\"\"\"\n    rows = []\n    \n    # Date header row with empty cells\n    for date, desc, deb, cred, bal in [\n        (\"22 Mar\", \"\", \"\", \"\", \"\"),\n        (\"\", \"Auto Services\", \"580.00\", \"\", \"$8,721.15 CR\"),\n        (\"\", \"EFTPOS Grocers\", \"125.00\", \"\", \"$8,596.15 CR\"),\n        (\"23 Mar\", \"\", \"\", \"\", \"\"),\n        (\"\", \"VISA Markets\", \"89.75\", \"\", \"$8,506.40 CR\")\n    ]:\n        row = []\n        for h in headers:\n            if h.lower() in ['date', 'day']:\n                row.append(date)\n            elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n                row.append(desc)\n            elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n                row.append(deb)\n            elif 'credit' in h.lower() or 'deposit' in h.lower():\n                row.append(cred)\n            elif 'balance' in h.lower():\n                row.append(bal)\n            elif 'amount' in h.lower():\n                row.append(deb if deb else cred)\n            else:\n                row.append(\"\")\n        rows.append(row)\n    \n    return rows\n\ndef build_date_grouped_target(headers):\n    \"\"\"Show how to extract date-grouped (with dates distributed).\"\"\"\n    rows = []\n    \n    for date, desc, deb, cred, bal in [\n        (\"22 Mar\", \"Auto Services\", \"580.00\", \"\", \"$8,721.15 CR\"),\n        (\"22 Mar\", \"EFTPOS Grocers\", \"125.00\", \"\", \"$8,596.15 CR\"),\n        (\"23 Mar\", \"VISA Markets\", \"89.75\", \"\", \"$8,506.40 CR\")\n    ]:\n        row = []\n        for h in headers:\n            if h.lower() in ['date', 'day']:\n                row.append(date)\n            elif 'desc' in h.lower() or 'particular' in h.lower() or 'detail' in h.lower() or 'transaction' in h.lower():\n                row.append(desc)\n            elif 'debit' in h.lower() or 'withdrawal' in h.lower():\n                row.append(deb)\n            elif 'credit' in h.lower() or 'deposit' in h.lower():\n                row.append(cred)\n            elif 'balance' in h.lower():\n                row.append(bal)\n            elif 'amount' in h.lower():\n                row.append(deb if deb else cred)\n            else:\n                row.append(\"\")\n        rows.append(row)\n    \n    return rows\n\n# Generate format-specific example\nprint(f\"üéØ Building extraction prompt for format: {date_format}\")\n\nif date_format == \"Date-grouped\":\n    # Use aligned formatting for transformation clarity\n    source_rows = build_date_grouped_source(table_headers)\n    target_rows = build_date_grouped_target(table_headers)\n    source_table = format_aligned_table(source_rows, table_headers)\n    target_table = format_aligned_table(target_rows, table_headers)\n    \n    follow_up_prompt = f\"\"\"Extract the transaction table as markdown.\n\nIf you see this structure (dates as section headers with empty cells):\n{source_table}\n\nExtract as (distribute date to every transaction row):\n{target_table}\n\nOutput: Markdown table only.\"\"\"\n\nelse:\n    # Minimal formatting for date-per-row\n    example_rows = build_minimal_date_per_row_extraction(table_headers)\n    header_row = \"| \" + \" | \".join(table_headers) + \" |\"\n    example_table = header_row + \"\\n\" + \"\\n\".join(example_rows)\n    \n    follow_up_prompt = f\"\"\"Extract the transaction table as markdown.\n\nExample format:\n{example_table}\n\nExtract ALL transactions.\n\nOutput: Markdown table only.\"\"\"\n\nprint(\"\\n\" + \"=\" * 60)\nprint(f\"Turn 1 Extraction Prompt ({date_format} format):\")\nprint(\"=\" * 60)\nprint(f\"\\n{follow_up_prompt}\")\nprint(\"=\" * 60 + \"\\n\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 1: Extract Full Table in Markdown\n",
    "\n",
    "Now that we know the actual column headers, extract the complete table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 19: Turn 1 - Extract full table (INDEPENDENT, fresh context)\n\n# # CRITICAL: Create FRESH message structure (NOT appending to conversation history)\nmessageDataStructure_turn1 = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\"},\n            {\"type\": \"text\", \"text\": follow_up_prompt}\n        ]\n    }\n]\n\nprint(\"Generating response with Llama-3.2-Vision...\")\n\n# Process with FRESH context\ntextInput = processor.apply_chat_template(\n    messageDataStructure_turn1, add_generation_prompt=True\n)\n\n# CRITICAL: Use named parameter 'images=' with list\ninputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n\n# Generate response\noutput = model.generate(\n    **inputs,\n    max_new_tokens=2000,\n    do_sample=False,\n    temperature=None,\n    top_p=None,\n)\n\n# CRITICAL: Trim input tokens from output\ngenerate_ids = output[:, inputs['input_ids'].shape[1]:-1]\ncleanedOutput2 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n\nprint(\"\\nTurn 1 extraction complete!\")\n\n# Display the extracted table as rendered markdown for easy visual verification\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 1 - EXTRACTED MARKDOWN TABLE:\")\nprint(\"=\" * 60)\ndisplay(Markdown(cleanedOutput2))\nprint(\"=\" * 60)\n\n# Save the markdown table\noutput_path = Path(\"llama_markdown_table_extraction.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(cleanedOutput2)\n\nprint(f\"\\nMarkdown table saved to: {output_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance-Based Validation/Correction\n",
    "- Validate that total debits + total credits = balance change\n",
    "- Ensures accurate debit/credit separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 21: Balance-Based Debit/Credit Validation Function\n\ndef validate_and_correct_alignment(rows, balance_col, debit_col, credit_col, desc_col):\n    \"\"\"\n    Use balance changes to validate and correct debit/credit alignment.\n    \n    CRITICAL: This provides mathematical proof of correct alignment!\n    - Balance increase = CREDIT (income/deposit)\n    - Balance decrease = DEBIT (expense/withdrawal)\n    \n    Args:\n        rows: List of dictionaries (parsed markdown table rows)\n        balance_col: Name of the Balance column\n        debit_col: Name of the Debit column\n        credit_col: Name of the Credit column\n        desc_col: Name of the Description column (to detect opening/closing balance)\n    \n    Returns:\n        List of corrected row dictionaries\n    \"\"\"\n    \n    def parse_amount(value):\n        \"\"\"Extract numeric value from formatted currency string.\"\"\"\n        if not value or value.strip() == \"\":\n            return 0.0\n        # Remove currency symbols, commas, CR/DR markers\n        cleaned = value.replace(\"$\", \"\").replace(\",\", \"\").replace(\"CR\", \"\").replace(\"DR\", \"\").strip()\n        try:\n            return float(cleaned)\n        except ValueError:\n            return 0.0\n    \n    def is_balance_row(row, desc_col):\n        \"\"\"Check if this row is an opening/closing balance row (not a transaction).\"\"\"\n        desc = row.get(desc_col, \"\").upper()\n        return \"OPENING BALANCE\" in desc or \"CLOSING BALANCE\" in desc\n    \n    # Check if Balance column exists\n    if not rows or balance_col not in rows[0]:\n        print(f\"‚ö†Ô∏è  Balance column '{balance_col}' not found - skipping validation\")\n        return rows\n    \n    corrected_rows = []\n    corrections_made = 0\n    start_idx = 0\n    \n    # Check if row 0 is an opening balance row\n    if rows and is_balance_row(rows[0], desc_col):\n        print(f\"‚úÖ Row 0: Opening/closing balance detected - skipping (not a transaction)\")\n        start_idx = 1\n    elif rows:\n        # Row 0 is a regular transaction - include it without validation\n        corrected_rows.append(rows[0].copy())\n        print(f\"‚úÖ Row 0: First transaction included without validation (no previous balance to compare)\")\n        start_idx = 1\n    \n    # Validate and correct remaining rows (can compare to previous row)\n    for i in range(start_idx, len(rows)):\n        current_row = rows[i].copy()\n        \n        # Skip balance rows (opening/closing balance)\n        if is_balance_row(current_row, desc_col):\n            print(f\"‚ö†Ô∏è  Row {i}: Opening/closing balance row detected - skipping (not a transaction)\")\n            continue\n        \n        # Find the previous non-balance row for comparison\n        prev_idx = i - 1\n        while prev_idx >= 0 and is_balance_row(rows[prev_idx], desc_col):\n            prev_idx -= 1\n        \n        if prev_idx < 0:\n            # No previous row to compare (first transaction after opening balance)\n            corrected_rows.append(current_row)\n            print(f\"‚úÖ Row {i}: First transaction after balance row - included without validation\")\n            continue\n        \n        # Parse balances\n        prev_balance = parse_amount(rows[prev_idx].get(balance_col, \"0\"))\n        curr_balance = parse_amount(current_row.get(balance_col, \"0\"))\n        \n        # Calculate balance change\n        balance_change = curr_balance - prev_balance\n        \n        # Parse current debit/credit values\n        debit_value = parse_amount(current_row.get(debit_col, \"\"))\n        credit_value = parse_amount(current_row.get(credit_col, \"\"))\n        \n        # Validation logic (use small epsilon for float comparison)\n        if balance_change > 0.01:  # Balance increased\n            # Should be CREDIT\n            if debit_value > 0 and credit_value == 0:\n                # MISALIGNMENT: Amount in Debit column but balance increased\n                print(f\"‚ö†Ô∏è  Row {i}: Balance increased by ${balance_change:.2f} but amount in Debit column\")\n                print(f\"   Correction: Moving ${debit_value:.2f} from Debit ‚Üí Credit\")\n                current_row[credit_col] = current_row[debit_col]\n                current_row[debit_col] = \"\"\n                corrections_made += 1\n                \n                # Verify the correction matches the balance change\n                expected_amount = abs(balance_change)\n                if abs(expected_amount - debit_value) > 0.01:\n                    print(f\"   ‚ö†Ô∏è  Warning: Balance change (${expected_amount:.2f}) doesn't match amount (${debit_value:.2f})\")\n                \n        elif balance_change < -0.01:  # Balance decreased\n            # Should be DEBIT\n            if credit_value > 0 and debit_value == 0:\n                # MISALIGNMENT: Amount in Credit column but balance decreased\n                print(f\"‚ö†Ô∏è  Row {i}: Balance decreased by ${abs(balance_change):.2f} but amount in Credit column\")\n                print(f\"   Correction: Moving ${credit_value:.2f} from Credit ‚Üí Debit\")\n                current_row[debit_col] = current_row[credit_col]\n                current_row[credit_col] = \"\"\n                corrections_made += 1\n                \n                # Verify the correction matches the balance change\n                expected_amount = abs(balance_change)\n                if abs(expected_amount - credit_value) > 0.01:\n                    print(f\"   ‚ö†Ô∏è  Warning: Balance change (${expected_amount:.2f}) doesn't match amount (${credit_value:.2f})\")\n        \n        corrected_rows.append(current_row)\n    \n    print(f\"\\n‚úÖ Balance validation complete: {corrections_made} corrections made\")\n    print(f\"‚úÖ Total transaction rows processed: {len(corrected_rows)}\")\n    return corrected_rows\n\nprint(\"‚úÖ Balance validation function defined\")\nprint(\"üí° This function uses balance mathematics to validate and auto-correct misaligned amounts\")\nprint(\"üí° Opening/closing balance rows are automatically detected and skipped\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Parsing and Filtering\n",
    "\n",
    "Parse the Turn 1 markdown table, filter for debit transactions, and extract schema fields using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 23: Parse Turn 1 markdown table and filter for debits (Python)\nimport re\nfrom datetime import datetime\n\ndef parse_markdown_table(markdown_text):\n    \"\"\"Parse markdown table into list of dictionaries.\n    \n    CRITICAL: Must preserve empty columns for correct Debit/Credit alignment!\n    \"\"\"\n    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n    \n    # Find header row (first line with pipes)\n    header_idx = None\n    for i, line in enumerate(lines):\n        if '|' in line:\n            # Skip separator rows (contain only pipes, hyphens, and spaces)\n            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n            if cleaned:  # Has actual content, not just separators\n                header_idx = i\n                break\n    \n    if header_idx is None:\n        return []\n    \n    # Parse headers - KEEP empty values to preserve column positions\n    header_line = lines[header_idx]\n    header_parts = [h.strip() for h in header_line.split('|')]\n    # Remove leading/trailing empty strings from pipe delimiters\n    if header_parts and header_parts[0] == '':\n        header_parts = header_parts[1:]\n    if header_parts and header_parts[-1] == '':\n        header_parts = header_parts[:-1]\n    # Filter out any remaining empty headers\n    headers = [h for h in header_parts if h]\n    \n    print(f\"üîç Debug: Parsed {len(headers)} headers: {headers}\")\n    \n    # Parse data rows (skip header and separator)\n    rows = []\n    for idx, line in enumerate(lines[header_idx + 1:], start=header_idx+1):\n        if '|' not in line:\n            continue\n            \n        # Skip separator rows\n        cleaned = line.replace(\"|\", \"\").replace(\"-\", \"\").replace(\" \", \"\").replace(\":\", \"\")\n        if not cleaned:\n            continue\n        \n        # Parse values - KEEP empty values to preserve column positions!\n        value_parts = [v.strip() for v in line.split('|')]\n        # Remove leading/trailing empty strings from pipe delimiters\n        if value_parts and value_parts[0] == '':\n            value_parts = value_parts[1:]\n        if value_parts and value_parts[-1] == '':\n            value_parts = value_parts[:-1]\n        \n        print(f\"üîç Debug row {idx}: {len(value_parts)} values: {value_parts}\")\n        \n        # Match to headers length\n        if len(value_parts) == len(headers):\n            rows.append(dict(zip(headers, value_parts)))\n        else:\n            print(f\"‚ö†Ô∏è  Row {idx} mismatch: {len(value_parts)} values vs {len(headers)} headers - SKIPPED\")\n    \n    return rows\n\ndef filter_debit_transactions(rows, debit_col):\n    \"\"\"Filter rows to only those with debit (purchase) amounts.\n    \n    CRITICAL: For tax purposes, we only want transactions where taxpayer PAID money (debits).\n    \"\"\"\n    debit_rows = []\n    for row in rows:\n        debit_value = row.get(debit_col, '').strip()\n        # Include row if debit column has a value (not empty)\n        if debit_value:\n            debit_rows.append(row)\n    \n    return debit_rows\n\ndef extract_schema_fields(rows, date_col, desc_col, debit_col):\n    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n    if not rows:\n        return {\n            'TRANSACTION_DATES': 'NOT_FOUND',\n            'LINE_ITEM_DESCRIPTIONS': 'NOT_FOUND',\n            'TRANSACTION_AMOUNTS_PAID': 'NOT_FOUND',\n            'STATEMENT_DATE_RANGE': 'NOT_FOUND'\n        }\n    \n    # Extract lists\n    dates = []\n    descriptions = []\n    amounts = []\n    \n    for row in rows:\n        date = row.get(date_col, '').strip()\n        desc = row.get(desc_col, '').strip()\n        amount = row.get(debit_col, '').strip()\n        \n        if date:\n            dates.append(date)\n        if desc:\n            descriptions.append(desc)\n        if amount:\n            amounts.append(amount)\n    \n    # Calculate statement date range - use literal date format from image\n    # No parsing, no year assumption - just \"earliest date - latest date\"\n    date_range = 'NOT_FOUND'\n    if dates:\n        # Use first and last date as-is (same format as in the image)\n        date_range = f\"{dates[0]} - {dates[-1]}\"\n    \n    return {\n        'TRANSACTION_DATES': ' | '.join(dates) if dates else 'NOT_FOUND',\n        'LINE_ITEM_DESCRIPTIONS': ' | '.join(descriptions) if descriptions else 'NOT_FOUND',\n        'TRANSACTION_AMOUNTS_PAID': ' | '.join(amounts) if amounts else 'NOT_FOUND',\n        'STATEMENT_DATE_RANGE': date_range\n    }\n\nprint(\"=\" * 60)\nprint(\"PARSING TURN 1 MARKDOWN TABLE:\")\nprint(\"=\" * 60)\n\n# Parse the full markdown table from Turn 1\nall_rows = parse_markdown_table(cleanedOutput2)\n\n# CRITICAL: Validate and correct debit/credit alignment using balance mathematics\nif balance_col in all_rows[0] if all_rows else False:\n    print(\"\\n\" + \"=\" * 60)\n    print(\"VALIDATING DEBIT/CREDIT ALIGNMENT USING BALANCE CHANGES:\")\n    print(\"=\" * 60)\n    all_rows = validate_and_correct_alignment(all_rows, balance_col, debit_col, credit_col, desc_col)\n    \n    # Display corrected table as markdown\n    def rows_to_markdown(rows, headers):\n        \"\"\"Convert row dictionaries back to markdown table.\"\"\"\n        if not rows:\n            return \"No rows to display\"\n        \n        # Build header row\n        header_row = \"| \" + \" | \".join(headers) + \" |\"\n        \n        # Build separator row\n        separator_parts = []\n        for h in headers:\n            h_lower = h.lower()\n            if any(kw in h_lower for kw in ['debit', 'credit', 'balance', 'amount']):\n                separator_parts.append('---:')\n            else:\n                separator_parts.append(':---')\n        separator_row = \"| \" + \" | \".join(separator_parts) + \" |\"\n        \n        # Build data rows\n        data_rows = []\n        for row in rows:\n            values = [row.get(h, '') for h in headers]\n            data_rows.append(\"| \" + \" | \".join(values) + \" |\")\n        \n        return header_row + \"\\n\" + separator_row + \"\\n\" + \"\\n\".join(data_rows)\n    \n    # Convert corrected rows to markdown and display\n    if all_rows:\n        headers = list(all_rows[0].keys())\n        corrected_table_markdown = rows_to_markdown(all_rows, headers)\n        \n        print(\"\\n\" + \"=\" * 60)\n        print(\"CORRECTED TABLE (After Balance Validation):\")\n        print(\"=\" * 60)\n        display(Markdown(corrected_table_markdown))\n        print(\"=\" * 60)\nelse:\n    print(\"\\n‚ö†Ô∏è  Balance column not found - skipping validation\")\n\nprint(f\"\\nüìä Parsed {len(all_rows)} total transactions from Turn 1 markdown table\")\n\nif all_rows:\n    # Show sample parsed row\n    print(f\"\\nüîç Sample parsed row:\")\n    for key, value in all_rows[0].items():\n        print(f\"  {key}: '{value}'\")\n\n# Filter to only debit (purchase) transactions - Python filtering, not LLM!\ndebit_rows = filter_debit_transactions(all_rows, debit_col)\n\nprint(f\"\\nüí∞ Filtered to {len(debit_rows)} debit transactions (taxpayer purchases)\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DEBIT TRANSACTIONS (WHAT TAXPAYER PAID):\")\nprint(\"=\" * 60)\nfor i, row in enumerate(debit_rows, 1):\n    print(f\"\\nTransaction {i}:\")\n    print(f\"  {date_col}: {row.get(date_col, '')}\")\n    print(f\"  {desc_col}: {row.get(desc_col, '')}\")\n    print(f\"  {debit_col}: {row.get(debit_col, '')}\")\n\n# Extract schema fields using the LITERAL column names from pattern matching\nschema_fields = extract_schema_fields(debit_rows, date_col, desc_col, debit_col)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"EXTRACTED SCHEMA FIELDS (TAX-RELEVANT DATA):\")\nprint(\"=\" * 60)\nfor field, value in schema_fields.items():\n    print(f\"{field}: {value}\")\nprint(\"=\" * 60)\n\n# Save to file\noutput_path = Path(\"llama_extracted_fields.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as f:\n    for field, value in schema_fields.items():\n        f.write(f\"{field}: {value}\\n\")\n\nprint(f\"\\n‚úÖ Schema fields saved to: {output_path}\")\nprint(f\"üí° Fields extracted from columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")\nprint(f\"üéØ Success: Python parsing + filtering from Turn 1 markdown table\")\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}