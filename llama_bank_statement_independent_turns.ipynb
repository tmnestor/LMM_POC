{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 Vision: Independent Single-Turn Bank Statement Extraction\n",
    "\n",
    "**Protocol**: Two independent single-turn prompts + Python parsing/filtering\n",
    "\n",
    "**Key Insight**: Multi-turn conversation degrades accuracy. LLM filtering mixes up rows. Use Python for filtering!\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Turn 0: Image + Prompt â†’ Headers (fresh context)\n",
    "        â†“ (Python pattern matching)\n",
    "Turn 1: Image + Prompt â†’ Full Table (fresh context, dynamic markdown example)\n",
    "        â†“ (Python parsing + filtering)\n",
    "Schema Fields: TRANSACTION_DATES, LINE_ITEM_DESCRIPTIONS, TRANSACTION_AMOUNTS_PAID\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to concepts (Date, Description, Debit, Credit)\n",
    "3. **Turn 1 (LLM)**: Extract full markdown table using **dynamic example** matching detected column structure\n",
    "4. **Python Parsing**: Parse markdown â†’ Filter for debits â†’ Extract schema fields\n",
    "\n",
    "### Critical Features:\n",
    "- âŒ **No Turn 2** - LLM filtering mixes up rows!\n",
    "- âœ… **Python filtering** - Reliable debit/credit separation\n",
    "- âœ… **Dynamic examples** - Adapt to 3/4/5 column formats\n",
    "- âœ… **Markdown teaching** - Llama understands markdown format for alignment\n",
    "- âœ… **Tax accuracy** - Correct Debit/Credit separation critical for identifying purchases\n",
    "\n",
    "### Why This Works:\n",
    "- **Turn 0**: Clean context â†’ accurate header identification\n",
    "- **Turn 1**: Dynamic example + markdown alignment rules â†’ accurate table extraction\n",
    "- **Python**: Reliable filtering for debit transactions (what taxpayer PAID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Set random seed\n",
    "\n",
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Loading Llama-3.2-Vision model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">ğŸš€ Loading Llama Vision model with robust multi-GPU optimization...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mğŸš€ Loading Llama Vision model with robust multi-GPU optimization\u001b[0m\u001b[1;34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Features: Smart quantization, memory management, V100 support</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFeatures: Smart quantization, memory management, V100 support\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”§ Configuring CUDA memory for Llama...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”§ Configuring CUDA memory for Llama\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ CUDA memory allocation configured: max_split_size_mb:64\n",
      "ğŸ’¡ Using 64MB memory blocks to reduce fragmentation\n",
      "ğŸ“Š Initial CUDA state (Multi-GPU Total): Allocated=0.00GB, Reserved=0.00GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ” Performing robust GPU memory detection...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ” Performing robust GPU memory detection\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Starting robust GPU memory detection...\n",
      "ğŸ“Š Detected 2 GPU(s), analyzing each device...\n",
      "   GPU 0 (NVIDIA L40S): 44.5GB total, 44.5GB available\n",
      "   GPU 1 (NVIDIA L40S): 44.5GB total, 44.5GB available\n",
      "\n",
      "======================================================================\n",
      "ğŸ” ROBUST GPU MEMORY DETECTION REPORT\n",
      "======================================================================\n",
      "âœ… Success: 2/2 GPUs detected\n",
      "ğŸ“Š Total Memory: 89.04GB\n",
      "ğŸ’¾ Available Memory: 89.04GB\n",
      "âš¡ Allocated Memory: 0.00GB\n",
      "ğŸ”„ Reserved Memory: 0.00GB\n",
      "ğŸ“¦ Fragmentation: 0.00GB\n",
      "ğŸ–¥ï¸  Multi-GPU: Yes\n",
      "âš–ï¸  Balanced Distribution: Yes\n",
      "\n",
      "ğŸ“‹ Per-GPU Breakdown:\n",
      "   GPU 0 (NVIDIA L40S): 44.5GB total, 44.5GB available (0.0% used)\n",
      "   GPU 1 (NVIDIA L40S): 44.5GB total, 44.5GB available (0.0% used)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ“Š GPU Hardware: NVIDIA L40S </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">2x 45GB = 89GB total</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ“Š GPU Hardware: NVIDIA L40S \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34m2x 45GB = 89GB total\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ—ï¸ Architecture: workstation_high_memory </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">dynamic detection</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ—ï¸ Architecture: workstation_high_memory \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mdynamic detection\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ¯ Model: Llama-</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3.2</span><span style=\"color: #000080; text-decoration-color: #000080\">-11B-Vision </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">estimated need: 22GB + </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">6.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB buffer</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ¯ Model: Llama-\u001b[0m\u001b[1;34m3.2\u001b[0m\u001b[34m-11B-Vision \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mestimated need: 22GB + \u001b[0m\u001b[1;34m6.\u001b[0m\u001b[34m0GB buffer\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ’¾ Available Memory: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">89.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB across </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">GPU(</span><span style=\"color: #000080; text-decoration-color: #000080\">s</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ’¾ Available Memory: \u001b[0m\u001b[1;34m89.\u001b[0m\u001b[34m0GB across \u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mGPU\u001b[0m\u001b[1;34m(\u001b[0m\u001b[34ms\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ’¡ Memory sufficient: âœ… Yes</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ’¡ Memory sufficient: âœ… Yes\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… workstation_high_memory with 89GB - running in full precision as requested</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… workstation_high_memory with 89GB - running in full precision as requested\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ“Š FINAL QUANTIZATION DECISION: DISABLED (full precision)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mğŸ“Š FINAL QUANTIZATION DECISION: DISABLED \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mfull precision\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Total GPU Memory: 89GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Total GPU Memory: 89GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Available Memory: 89GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Available Memory: 89GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Model needs: ~22GB + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>0GB buffer for Llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>-11B-Vision\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Model needs: ~22GB + \u001b[1;36m6.\u001b[0m0GB buffer for Llama-\u001b[1;36m3.2\u001b[0m-11B-Vision\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Working GPUs: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008080; text-decoration-color: #008080\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Working GPUs: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[36m/\u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ğŸš€ Using </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">16</span><span style=\"color: #008000; text-decoration-color: #008000\">-bit precision for optimal performance</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mğŸš€ Using \u001b[0m\u001b[1;32m16\u001b[0m\u001b[32m-bit precision for optimal performance\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading Llama Vision model...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading Llama Vision model\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”„ Auto-distributing model across </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> GPUs...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”„ Auto-distributing model across \u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m GPUs\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e11853c2f354ada818c55639316719a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading processor...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading processor\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model and processor loaded successfully!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model and processor loaded successfully!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”„ Multi-GPU Distribution Analysis </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> GPUs</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span><span style=\"color: #000080; text-decoration-color: #000080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”„ Multi-GPU Distribution Analysis \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m GPUs\u001b[0m\u001b[1;34m)\u001b[0m\u001b[34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"font-weight: bold\">(</span>NVIDIA L40S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>8GB/48GB <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.8</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   GPU \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mNVIDIA L40S\u001b[1m)\u001b[0m: \u001b[1;36m9.\u001b[0m8GB/48GB \u001b[1m(\u001b[0m\u001b[1;36m20.8\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>NVIDIA L40S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.</span>6GB/48GB <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.4</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   GPU \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mNVIDIA L40S\u001b[1m)\u001b[0m: \u001b[1;36m11.\u001b[0m6GB/48GB \u001b[1m(\u001b[0m\u001b[1;36m24.4\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ“Š Total across all GPUs: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">21.</span><span style=\"color: #000080; text-decoration-color: #000080\">3GB allocated, </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">21.</span><span style=\"color: #000080; text-decoration-color: #000080\">6GB reserved, 96GB capacity</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ“Š Total across all GPUs: \u001b[0m\u001b[1;34m21.\u001b[0m\u001b[34m3GB allocated, \u001b[0m\u001b[1;34m21.\u001b[0m\u001b[34m6GB reserved, 96GB capacity\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model successfully distributed across GPUs</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model successfully distributed across GPUs\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> modules\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;36m0\u001b[0m: \u001b[1;36m18\u001b[0m modules\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> modules\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;36m1\u001b[0m: \u001b[1;36m28\u001b[0m modules\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                            ğŸ”§ Llama Vision Model Configuration                            </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Setting             </span>â”ƒ<span style=\"font-weight: bold\"> Value                         </span>â”ƒ<span style=\"font-weight: bold\"> Llama Status                      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model Path          </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> Llama-3.2-11B-Vision-Instruct </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Valid                          </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Device Placement    </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> cuda:0                        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Loaded                         </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Quantization Method </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 16-bit                        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… 16-bit (Performance Optimized) </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Data Type           </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> bfloat16                      </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Recommended                    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Max New Tokens      </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 2000                          </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Generation Ready               </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> GPU Configuration   </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 2x NVIDIA L40S (96GB)         </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… 96GB Total                     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model Parameters    </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 10,670,220,835                </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Loaded                         </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Memory Optimization </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> Llama Robust                  </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… V100 Compatible                </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                            ğŸ”§ Llama Vision Model Configuration                            \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mSetting            \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mValue                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mLlama Status                     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel Path         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mLlama-3.2-11B-Vision-Instruct\u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Valid                         \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mDevice Placement   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mcuda:0                       \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Loaded                        \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mQuantization Method\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m16-bit                       \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… 16-bit (Performance Optimized)\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mData Type          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mbfloat16                     \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Recommended                   \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mMax New Tokens     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m2000                         \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Generation Ready              \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mGPU Configuration  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m2x NVIDIA L40S (96GB)        \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… 96GB Total                    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel Parameters   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m10,670,220,835               \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Loaded                        \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mMemory Optimization\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mLlama Robust                 \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… V100 Compatible               \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Running model compatibility test...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mRunning model compatibility test\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model compatibility test passed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model compatibility test passed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Performing initial memory cleanup...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mPerforming initial memory cleanup\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸ§¹ Memory cleanup completed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸ§¹ Memory cleanup completed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸ’¾ Final state <span style=\"font-weight: bold\">(</span>Multi-GPU Total<span style=\"font-weight: bold\">)</span>: <span style=\"color: #808000; text-decoration-color: #808000\">Allocated</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>34GB, <span style=\"color: #808000; text-decoration-color: #808000\">Reserved</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>65GB, <span style=\"color: #808000; text-decoration-color: #808000\">Fragmentation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>30GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸ’¾ Final state \u001b[1m(\u001b[0mMulti-GPU Total\u001b[1m)\u001b[0m: \u001b[33mAllocated\u001b[0m=\u001b[1;36m21\u001b[0m\u001b[1;36m.\u001b[0m34GB, \u001b[33mReserved\u001b[0m=\u001b[1;36m21\u001b[0m\u001b[1;36m.\u001b[0m65GB, \u001b[33mFragmentation\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0m30GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ‰ Llama Vision model loading and validation complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mğŸ‰ Llama Vision model loading and validation complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”§ Llama optimizations active: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">16</span><span style=\"color: #000080; text-decoration-color: #000080\">-bit precision, memory management, vision preservation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”§ Llama optimizations active: \u001b[0m\u001b[1;34m16\u001b[0m\u001b[34m-bit precision, memory management, vision preservation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model weights tied successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Load Llama-3.2-Vision model\n",
    "# Update this path to your local Llama model\n",
    "# model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"ğŸ”§ Loading Llama-3.2-Vision model...\")\n",
    "# model = MllamaForConditionalGeneration.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_id,\n",
    "    use_quantization=False,\n",
    "    device_map='auto',\n",
    "    max_new_tokens=2000,\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Add tie_weights() call\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    print(\"âœ… Model weights tied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ tie_weights() warning: {e}\")\n",
    "\n",
    "# processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Loading image...\n",
      "âœ… Image loaded: (753, 584)\n",
      "âœ… Images list created with 1 image(s)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Load bank statement image\n",
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_amount_balance.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_date_grouped_cont.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_highligted.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/low_contrast_fixed.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/nab_classic_highligted.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/westpac_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/transaction_summary.png\"\n",
    "\n",
    "\n",
    "\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/images/image_009.png\"\n",
    "print(\"ğŸ“ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"âœ… Image loaded: {image.size}\")\n",
    "print(f\"âœ… Images list created with {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Statement Extraction Protocol\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract full table using dynamic markdown example\n",
    "- Python: Parse, filter, and extract schema fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ TURN 0: Identifying actual table headers\n",
      "ğŸ¤– Generating response with Llama-3.2-Vision...\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Turn 0 - Identify table headers (prompt)\n",
    "# TURN 0: Identify Table Headers\n",
    "# First, identify the actual column headers used in this specific bank statement\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "IMPORTANT STRUCTURAL NOTE:\n",
    "Some bank statements show dates as section headings with multiple transactions underneath.\n",
    "If you see this structure, remember that each transaction needs its explicit date in the final output.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ’¬ TURN 0: Identifying actual table headers\")\n",
    "print(\"ğŸ¤– Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Response generated successfully!\n",
      "\n",
      "============================================================\n",
      "TURN 0 - IDENTIFIED TABLE HEADERS:\n",
      "============================================================\n",
      "**Transaction Table Column Headers:**\n",
      "\n",
      "*   **Date**\n",
      "*   **Description**\n",
      "*   **Credits**\n",
      "*   **Debits**\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Parsed 4 column headers:\n",
      "  1. 'Date'\n",
      "  2. 'Description'\n",
      "  3. 'Credits'\n",
      "  4. 'Debits'\n",
      "\n",
      "âœ… Table headers saved to: llama_table_headers.txt\n",
      "ğŸ’¡ These LITERAL header names will be used in Turn 1 & 2 prompts\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Turn 0 - Execute and parse headers\n",
    "# Process the input using the CORRECT multi-turn pattern\n",
    "# Based on: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' with list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response with deterministic parameters\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output (this is the key to clean responses!)\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"âœ… Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CRITICAL: Parse the identified headers for use in subsequent turns\n",
    "# Extract column names from the response\n",
    "header_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\n",
    "identified_headers = []\n",
    "\n",
    "# Look for numbered list or bullet points\n",
    "for line in header_lines:\n",
    "    # Remove common list markers\n",
    "    cleaned = line.lstrip('0123456789.-â€¢* ').strip()\n",
    "    \n",
    "    # Strip markdown bold formatting\n",
    "    cleaned = cleaned.replace('**', '').replace('__', '')\n",
    "    \n",
    "    # Skip section headers (lines ending with colon)\n",
    "    if cleaned.endswith(':'):\n",
    "        continue\n",
    "    \n",
    "    # Skip long sentences (likely explanatory text, not headers)\n",
    "    if len(cleaned) > 40:\n",
    "        continue\n",
    "        \n",
    "    if cleaned and len(cleaned) > 2:  # Ignore very short strings\n",
    "        identified_headers.append(cleaned)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Parsed {len(identified_headers)} column headers:\")\n",
    "for i, header in enumerate(identified_headers, 1):\n",
    "    print(f\"  {i}. '{header}'\")\n",
    "\n",
    "# Store headers for use in subsequent turns\n",
    "table_headers = identified_headers\n",
    "\n",
    "# Save the table headers\n",
    "output_path = Path(\"llama_table_headers.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput)\n",
    "\n",
    "print(f\"\\nâœ… Table headers saved to: {output_path}\")\n",
    "print(\"ğŸ’¡ These LITERAL header names will be used in Turn 1 & 2 prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PATTERN MATCHING RESULTS:\n",
      "============================================================\n",
      "ğŸ“‹ Extracted Headers: ['Date', 'Description', 'Credits', 'Debits']\n",
      "\n",
      "ğŸ” Mapped Columns:\n",
      "  Date        â†’ 'Date'\n",
      "  Description â†’ 'Description'\n",
      "  Debit       â†’ 'Debits'\n",
      "  Credit      â†’ 'Credits'\n",
      "  Balance     â†’ 'Balance'\n",
      "============================================================\n",
      "\n",
      "âœ… These literal column names will be used in Turn 1 and Turn 2\n",
      "ğŸ’¡ Adjust patterns above if matching fails for your bank statement format\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Pattern Matching - Map headers to generic columns\n",
    "# Pattern Matching: Map extracted headers to generic concepts\n",
    "# This handles variety in bank statement column naming conventions\n",
    "\n",
    "# Pattern keywords for each concept (in priority order)\n",
    "DATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\n",
    "DESCRIPTION_PATTERNS = [\n",
    "    'description', 'details', 'transaction details', 'trans details',\n",
    "    'particulars', 'narrative', 'transaction', 'trans'\n",
    "]\n",
    "DEBIT_PATTERNS = ['debit', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\n",
    "CREDIT_PATTERNS = ['credit', 'deposit', 'deposits', 'received', 'cr']\n",
    "BALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n",
    "\n",
    "# NEW: Pattern for single-column transaction formats (e.g., \"Amount\" instead of separate Debit/Credit)\n",
    "AMOUNT_PATTERNS = ['amount', 'amt', 'value', 'total']\n",
    "\n",
    "def match_header(headers, patterns, fallback=None):\n",
    "    \"\"\"Match a header using pattern keywords.\n",
    "    \n",
    "    Matching strategy:\n",
    "    1. Exact match (case-insensitive)\n",
    "    2. Substring match (only for patterns with length > 2 to avoid false positives)\n",
    "    \"\"\"\n",
    "    headers_lower = [h.lower() for h in headers]\n",
    "    \n",
    "    # Try exact match first\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern == header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    # Try substring match (only for patterns longer than 2 chars)\n",
    "    for pattern in patterns:\n",
    "        if len(pattern) > 2:  # Avoid false positives like 'cr' matching 'description'\n",
    "            for i, header_lower in enumerate(headers_lower):\n",
    "                if pattern in header_lower:\n",
    "                    return headers[i]\n",
    "    \n",
    "    return fallback\n",
    "\n",
    "# Perform pattern matching on extracted headers\n",
    "date_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\n",
    "desc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n",
    "\n",
    "# NEW: First try to match a generic \"Amount\" column (for 4-column formats)\n",
    "amount_col = match_header(table_headers, AMOUNT_PATTERNS, fallback=None)\n",
    "\n",
    "# Use amount_col as fallback if no separate debit/credit columns exist\n",
    "# This handles formats like: Date | Description | Amount | Balance\n",
    "debit_col = match_header(table_headers, DEBIT_PATTERNS, fallback=amount_col if amount_col else 'Debit')\n",
    "credit_col = match_header(table_headers, CREDIT_PATTERNS, fallback=amount_col if amount_col else 'Credit')\n",
    "balance_col = match_header(table_headers, BALANCE_PATTERNS, fallback='Balance')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATTERN MATCHING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“‹ Extracted Headers: {table_headers}\")\n",
    "print(f\"\\nğŸ” Mapped Columns:\")\n",
    "print(f\"  Date        â†’ '{date_col}'\")\n",
    "print(f\"  Description â†’ '{desc_col}'\")\n",
    "print(f\"  Debit       â†’ '{debit_col}'\")\n",
    "print(f\"  Credit      â†’ '{credit_col}'\")\n",
    "print(f\"  Balance     â†’ '{balance_col}'\")\n",
    "if amount_col:\n",
    "    print(f\"\\nğŸ’¡ Single-column format detected: '{amount_col}' used for both debit and credit\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nâœ… These literal column names will be used in Turn 1 and Turn 2\")\n",
    "print(\"ğŸ’¡ Adjust patterns above if matching fails for your bank statement format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”‘ Independent Single-Turn Pattern (NOT Multi-Turn Conversation)\n",
    "\n",
    "**CRITICAL INSIGHT**: Multi-turn conversation accumulates context and degrades accuracy.\n",
    "\n",
    "We use **two independent single-turn prompts**, each with fresh context:\n",
    "\n",
    "#### Key Principles:\n",
    "\n",
    "1. **No Conversation History**: Each turn is completely independent\n",
    "2. **Fresh Image Attention**: Each turn processes the image directly\n",
    "3. **No Context Accumulation**: Prevents attention dilution\n",
    "4. **Headers as Parameters**: Turn 0 headers used to generate dynamic examples for Turn 1\n",
    "5. **Python Filtering**: LLM filtering mixes up rows - Python is reliable\n",
    "\n",
    "#### Message Structure for Each Turn:\n",
    "\n",
    "Every turn uses fresh structure:\n",
    "```python\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"<prompt with dynamic example>\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "**No assistant responses in history. No conversation accumulation.**\n",
    "\n",
    "#### Why This Works Better:\n",
    "\n",
    "- **Turn 0**: Clean context â†’ accurate header identification\n",
    "- **Turn 1**: Clean context + dynamic example â†’ accurate table extraction  \n",
    "- **Python**: Reliable parsing and filtering (no row mixing!)\n",
    "\n",
    "Each turn has **full attention** on the image, not diluted by conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Independent turn approach - NO conversation history\n",
      "ğŸ’¡ Each turn has fresh context with direct image access\n",
      "ğŸ Python handles all filtering - no LLM row mixing!\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: NO conversation history (independent turns)\n",
    "# \n",
    "# CRITICAL: We do NOT use conversation history in this notebook.\n",
    "# Each turn is completely independent with fresh context.\n",
    "#\n",
    "# Why? Multi-turn conversation accumulates context and degrades accuracy:\n",
    "# - Turn 0: ~50 tokens â†’ accurate\n",
    "# - Turn 1 with history: ~350 tokens â†’ attention diluted â†’ less accurate\n",
    "# - Turn 2 with history: ~2000 tokens â†’ attention heavily diluted â†’ row mixing!\n",
    "#\n",
    "# Instead: \n",
    "# - Turn 0: Fresh context â†’ headers\n",
    "# - Turn 1: Fresh context + dynamic example â†’ full table\n",
    "# - Python: Parse and filter (no LLM confusion!)\n",
    "\n",
    "print(\"âœ… Independent turn approach - NO conversation history\")\n",
    "print(\"ğŸ’¡ Each turn has fresh context with direct image access\")\n",
    "print(\"ğŸ Python handles all filtering - no LLM row mixing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 1: Extract Full Table in Markdown\n",
    "\n",
    "Now that we know the actual column headers, extract the complete table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ TURN 1: Extract full markdown table (INDEPENDENT)\n",
      "ğŸ“‹ Detected headers: ['Date', 'Description', 'Credits', 'Debits']\n",
      "ğŸ’¡ Dynamic example generated - emphasizing Debit/Credit column alignment\n",
      "ğŸ”„ Fresh context (no conversation history)\n",
      "ğŸ¤– Generating response with Llama-3.2-Vision...\n",
      "\n",
      "âœ… Follow-up response generated successfully!\n",
      "\n",
      "============================================================\n",
      "TURN 1 - FULL MARKDOWN TABLE:\n",
      "============================================================\n",
      "| Date | Description | Credits | Debits |\n",
      "| --- | --- | --- | --- |\n",
      "| 05 Sep 2023 | Otr Supermarket 9876 Sydney Aus |  | 45.80 |\n",
      "| 06 Sep 2023 | Otr Convenience 4321 Melbourne Aus |  | 28.45 |\n",
      "| 06 Sep 2023 | Otr Convenience 4321 Melbourne Aus |  | 15.90 |\n",
      "| 07 Sep 2023 | Retailstore 8765 Perth Aus |  | 12.35 |\n",
      "| 07 Sep 2023 | Otr Convenience 4321 Melbourne Aus |  | 34.60 |\n",
      "| 07 Sep 2023 | Valley Shopping Ct Brisbane Aus |  | 67.00 |\n",
      "| 07 Sep 2023 | Plaza Hotel Sydney Sydney Cre Aus | 89.00 |  |\n",
      "| 07 Sep 2023 | Plaza Hotel Sydney Sydney Cre Aus | 23.50 |  |\n",
      "| 07 Sep 2023 | Department Store Pl Adelaide Aus | 156.95 |  |\n",
      "| 07 Sep 2023 | Plaza Motorcycl Brisbane Aus | 245.00 |  |\n",
      "| 07 Sep 2023 | Plaza Hotel Sydney Sydney Cre Aus | 389.00 |  |\n",
      "| 07 Sep 2023 | Value Retail Pty Newcastle South Aus | 12.80 |  |\n",
      "| 08 Sep 2023 | Office Supplies Brisbane Aus | 78.45 |  |\n",
      "| 08 Sep 2023 | Valley Shop Brisbane Aus | 45.30 |  |\n",
      "| 09 Sep 2023 | Brisbane Store Brisbane Aus | 23.90 |  |\n",
      "| 10 Sep 2023 | Value Family Trust Brisbane Aus | 890.00 |  |\n",
      "============================================================\n",
      "\n",
      "âœ… Markdown table saved to: llama_markdown_table_extraction.txt\n",
      "ğŸ’¡ Ready for Python parsing and filtering\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Turn 1 - Extract full table (INDEPENDENT, fresh context)\n",
    "\n",
    "# Build the header string using LITERAL names from Turn 0\n",
    "header_string = \" | \".join(table_headers)\n",
    "separator_row = \" | \".join([\"---\"] * len(table_headers))\n",
    "\n",
    "# Build dynamic example rows based on detected column structure\n",
    "# CRITICAL: Examples must emphasize correct Debit/Credit column alignment!\n",
    "def build_dynamic_example(headers, date_col, desc_col, debit_col, credit_col, balance_col):\n",
    "    \"\"\"Generate example rows matching detected column structure.\n",
    "    \n",
    "    Emphasizes correct Debit/Credit alignment for tax purposes:\n",
    "    - Debits (purchases/withdrawals) = money OUT = what taxpayer PAID\n",
    "    - Credits (deposits/income) = money IN = NOT purchases\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if we have separate debit/credit columns\n",
    "    has_separate_debit_credit = (debit_col in headers and credit_col in headers and debit_col != credit_col)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    if has_separate_debit_credit:\n",
    "        # 5-column format: Emphasize Debit vs Credit with clear examples\n",
    "        \n",
    "        # Example 1: DEBIT transaction (purchase/withdrawal) - money OUT\n",
    "        row1 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row1.append(\"15 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row1.append(\"ATM Withdrawal City Branch\")\n",
    "            elif h == debit_col:\n",
    "                row1.append(\"200.00\")  # Amount in DEBIT column\n",
    "            elif h == credit_col:\n",
    "                row1.append(\"\")  # Credit column EMPTY\n",
    "            elif h == balance_col:\n",
    "                row1.append(\"$1,500.00 CR\")\n",
    "            else:\n",
    "                row1.append(\"\")\n",
    "        rows.append(\" | \".join(row1))\n",
    "        \n",
    "        # Example 2: CREDIT transaction (deposit) - money IN\n",
    "        row2 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row2.append(\"16 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row2.append(\"Salary Employer Name Ref 12345\")\n",
    "            elif h == debit_col:\n",
    "                row2.append(\"\")  # Debit column EMPTY\n",
    "            elif h == credit_col:\n",
    "                row2.append(\"3,500.00\")  # Amount in CREDIT column\n",
    "            elif h == balance_col:\n",
    "                row2.append(\"$5,000.00 CR\")\n",
    "            else:\n",
    "                row2.append(\"\")\n",
    "        rows.append(\" | \".join(row2))\n",
    "        \n",
    "        # Example 3: Another DEBIT transaction (purchase)\n",
    "        row3 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row3.append(\"17 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row3.append(\"Online Purchase Store Name\")\n",
    "            elif h == debit_col:\n",
    "                row3.append(\"150.00\")  # Amount in DEBIT column\n",
    "            elif h == credit_col:\n",
    "                row3.append(\"\")  # Credit column EMPTY\n",
    "            elif h == balance_col:\n",
    "                row3.append(\"$4,850.00 CR\")\n",
    "            else:\n",
    "                row3.append(\"\")\n",
    "        rows.append(\" | \".join(row3))\n",
    "        \n",
    "    else:\n",
    "        # 4-column format: Single Amount column\n",
    "        row1 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row1.append(\"15 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row1.append(\"ATM Withdrawal City Branch\")\n",
    "            elif h == debit_col:  # This is the Amount column\n",
    "                row1.append(\"200.00\")\n",
    "            elif h == balance_col:\n",
    "                row1.append(\"$1,500.00 CR\")\n",
    "            else:\n",
    "                row1.append(\"\")\n",
    "        rows.append(\" | \".join(row1))\n",
    "        \n",
    "        row2 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row2.append(\"16 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row2.append(\"Salary Employer Name Ref 12345\")\n",
    "            elif h == debit_col:  # This is the Amount column\n",
    "                row2.append(\"3,500.00\")\n",
    "            elif h == balance_col:\n",
    "                row2.append(\"$5,000.00 CR\")\n",
    "            else:\n",
    "                row2.append(\"\")\n",
    "        rows.append(\" | \".join(row2))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "# Generate dynamic example rows\n",
    "example_rows = build_dynamic_example(table_headers, date_col, desc_col, debit_col, credit_col, balance_col)\n",
    "\n",
    "# Build complete example table\n",
    "example_table = f\"\"\"| {header_string} |\n",
    "| {separator_row} |\n",
    "\"\"\" + \"\\n\".join([f\"| {row} |\" for row in example_rows])\n",
    "\n",
    "follow_up_prompt = f\"\"\"\n",
    "Extract ONLY the MAIN transaction table from this bank statement image in markdown format.\n",
    "\n",
    "Here is an example showing the EXACT format and column alignment I want:\n",
    "\n",
    "{example_table}\n",
    "\n",
    "CRITICAL EXTRACTION RULES:\n",
    "1. EACH ROW MUST be ALIGNED UNDER the CORRECT COLUMN HEADING\n",
    "2. If you see a transaction row that looks like:\n",
    "      a date |  line 1  |  | amount1 | amount2\n",
    "             |  line 2  |  |         |\n",
    "    you must extract it as:\n",
    "      a date |  line 1 line 2 |  | amount1 | amount2\n",
    "3. If you see a transaction row that looks like:\n",
    "      a date |  line 1  | amount1 |  | amount2\n",
    "             |  line 2  |         |  |\n",
    "    you must extract it as:\n",
    "      a date |  line 1 line 2 | amount1 |  | amount2\n",
    "4. Look at which column each amount appears under in the image - put it in that SAME column in your table\n",
    "5. If a column is empty in the image, leave it empty in your table (spaces between pipes: |  |)\n",
    "6. IGNORE ANY OTHER TABLES that may exist (like summary tables or interest rate tables)\n",
    "7. DO NOT ADD ANY further information or explanation - ONLY output the markdown table\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# CRITICAL: Create FRESH message structure (NOT appending to conversation history)\n",
    "messageDataStructure_turn1 = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": follow_up_prompt}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"ğŸ’¬ TURN 1: Extract full markdown table (INDEPENDENT)\")\n",
    "print(f\"ğŸ“‹ Detected headers: {table_headers}\")\n",
    "print(f\"ğŸ’¡ Dynamic example generated - emphasizing Debit/Credit column alignment\")\n",
    "print(f\"ğŸ”„ Fresh context (no conversation history)\")\n",
    "print(\"ğŸ¤– Generating response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with FRESH context\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure_turn1, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' with list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput2 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\nâœ… Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 1 - FULL MARKDOWN TABLE:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput2)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save the markdown table\n",
    "output_path = Path(\"llama_markdown_table_extraction.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput2)\n",
    "\n",
    "print(f\"\\nâœ… Markdown table saved to: {output_path}\")\n",
    "print(\"ğŸ’¡ Ready for Python parsing and filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Parsing and Filtering\n",
    "\n",
    "Parse the Turn 1 markdown table, filter for debit transactions, and extract schema fields using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PARSING TURN 1 MARKDOWN TABLE:\n",
      "============================================================\n",
      "ğŸ” Debug: Parsed 4 headers: ['Date', 'Description', 'Credits', 'Debits']\n",
      "ğŸ” Debug row 2: 4 values: ['05 Sep 2023', 'Otr Supermarket 9876 Sydney Aus', '', '45.80']\n",
      "ğŸ” Debug row 3: 4 values: ['06 Sep 2023', 'Otr Convenience 4321 Melbourne Aus', '', '28.45']\n",
      "ğŸ” Debug row 4: 4 values: ['06 Sep 2023', 'Otr Convenience 4321 Melbourne Aus', '', '15.90']\n",
      "ğŸ” Debug row 5: 4 values: ['07 Sep 2023', 'Retailstore 8765 Perth Aus', '', '12.35']\n",
      "ğŸ” Debug row 6: 4 values: ['07 Sep 2023', 'Otr Convenience 4321 Melbourne Aus', '', '34.60']\n",
      "ğŸ” Debug row 7: 4 values: ['07 Sep 2023', 'Valley Shopping Ct Brisbane Aus', '', '67.00']\n",
      "ğŸ” Debug row 8: 4 values: ['07 Sep 2023', 'Plaza Hotel Sydney Sydney Cre Aus', '89.00', '']\n",
      "ğŸ” Debug row 9: 4 values: ['07 Sep 2023', 'Plaza Hotel Sydney Sydney Cre Aus', '23.50', '']\n",
      "ğŸ” Debug row 10: 4 values: ['07 Sep 2023', 'Department Store Pl Adelaide Aus', '156.95', '']\n",
      "ğŸ” Debug row 11: 4 values: ['07 Sep 2023', 'Plaza Motorcycl Brisbane Aus', '245.00', '']\n",
      "ğŸ” Debug row 12: 4 values: ['07 Sep 2023', 'Plaza Hotel Sydney Sydney Cre Aus', '389.00', '']\n",
      "ğŸ” Debug row 13: 4 values: ['07 Sep 2023', 'Value Retail Pty Newcastle South Aus', '12.80', '']\n",
      "ğŸ” Debug row 14: 4 values: ['08 Sep 2023', 'Office Supplies Brisbane Aus', '78.45', '']\n",
      "ğŸ” Debug row 15: 4 values: ['08 Sep 2023', 'Valley Shop Brisbane Aus', '45.30', '']\n",
      "ğŸ” Debug row 16: 4 values: ['09 Sep 2023', 'Brisbane Store Brisbane Aus', '23.90', '']\n",
      "ğŸ” Debug row 17: 4 values: ['10 Sep 2023', 'Value Family Trust Brisbane Aus', '890.00', '']\n",
      "\n",
      "ğŸ“Š Parsed 16 total transactions from Turn 1 markdown table\n",
      "\n",
      "ğŸ” Sample parsed row:\n",
      "  Date: '05 Sep 2023'\n",
      "  Description: 'Otr Supermarket 9876 Sydney Aus'\n",
      "  Credits: ''\n",
      "  Debits: '45.80'\n",
      "\n",
      "ğŸ’° Filtered to 6 debit transactions (taxpayer purchases)\n",
      "\n",
      "============================================================\n",
      "DEBIT TRANSACTIONS (WHAT TAXPAYER PAID):\n",
      "============================================================\n",
      "\n",
      "Transaction 1:\n",
      "  Date: 05 Sep 2023\n",
      "  Description: Otr Supermarket 9876 Sydney Aus\n",
      "  Debits: 45.80\n",
      "\n",
      "Transaction 2:\n",
      "  Date: 06 Sep 2023\n",
      "  Description: Otr Convenience 4321 Melbourne Aus\n",
      "  Debits: 28.45\n",
      "\n",
      "Transaction 3:\n",
      "  Date: 06 Sep 2023\n",
      "  Description: Otr Convenience 4321 Melbourne Aus\n",
      "  Debits: 15.90\n",
      "\n",
      "Transaction 4:\n",
      "  Date: 07 Sep 2023\n",
      "  Description: Retailstore 8765 Perth Aus\n",
      "  Debits: 12.35\n",
      "\n",
      "Transaction 5:\n",
      "  Date: 07 Sep 2023\n",
      "  Description: Otr Convenience 4321 Melbourne Aus\n",
      "  Debits: 34.60\n",
      "\n",
      "Transaction 6:\n",
      "  Date: 07 Sep 2023\n",
      "  Description: Valley Shopping Ct Brisbane Aus\n",
      "  Debits: 67.00\n",
      "\n",
      "============================================================\n",
      "EXTRACTED SCHEMA FIELDS (TAX-RELEVANT DATA):\n",
      "============================================================\n",
      "TRANSACTION_DATES: 05 Sep 2023 | 06 Sep 2023 | 06 Sep 2023 | 07 Sep 2023 | 07 Sep 2023 | 07 Sep 2023\n",
      "LINE_ITEM_DESCRIPTIONS: Otr Supermarket 9876 Sydney Aus | Otr Convenience 4321 Melbourne Aus | Otr Convenience 4321 Melbourne Aus | Retailstore 8765 Perth Aus | Otr Convenience 4321 Melbourne Aus | Valley Shopping Ct Brisbane Aus\n",
      "TRANSACTION_AMOUNTS_PAID: 45.80 | 28.45 | 15.90 | 12.35 | 34.60 | 67.00\n",
      "STATEMENT_DATE_RANGE: 05 Sep 2023 - 07 Sep 2023\n",
      "============================================================\n",
      "\n",
      "âœ… Schema fields saved to: llama_extracted_fields.txt\n",
      "ğŸ’¡ Fields extracted from columns: 'Date' | 'Description' | 'Debits'\n",
      "ğŸ¯ Success: Python parsing + filtering from Turn 1 markdown table\n"
     ]
    }
   ],
   "source": [
    "# Cell 19: Parse Turn 1 markdown table and filter for debits (Python)\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_markdown_table(markdown_text):\n",
    "    \"\"\"Parse markdown table into list of dictionaries.\n",
    "    \n",
    "    CRITICAL: Must preserve empty columns for correct Debit/Credit alignment!\n",
    "    \"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    # Find header row (first line with pipes)\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line:\n",
    "            # Skip separator rows (contain only pipes, hyphens, and spaces)\n",
    "            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n",
    "            if cleaned:  # Has actual content, not just separators\n",
    "                header_idx = i\n",
    "                break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        return []\n",
    "    \n",
    "    # Parse headers - KEEP empty values to preserve column positions\n",
    "    header_line = lines[header_idx]\n",
    "    header_parts = [h.strip() for h in header_line.split('|')]\n",
    "    # Remove leading/trailing empty strings from pipe delimiters\n",
    "    if header_parts and header_parts[0] == '':\n",
    "        header_parts = header_parts[1:]\n",
    "    if header_parts and header_parts[-1] == '':\n",
    "        header_parts = header_parts[:-1]\n",
    "    # Filter out any remaining empty headers\n",
    "    headers = [h for h in header_parts if h]\n",
    "    \n",
    "    print(f\"ğŸ” Debug: Parsed {len(headers)} headers: {headers}\")\n",
    "    \n",
    "    # Parse data rows (skip header and separator)\n",
    "    rows = []\n",
    "    for idx, line in enumerate(lines[header_idx + 1:], start=header_idx+1):\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "            \n",
    "        # Skip separator rows\n",
    "        cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        \n",
    "        # Parse values - KEEP empty values to preserve column positions!\n",
    "        value_parts = [v.strip() for v in line.split('|')]\n",
    "        # Remove leading/trailing empty strings from pipe delimiters\n",
    "        if value_parts and value_parts[0] == '':\n",
    "            value_parts = value_parts[1:]\n",
    "        if value_parts and value_parts[-1] == '':\n",
    "            value_parts = value_parts[:-1]\n",
    "        \n",
    "        print(f\"ğŸ” Debug row {idx}: {len(value_parts)} values: {value_parts}\")\n",
    "        \n",
    "        # Match to headers length\n",
    "        if len(value_parts) == len(headers):\n",
    "            rows.append(dict(zip(headers, value_parts)))\n",
    "        else:\n",
    "            print(f\"âš ï¸  Row {idx} mismatch: {len(value_parts)} values vs {len(headers)} headers - SKIPPED\")\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def filter_debit_transactions(rows, debit_col):\n",
    "    \"\"\"Filter rows to only those with debit (purchase) amounts.\n",
    "    \n",
    "    CRITICAL: For tax purposes, we only want transactions where taxpayer PAID money (debits).\n",
    "    \"\"\"\n",
    "    debit_rows = []\n",
    "    for row in rows:\n",
    "        debit_value = row.get(debit_col, '').strip()\n",
    "        # Include row if debit column has a value (not empty)\n",
    "        if debit_value:\n",
    "            debit_rows.append(row)\n",
    "    \n",
    "    return debit_rows\n",
    "\n",
    "def extract_schema_fields(rows, date_col, desc_col, debit_col):\n",
    "    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n",
    "    if not rows:\n",
    "        return {\n",
    "            'TRANSACTION_DATES': 'NOT_FOUND',\n",
    "            'LINE_ITEM_DESCRIPTIONS': 'NOT_FOUND',\n",
    "            'TRANSACTION_AMOUNTS_PAID': 'NOT_FOUND',\n",
    "            'STATEMENT_DATE_RANGE': 'NOT_FOUND'\n",
    "        }\n",
    "    \n",
    "    # Extract lists\n",
    "    dates = []\n",
    "    descriptions = []\n",
    "    amounts = []\n",
    "    \n",
    "    for row in rows:\n",
    "        date = row.get(date_col, '').strip()\n",
    "        desc = row.get(desc_col, '').strip()\n",
    "        amount = row.get(debit_col, '').strip()\n",
    "        \n",
    "        if date:\n",
    "            dates.append(date)\n",
    "        if desc:\n",
    "            descriptions.append(desc)\n",
    "        if amount:\n",
    "            amounts.append(amount)\n",
    "    \n",
    "    # Calculate statement date range - use literal date format from image\n",
    "    # No parsing, no year assumption - just \"earliest date - latest date\"\n",
    "    date_range = 'NOT_FOUND'\n",
    "    if dates:\n",
    "        # Use first and last date as-is (same format as in the image)\n",
    "        date_range = f\"{dates[0]} - {dates[-1]}\"\n",
    "    \n",
    "    return {\n",
    "        'TRANSACTION_DATES': ' | '.join(dates) if dates else 'NOT_FOUND',\n",
    "        'LINE_ITEM_DESCRIPTIONS': ' | '.join(descriptions) if descriptions else 'NOT_FOUND',\n",
    "        'TRANSACTION_AMOUNTS_PAID': ' | '.join(amounts) if amounts else 'NOT_FOUND',\n",
    "        'STATEMENT_DATE_RANGE': date_range\n",
    "    }\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PARSING TURN 1 MARKDOWN TABLE:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Parse the full markdown table from Turn 1\n",
    "all_rows = parse_markdown_table(cleanedOutput2)\n",
    "\n",
    "print(f\"\\nğŸ“Š Parsed {len(all_rows)} total transactions from Turn 1 markdown table\")\n",
    "\n",
    "if all_rows:\n",
    "    # Show sample parsed row\n",
    "    print(f\"\\nğŸ” Sample parsed row:\")\n",
    "    for key, value in all_rows[0].items():\n",
    "        print(f\"  {key}: '{value}'\")\n",
    "\n",
    "# Filter to only debit (purchase) transactions - Python filtering, not LLM!\n",
    "debit_rows = filter_debit_transactions(all_rows, debit_col)\n",
    "\n",
    "print(f\"\\nğŸ’° Filtered to {len(debit_rows)} debit transactions (taxpayer purchases)\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEBIT TRANSACTIONS (WHAT TAXPAYER PAID):\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in enumerate(debit_rows, 1):\n",
    "    print(f\"\\nTransaction {i}:\")\n",
    "    print(f\"  {date_col}: {row.get(date_col, '')}\")\n",
    "    print(f\"  {desc_col}: {row.get(desc_col, '')}\")\n",
    "    print(f\"  {debit_col}: {row.get(debit_col, '')}\")\n",
    "\n",
    "# Extract schema fields using the LITERAL column names from pattern matching\n",
    "schema_fields = extract_schema_fields(debit_rows, date_col, desc_col, debit_col)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTED SCHEMA FIELDS (TAX-RELEVANT DATA):\")\n",
    "print(\"=\" * 60)\n",
    "for field, value in schema_fields.items():\n",
    "    print(f\"{field}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save to file\n",
    "output_path = Path(\"llama_extracted_fields.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for field, value in schema_fields.items():\n",
    "        f.write(f\"{field}: {value}\\n\")\n",
    "\n",
    "print(f\"\\nâœ… Schema fields saved to: {output_path}\")\n",
    "print(f\"ğŸ’¡ Fields extracted from columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")\n",
    "print(f\"ğŸ¯ Success: Python parsing + filtering from Turn 1 markdown table\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
