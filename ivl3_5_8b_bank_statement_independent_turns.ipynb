{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# InternVL3.5-8B: Independent Single-Turn Bank Statement Extraction\n",
    "\n",
    "**Protocol**: Two independent single-turn prompts + Python parsing/filtering\n",
    "\n",
    "**Key Insight**: Multi-turn conversation degrades accuracy. LLM filtering mixes up rows. Use Python for filtering!\n",
    "\n",
    "**Model**: InternVL3.5-8B (non-quantized, bfloat16) optimized for H200 GPU\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Turn 0: Image + Prompt ‚Üí Headers (fresh context)\n",
    "        ‚Üì (Python pattern matching)\n",
    "Turn 1: Image + Prompt ‚Üí Full Table (fresh context, dynamic markdown example)\n",
    "        ‚Üì (Python parsing + filtering)\n",
    "Schema Fields: TRANSACTION_DATES, LINE_ITEM_DESCRIPTIONS, TRANSACTION_AMOUNTS_PAID\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to concepts (Date, Description, Debit, Credit)\n",
    "3. **Turn 1 (LLM)**: Extract full markdown table using **dynamic example** matching detected column structure\n",
    "4. **Python Parsing**: Parse markdown ‚Üí Filter for debits ‚Üí Extract schema fields\n",
    "\n",
    "### Critical Features:\n",
    "- ‚ùå **No Turn 2** - LLM filtering mixes up rows!\n",
    "- ‚úÖ **Python filtering** - Reliable debit/credit separation\n",
    "- ‚úÖ **Dynamic examples** - Adapt to 3/4/5 column formats\n",
    "- ‚úÖ **Markdown teaching** - InternVL3.5 understands markdown format for alignment\n",
    "- ‚úÖ **Tax accuracy** - Correct Debit/Credit separation critical for identifying purchases\n",
    "\n",
    "### Why This Works:\n",
    "- **Turn 0**: Clean context ‚Üí accurate header identification\n",
    "- **Turn 1**: Clean context + dynamic example ‚Üí accurate table extraction\n",
    "- **Python**: Reliable filtering for debit transactions (what taxpayer PAID)\n",
    "\n",
    "### Model: InternVL3.5-8B\n",
    "- **Non-quantized** for H200 GPU with 80GB HBM3\n",
    "- **bfloat16** precision for optimal performance\n",
    "- **Flash Attention** enabled for efficiency\n",
    "- Higher capacity than 2B variant\n",
    "- Strong vision-language capabilities\n",
    "- Simple API with `model.chat()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Imports and Configuration\n\nfrom pathlib import Path\nimport random\nimport math\n\nimport numpy as np\nimport torch\nfrom PIL import Image\nfrom transformers import AutoModel, AutoTokenizer\nimport torchvision.transforms as T\nfrom torchvision.transforms.functional import InterpolationMode\n\n# IPython display for rendering markdown\nfrom IPython.display import display, Markdown\n\n# ============================================================================\n# CONFIGURATION - All settings explicit in notebook\n# ============================================================================\nCONFIG = {\n    # Model settings - InternVL3.5-8B (H200 optimized)\n    'MODEL_PATH': '/home/jovyan/nfs_share/models/InternVL3_5-8B',\n    \n    # H200 TILE CONFIGURATION\n    'MAX_TILES': 36,  # H200 optimized - InternVL3.5 training max for dense OCR\n    \n    # Generation settings\n    'MAX_NEW_TOKENS': 2000,\n    \n    # H200 precision settings\n    'TORCH_DTYPE': 'bfloat16',\n    'USE_FLASH_ATTN': True,\n}\n\nprint(\"‚úÖ Imports loaded\")\nprint(f\"üî≤ Max Tiles: {CONFIG['MAX_TILES']} (H200 optimized)\")\nprint(f\"ü§ñ Model: {Path(CONFIG['MODEL_PATH']).name}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Set random seed\n",
    "\n",
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 5: Load InternVL3.5-8B model (non-quantized for H200)\n\nprint(\"üîß Loading InternVL3.5-8B (non-quantized, bfloat16) for H200 GPU...\")\n\n# Load model with bfloat16 and flash attention for H200\nmodel = AutoModel.from_pretrained(\n    CONFIG['MODEL_PATH'],\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    low_cpu_mem_usage=True,\n    use_flash_attn=CONFIG['USE_FLASH_ATTN'],\n).eval()\n\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    CONFIG['MODEL_PATH'],\n    trust_remote_code=True,\n    use_fast=False\n)\n\n# Set generation config on model\nmodel.config.max_new_tokens = CONFIG['MAX_NEW_TOKENS']\n\n# Fix pad_token_id to suppress warnings\nif tokenizer.pad_token_id is None:\n    tokenizer.pad_token_id = tokenizer.eos_token_id\n\nprint(f\"‚úÖ InternVL3.5-8B model loaded successfully!\")\nprint(f\"‚úÖ Model distributed across devices: {model.hf_device_map}\")\nprint(f\"üìä Parameters: {sum(p.numel() for p in model.parameters()):,}\")\nprint(f\"üìä Precision: bfloat16 with flash attention\")\nprint(f\"üî≤ Max Tiles: {CONFIG['MAX_TILES']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load bank statement image\n",
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_amount_balance.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_date_grouped_cont.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/cba_highligted.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/low_contrast_fixed.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/nab_classic_highligted.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/westpac_debit_credit.png\"\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/synthetic_bank_images/transaction_summary.png\"\n",
    "\n",
    "print(\"üìÅ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"‚úÖ Image loaded: {image.size}\")\n",
    "print(f\"‚úÖ Images list created with {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the loaded image for visual verification\n",
    "print(\"üñºÔ∏è  Bank statement image:\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 9: Image preprocessing for InternVL3.5 (Official implementation)\n\n# Official InternVL3 image preprocessing (from docs)\nIMAGENET_MEAN = (0.485, 0.456, 0.406)\nIMAGENET_STD = (0.229, 0.224, 0.229)\n\ndef build_transform(input_size):\n    \"\"\"Build image transformation pipeline with ImageNet normalization.\"\"\"\n    transform = T.Compose([\n        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n        T.ToTensor(),\n        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n    ])\n    return transform\n\ndef find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n    \"\"\"Find the closest aspect ratio from target ratios based on image dimensions.\"\"\"\n    best_ratio_diff = float('inf')\n    best_ratio = (1, 1)\n    area = width * height\n    for ratio in target_ratios:\n        target_aspect_ratio = ratio[0] / ratio[1]\n        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n        if ratio_diff < best_ratio_diff:\n            best_ratio_diff = ratio_diff\n            best_ratio = ratio\n        elif ratio_diff == best_ratio_diff:\n            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n                best_ratio = ratio\n    return best_ratio\n\ndef dynamic_preprocess(image, min_num=1, max_num=None, image_size=448, use_thumbnail=False):\n    \"\"\"\n    Dynamically preprocess image by splitting into tiles based on aspect ratio.\n    \n    Args:\n        image: PIL Image\n        min_num: Minimum number of tiles\n        max_num: Maximum number of tiles (from CONFIG['MAX_TILES'])\n        image_size: Size of each tile (448 for InternVL3)\n        use_thumbnail: Whether to include thumbnail image\n    \n    Returns:\n        List of PIL Image tiles\n    \"\"\"\n    # Use CONFIG if max_num not specified\n    if max_num is None:\n        max_num = CONFIG['MAX_TILES']\n    \n    orig_width, orig_height = image.size\n    aspect_ratio = orig_width / orig_height\n\n    # Generate target aspect ratios\n    target_ratios = set(\n        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n        i * j <= max_num and i * j >= min_num)\n    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n\n    # Find best aspect ratio\n    target_aspect_ratio = find_closest_aspect_ratio(\n        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n\n    # Calculate target dimensions\n    target_width = image_size * target_aspect_ratio[0]\n    target_height = image_size * target_aspect_ratio[1]\n    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n\n    # Resize and split into tiles\n    resized_img = image.resize((target_width, target_height))\n    processed_images = []\n    for i in range(blocks):\n        box = (\n            (i % (target_width // image_size)) * image_size,\n            (i // (target_width // image_size)) * image_size,\n            ((i % (target_width // image_size)) + 1) * image_size,\n            ((i // (target_width // image_size)) + 1) * image_size\n        )\n        split_img = resized_img.crop(box)\n        processed_images.append(split_img)\n    \n    assert len(processed_images) == blocks\n    \n    # Add thumbnail if requested\n    if use_thumbnail and len(processed_images) != 1:\n        thumbnail_img = image.resize((image_size, image_size))\n        processed_images.append(thumbnail_img)\n    \n    return processed_images\n\ndef load_image(image_file, input_size=448, max_num=None):\n    \"\"\"\n    Load and preprocess image for InternVL3.5.\n    \n    Args:\n        image_file: Path to image or PIL Image object\n        input_size: Size of each tile (448 for InternVL3)\n        max_num: Max number of tiles (uses CONFIG['MAX_TILES'] if None)\n    \n    Returns:\n        pixel_values: Preprocessed tensor ready for model.chat()\n    \"\"\"\n    # Use CONFIG if max_num not specified\n    if max_num is None:\n        max_num = CONFIG['MAX_TILES']\n    \n    # Handle both path string and PIL Image\n    if isinstance(image_file, str):\n        image = Image.open(image_file).convert('RGB')\n    else:\n        image = image_file\n    \n    # Build transform and preprocess\n    transform = build_transform(input_size=input_size)\n    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n    pixel_values = [transform(img) for img in images]\n    pixel_values = torch.stack(pixel_values)\n    \n    return pixel_values\n\nprint(\"‚úÖ InternVL3.5 image preprocessing functions defined\")\nprint(f\"üî≤ Using max_num={CONFIG['MAX_TILES']} tiles (from CONFIG)\")\nprint(f\"üí° Image preprocessing: ImageNet normalization + dynamic tiling\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "# Bank Statement Extraction Protocol\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract full table using dynamic markdown example\n",
    "- Python: Parse, filter, and extract schema fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Turn 0 - Identify table headers (prompt)\n",
    "# TURN 0: Identify Table Headers\n",
    "# First, identify the actual column headers used in this specific bank statement\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "IMPORTANT STRUCTURAL NOTE:\n",
    "Some bank statements show dates as section headings with multiple transactions underneath.\n",
    "If you see this structure, remember that each transaction needs its explicit date in the final output.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üí¨ TURN 0: Identifying actual table headers\")\n",
    "print(\"ü§ñ Generating response with InternVL3.5-8B...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 12: Turn 0 - Execute and parse headers (InternVL3.5-8B version)\n\nprint(\"üí¨ TURN 0: Identifying actual table headers\")\nprint(\"ü§ñ Generating response with InternVL3.5-8B (bfloat16)...\")\n\n# Load and preprocess image for InternVL3.5 (uses CONFIG['MAX_TILES'])\npixel_values = load_image(imageName, input_size=448)\n\n# Move to correct device and dtype for InternVL3.5-8B\n# CRITICAL: Use bfloat16 for non-quantized H200 models\nvision_device = 'cuda:0'  # Vision model is on GPU 0\nmodel_dtype = torch.bfloat16\npixel_values = pixel_values.to(dtype=model_dtype, device=vision_device)\n\n# Generate response using chat() method\ncleanedOutput = model.chat(\n    tokenizer=tokenizer,\n    pixel_values=pixel_values,\n    question=prompt,\n    generation_config={\n        \"max_new_tokens\": CONFIG['MAX_NEW_TOKENS'],\n        \"do_sample\": False  # Greedy decoding for consistency\n    }\n)\n\n# Clean InternVL3 artifacts:\n# 1. Remove image markdown placeholder (![...])\n# 2. Remove markdown code fences (```markdown and ```)\nlines = cleanedOutput.split(\"\\n\")\ncleaned_lines = []\nfor line in lines:\n    stripped = line.strip()\n    # Skip image markdown, code fences, and empty fence markers\n    if stripped.startswith(\"![\"):\n        continue\n    if stripped in [\"```markdown\", \"```\", \"```md\"]:\n        continue\n    cleaned_lines.append(line)\n\ncleanedOutput = \"\\n\".join(cleaned_lines)\n\nprint(\"‚úÖ Response generated successfully!\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\nprint(\"=\" * 60)\nprint(cleanedOutput)\nprint(\"=\" * 60)\n\n# CRITICAL: Parse the identified headers for use in subsequent turns\n# Extract column names from the response\nheader_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\nidentified_headers = []\n\n# Look for numbered list or bullet points\nfor line in header_lines:\n    # Remove common list markers\n    cleaned = line.lstrip('0123456789.-‚Ä¢* ').strip()\n    \n    # Strip markdown bold formatting\n    cleaned = cleaned.replace('**', '').replace('__', '')\n    \n    # Skip section headers (lines ending with colon)\n    if cleaned.endswith(':'):\n        continue\n    \n    # Skip long sentences (likely explanatory text, not headers)\n    if len(cleaned) > 40:\n        continue\n        \n    if cleaned and len(cleaned) > 2:  # Ignore very short strings\n        identified_headers.append(cleaned)\n\nprint(f\"\\nüìã Parsed {len(identified_headers)} column headers:\")\nfor i, header in enumerate(identified_headers, 1):\n    print(f\"  {i}. '{header}'\")\n\n# Store headers for use in subsequent turns\ntable_headers = identified_headers\n\n# Save the table headers\noutput_path = Path(\"ivl3_5_8b_table_headers.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(cleanedOutput)\n\nprint(f\"\\n‚úÖ Table headers saved to: {output_path}\")\nprint(\"üí° These LITERAL header names will be used in Turn 1 prompts\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Pattern Matching - Map headers to generic columns\n",
    "# Pattern Matching: Map extracted headers to generic concepts\n",
    "# This handles variety in bank statement column naming conventions\n",
    "\n",
    "# Pattern keywords for each concept (in priority order)\n",
    "DATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\n",
    "DESCRIPTION_PATTERNS = [\n",
    "    'description', 'details', 'transaction details', 'trans details',\n",
    "    'particulars', 'narrative', 'transaction', 'trans'\n",
    "]\n",
    "DEBIT_PATTERNS = ['debit', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\n",
    "CREDIT_PATTERNS = ['credit', 'deposit', 'deposits', 'received', 'cr']\n",
    "BALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n",
    "\n",
    "# NEW: Pattern for single-column transaction formats (e.g., \"Amount\" instead of separate Debit/Credit)\n",
    "AMOUNT_PATTERNS = ['amount', 'amt', 'value', 'total']\n",
    "\n",
    "def match_header(headers, patterns, fallback=None):\n",
    "    \"\"\"Match a header using pattern keywords.\n",
    "    \n",
    "    Matching strategy:\n",
    "    1. Exact match (case-insensitive)\n",
    "    2. Substring match (only for patterns with length > 2 to avoid false positives)\n",
    "    \"\"\"\n",
    "    headers_lower = [h.lower() for h in headers]\n",
    "    \n",
    "    # Try exact match first\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern == header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    # Try substring match (only for patterns longer than 2 chars)\n",
    "    for pattern in patterns:\n",
    "        if len(pattern) > 2:  # Avoid false positives like 'cr' matching 'description'\n",
    "            for i, header_lower in enumerate(headers_lower):\n",
    "                if pattern in header_lower:\n",
    "                    return headers[i]\n",
    "    \n",
    "    return fallback\n",
    "\n",
    "# Perform pattern matching on extracted headers\n",
    "date_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\n",
    "desc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n",
    "\n",
    "# NEW: First try to match a generic \"Amount\" column (for 4-column formats)\n",
    "amount_col = match_header(table_headers, AMOUNT_PATTERNS, fallback=None)\n",
    "\n",
    "# Use amount_col as fallback if no separate debit/credit columns exist\n",
    "# This handles formats like: Date | Description | Amount | Balance\n",
    "debit_col = match_header(table_headers, DEBIT_PATTERNS, fallback=amount_col if amount_col else 'Debit')\n",
    "credit_col = match_header(table_headers, CREDIT_PATTERNS, fallback=amount_col if amount_col else 'Credit')\n",
    "balance_col = match_header(table_headers, BALANCE_PATTERNS, fallback='Balance')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATTERN MATCHING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìã Extracted Headers: {table_headers}\")\n",
    "print(f\"\\nüîç Mapped Columns:\")\n",
    "print(f\"  Date        ‚Üí '{date_col}'\")\n",
    "print(f\"  Description ‚Üí '{desc_col}'\")\n",
    "print(f\"  Debit       ‚Üí '{debit_col}'\")\n",
    "print(f\"  Credit      ‚Üí '{credit_col}'\")\n",
    "print(f\"  Balance     ‚Üí '{balance_col}'\")\n",
    "if amount_col:\n",
    "    print(f\"\\nüí° Single-column format detected: '{amount_col}' used for both debit and credit\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚úÖ These literal column names will be used in Turn 1 and Turn 2\")\n",
    "print(\"üí° Adjust patterns above if matching fails for your bank statement format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### üîë Independent Single-Turn Pattern (NOT Multi-Turn Conversation)\n",
    "\n",
    "**CRITICAL INSIGHT**: Multi-turn conversation accumulates context and degrades accuracy.\n",
    "\n",
    "We use **two independent single-turn prompts**, each with fresh context:\n",
    "\n",
    "#### Key Principles:\n",
    "\n",
    "1. **No Conversation History**: Each turn is completely independent\n",
    "2. **Fresh Image Attention**: Each turn processes the image directly\n",
    "3. **No Context Accumulation**: Prevents attention dilution\n",
    "4. **Headers as Parameters**: Turn 0 headers used to generate dynamic examples for Turn 1\n",
    "5. **Python Filtering**: LLM filtering mixes up rows - Python is reliable\n",
    "\n",
    "#### Message Structure for Each Turn:\n",
    "\n",
    "Every turn uses fresh structure:\n",
    "```python\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"<prompt with dynamic example>\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "**No assistant responses in history. No conversation accumulation.**\n",
    "\n",
    "#### Why This Works Better:\n",
    "\n",
    "- **Turn 0**: Clean context ‚Üí accurate header identification\n",
    "- **Turn 1**: Clean context + dynamic example ‚Üí accurate table extraction  \n",
    "- **Python**: Reliable parsing and filtering (no row mixing!)\n",
    "\n",
    "Each turn has **full attention** on the image, not diluted by conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: NO conversation history (independent turns)\n",
    "# \n",
    "# CRITICAL: We do NOT use conversation history in this notebook.\n",
    "# Each turn is completely independent with fresh context.\n",
    "#\n",
    "# Why? Multi-turn conversation accumulates context and degrades accuracy:\n",
    "# - Turn 0: ~50 tokens ‚Üí accurate\n",
    "# - Turn 1 with history: ~350 tokens ‚Üí attention diluted ‚Üí less accurate\n",
    "# - Turn 2 with history: ~2000 tokens ‚Üí attention heavily diluted ‚Üí row mixing!\n",
    "#\n",
    "# Instead: \n",
    "# - Turn 0: Fresh context ‚Üí headers\n",
    "# - Turn 1: Fresh context + dynamic example ‚Üí full table\n",
    "# - Python: Parse and filter (no LLM confusion!)\n",
    "\n",
    "print(\"‚úÖ Independent turn approach - NO conversation history\")\n",
    "print(\"üí° Each turn has fresh context with direct image access\")\n",
    "print(\"üêç Python handles all filtering - no LLM row mixing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Generate Column Aware Extraction Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Generate Column Aware Extraction Prompt\n",
    "\n",
    "# Build the header string using LITERAL names from Turn 0\n",
    "header_string = \" | \".join(table_headers)\n",
    "\n",
    "# Build separator row with proper alignment indicators\n",
    "# Date and Description columns: left-aligned (:---)\n",
    "# Debit, Credit, Balance columns: right-aligned (---:)\n",
    "separator_parts = []\n",
    "for h in table_headers:\n",
    "    h_lower = h.lower()\n",
    "    # Right-align numeric columns\n",
    "    if any(keyword in h_lower for keyword in ['debit', 'credit', 'balance', 'amount', 'total']):\n",
    "        separator_parts.append('---:')\n",
    "    else:\n",
    "        # Left-align text columns (Date, Transaction, Description, etc.)\n",
    "        separator_parts.append(':---')\n",
    "\n",
    "separator_row = \" | \".join(separator_parts)\n",
    "\n",
    "# Build dynamic example rows based on detected column structure\n",
    "# CRITICAL: Examples must emphasize correct Debit/Credit column alignment!\n",
    "def build_dynamic_example(headers, date_col, desc_col, debit_col, credit_col, balance_col):\n",
    "    \"\"\"Generate example rows matching detected column structure.\n",
    "    \n",
    "    Emphasizes correct Debit/Credit alignment for tax purposes:\n",
    "    - Debits (purchases/withdrawals) = money OUT = what taxpayer PAID\n",
    "    - Credits (deposits/income) = money IN = NOT purchases\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if we have separate debit/credit columns\n",
    "    has_separate_debit_credit = (debit_col in headers and credit_col in headers and debit_col != credit_col)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    if has_separate_debit_credit:\n",
    "        # 5-column format: Emphasize Debit vs Credit with clear examples\n",
    "        \n",
    "        # Example 1: DEBIT transaction (purchase/withdrawal) - money OUT\n",
    "        row1 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row1.append(\"15 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row1.append(\"ATM Withdrawal City Branch\")\n",
    "            elif h == debit_col:\n",
    "                row1.append(\"200.00\")  # Amount in DEBIT column\n",
    "            elif h == credit_col:\n",
    "                row1.append(\"\")  # Credit column EMPTY\n",
    "            elif h == balance_col:\n",
    "                row1.append(\"$1,500.00 CR\")\n",
    "            else:\n",
    "                row1.append(\"\")\n",
    "        rows.append(\" | \".join(row1))\n",
    "        \n",
    "        # Example 2: CREDIT transaction (deposit) - money IN\n",
    "        row2 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row2.append(\"16 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row2.append(\"Salary Employer Name Ref 12345\")\n",
    "            elif h == debit_col:\n",
    "                row2.append(\"\")  # Debit column EMPTY\n",
    "            elif h == credit_col:\n",
    "                row2.append(\"3,500.00\")  # Amount in CREDIT column\n",
    "            elif h == balance_col:\n",
    "                row2.append(\"$5,000.00 CR\")\n",
    "            else:\n",
    "                row2.append(\"\")\n",
    "        rows.append(\" | \".join(row2))\n",
    "        \n",
    "        # Example 3: Another DEBIT transaction (purchase)\n",
    "        row3 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row3.append(\"17 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row3.append(\"Online Purchase Store Name\")\n",
    "            elif h == debit_col:\n",
    "                row3.append(\"150.00\")  # Amount in DEBIT column\n",
    "            elif h == credit_col:\n",
    "                row3.append(\"\")  # Credit column EMPTY\n",
    "            elif h == balance_col:\n",
    "                row3.append(\"$4,850.00 CR\")\n",
    "            else:\n",
    "                row3.append(\"\")\n",
    "        rows.append(\" | \".join(row3))\n",
    "        \n",
    "    else:\n",
    "        # 4-column format: Single Amount column\n",
    "        row1 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row1.append(\"15 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row1.append(\"ATM Withdrawal City Branch\")\n",
    "            elif h == debit_col:  # This is the Amount column\n",
    "                row1.append(\"200.00\")\n",
    "            elif h == balance_col:\n",
    "                row1.append(\"$1,500.00 CR\")\n",
    "            else:\n",
    "                row1.append(\"\")\n",
    "        rows.append(\" | \".join(row1))\n",
    "        \n",
    "        row2 = []\n",
    "        for h in headers:\n",
    "            if h == date_col:\n",
    "                row2.append(\"16 Jan\")\n",
    "            elif h == desc_col:\n",
    "                row2.append(\"Salary Employer Name Ref 12345\")\n",
    "            elif h == debit_col:  # This is the Amount column\n",
    "                row2.append(\"3,500.00\")\n",
    "            elif h == balance_col:\n",
    "                row2.append(\"$5,000.00 CR\")\n",
    "            else:\n",
    "                row2.append(\"\")\n",
    "        rows.append(\" | \".join(row2))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def build_multiline_rule(headers):\n",
    "    \"\"\"Generate multi-line extraction rule using ACTUAL column structure from Turn 0.\"\"\"\n",
    "    num_cols = len(headers)\n",
    "    \n",
    "    # Find actual Debit, Credit, and Balance columns by name\n",
    "    debit_idx = None\n",
    "    credit_idx = None\n",
    "    balance_idx = None\n",
    "    \n",
    "    for i, header in enumerate(headers):\n",
    "        h_lower = header.lower()\n",
    "        if any(p in h_lower for p in [\"debit\", \"withdrawal\", \"paid\", \"spent\", \"dr\"]):\n",
    "            debit_idx = i\n",
    "        if any(p in h_lower for p in [\"credit\", \"deposit\", \"received\", \"cr\"]):\n",
    "            credit_idx = i\n",
    "        if any(p in h_lower for p in [\"balance\", \"bal\"]):\n",
    "            balance_idx = i\n",
    "    \n",
    "    if debit_idx is None or credit_idx is None:\n",
    "        return \"Multi-line: combine description lines into single row.\"\n",
    "    \n",
    "    def format_aligned_table(rows):\n",
    "        \"\"\"Format rows with properly aligned vertical pipes.\"\"\"\n",
    "        if not rows:\n",
    "            return []\n",
    "        \n",
    "        num_cols = len(rows[0])\n",
    "        \n",
    "        # Calculate max width for each column\n",
    "        col_widths = [0] * num_cols\n",
    "        for row in rows:\n",
    "            for i, val in enumerate(row):\n",
    "                col_widths[i] = max(col_widths[i], len(val))\n",
    "        \n",
    "        # Find last non-empty column index\n",
    "        last_col = 0\n",
    "        for row in rows:\n",
    "            for i, val in enumerate(row):\n",
    "                if val:\n",
    "                    last_col = max(last_col, i)\n",
    "        \n",
    "        # Ensure empty MIDDLE columns have minimum width\n",
    "        for i in range(1, last_col):  # Skip first column, only middle columns\n",
    "            if col_widths[i] == 0:\n",
    "                col_widths[i] = 7\n",
    "        \n",
    "        # Format each row with proper alignment\n",
    "        formatted = []\n",
    "        for row in rows:\n",
    "            # Determine how many columns to include\n",
    "            end_col = last_col + 2 if last_col < len(row) - 1 else last_col + 1\n",
    "            end_col = min(end_col, len(row))\n",
    "            \n",
    "            # Pad each column value to its width\n",
    "            parts = []\n",
    "            for i in range(end_col):\n",
    "                val = row[i] if i < len(row) else \"\"\n",
    "                parts.append(val.ljust(col_widths[i]))\n",
    "            \n",
    "            line = \" | \".join(parts)\n",
    "            \n",
    "            # CRITICAL: If first column is empty, add leading spaces to align pipes\n",
    "            if not row[0]:\n",
    "                line = \" \" * col_widths[0] + \" | \" + \" | \".join(parts[1:])\n",
    "            \n",
    "            formatted.append(line)\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    # Create example rows using ACTUAL column positions\n",
    "    # Credit example (amount in credit_idx position)\n",
    "    credit_rows = [[\"\"] * num_cols for _ in range(3)]\n",
    "    credit_rows[0][0] = \"a date\"\n",
    "    credit_rows[0][1] = \"line 1\"\n",
    "    credit_rows[0][credit_idx] = \"85.50\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        credit_rows[0][balance_idx] = \"$1,085.50 CR\"\n",
    "    credit_rows[1][0] = \"\"  # Empty date for continuation\n",
    "    credit_rows[1][1] = \"line 2\"\n",
    "    credit_rows[2][0] = \"a date\"\n",
    "    credit_rows[2][1] = \"line 1 line 2\"\n",
    "    credit_rows[2][credit_idx] = \"85.50\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        credit_rows[2][balance_idx] = \"$1,085.50 CR\"\n",
    "    \n",
    "    # Debit example (amount in debit_idx position)\n",
    "    debit_rows = [[\"\"] * num_cols for _ in range(3)]\n",
    "    debit_rows[0][0] = \"a date\"\n",
    "    debit_rows[0][1] = \"line 1\"\n",
    "    debit_rows[0][debit_idx] = \"150.00\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        debit_rows[0][balance_idx] = \"$850.00 CR\"\n",
    "    debit_rows[1][0] = \"\"  # Empty date for continuation\n",
    "    debit_rows[1][1] = \"line 2\"\n",
    "    debit_rows[2][0] = \"a date\"\n",
    "    debit_rows[2][1] = \"line 1 line 2\"\n",
    "    debit_rows[2][debit_idx] = \"150.00\"\n",
    "    # Add Balance column value if it exists\n",
    "    if balance_idx is not None:\n",
    "        debit_rows[2][balance_idx] = \"$850.00 CR\"\n",
    "    \n",
    "    # Format both examples\n",
    "    credit_fmt = format_aligned_table(credit_rows)\n",
    "    debit_fmt = format_aligned_table(debit_rows)\n",
    "    \n",
    "    # Build rule with LABELED examples using actual header names\n",
    "    rule = f\"\"\"  {headers[credit_idx]} example:\n",
    "       {credit_fmt[0]}\n",
    "       {credit_fmt[1]}\n",
    "    you must extract it as:\n",
    "       {credit_fmt[2]}\n",
    "\n",
    "  {headers[debit_idx]} example:\n",
    "       {debit_fmt[0]}\n",
    "       {debit_fmt[1]}\n",
    "    you must extract it as:\n",
    "       {debit_fmt[2]}\"\"\"\n",
    "    \n",
    "    return rule\n",
    "\n",
    "# Generate dynamic example rows\n",
    "example_rows = build_dynamic_example(table_headers, date_col, desc_col, debit_col, credit_col, balance_col)\n",
    "\n",
    "# Build complete example table with proper alignment\n",
    "example_table = f\"\"\"| {header_string} |\n",
    "| {separator_row} |\n",
    "\"\"\" + \"\\n\".join([f\"| {row} |\" for row in example_rows])\n",
    "\n",
    "# Generate dynamic multi-line rule\n",
    "multiline_rule = build_multiline_rule(table_headers)\n",
    "\n",
    "# OPTION D: STRONGER COLUMN REINFORCEMENT\n",
    "follow_up_prompt = f\"\"\"\n",
    "Extract the transaction table from this bank statement image in markdown format.\n",
    "\n",
    "Example showing the format I want:\n",
    "\n",
    "{example_table}\n",
    "\n",
    "## CRITICAL: COLUMN ALIGNMENT\n",
    "\n",
    "Before extracting ANY row, locate the header row with these column names:\n",
    "{\" | \".join(table_headers)}\n",
    "\n",
    "For EACH transaction, you must check which column the amount appears under:\n",
    "\n",
    "**Step-by-step process:**\n",
    "1. Find the header row\n",
    "2. Look at the transaction row\n",
    "3. Draw an imaginary vertical line from the amount UP to the header\n",
    "4. Read which header the amount aligns with\n",
    "5. Put the amount in that SAME column in your markdown table\n",
    "\n",
    "**Column placement rules:**\n",
    "- Amount aligns with \"{debit_col}\" header ‚Üí put amount in {debit_col} column, leave {credit_col} EMPTY\n",
    "- Amount aligns with \"{credit_col}\" header ‚Üí put amount in {credit_col} column, leave {debit_col} EMPTY\n",
    "\n",
    "**Do NOT guess based on description text. Use visual alignment ONLY.**\n",
    "\n",
    "## OTHER RULES\n",
    "\n",
    "**Multi-line transactions:** Combine description lines into single row:\n",
    "{multiline_rule}\n",
    "\n",
    "**Empty columns:** Leave empty (|  |)\n",
    "\n",
    "**Output:** Markdown table only, no explanations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Turn 1 Extraction Prompt (Option D):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{follow_up_prompt}\")\n",
    "print(\"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 19: Turn 1 - Extract full table (InternVL3.5-8B version, INDEPENDENT fresh context)\n\nprint(\"ü§ñ Generating response with InternVL3.5-8B (bfloat16)...\")\n\n# CRITICAL: Reload image for fresh context (independent turn, not continuing conversation)\n# Uses CONFIG['MAX_TILES'] automatically\npixel_values = load_image(imageName, input_size=448)\n\n# Move to correct device and dtype\n# CRITICAL: Use bfloat16 for non-quantized H200 models\npixel_values = pixel_values.to(dtype=torch.bfloat16, device='cuda:0')\n\n# Generate response using chat() method with dynamic prompt\ncleanedOutput2 = model.chat(\n    tokenizer=tokenizer,\n    pixel_values=pixel_values,\n    question=follow_up_prompt,  # Dynamic prompt with column-aware examples from Cell 18\n    generation_config={\n        \"max_new_tokens\": CONFIG['MAX_NEW_TOKENS'],\n        \"do_sample\": False\n    }\n)\n\n# Clean InternVL3 artifacts:\n# 1. Remove image markdown placeholder (![...])\n# 2. Remove markdown code fences (```markdown and ```)\nlines = cleanedOutput2.split(\"\\n\")\ncleaned_lines = []\nfor line in lines:\n    stripped = line.strip()\n    # Skip image markdown, code fences, and empty fence markers\n    if stripped.startswith(\"![\"):\n        continue\n    if stripped in [\"```markdown\", \"```\", \"```md\"]:\n        continue\n    cleaned_lines.append(line)\n\ncleanedOutput2 = \"\\n\".join(cleaned_lines)\n\nprint(\"\\n‚úÖ Turn 1 extraction complete!\")\n\n# Display the extracted table as rendered markdown for easy visual verification\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 1 - EXTRACTED MARKDOWN TABLE (Rendered):\")\nprint(\"=\" * 60)\n\n# Render the markdown table\ndisplay(Markdown(cleanedOutput2))\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 1 - RAW MARKDOWN TEXT:\")\nprint(\"=\" * 60)\nprint(cleanedOutput2)\nprint(\"=\" * 60)\n\n# Save the markdown table\noutput_path = Path(\"ivl3_5_8b_markdown_table_extraction.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(cleanedOutput2)\n\nprint(f\"\\n‚úÖ Markdown table saved to: {output_path}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## Python Parsing and Filtering\n",
    "\n",
    "Parse the Turn 1 markdown table, filter for debit transactions, and extract schema fields using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 21: Parse Turn 1 markdown table and filter for debits (Python)\nimport re\nfrom datetime import datetime\n\ndef parse_markdown_table(markdown_text):\n    \"\"\"Parse markdown table into list of dictionaries.\n    \n    CRITICAL: Must preserve empty columns for correct Debit/Credit alignment!\n    \"\"\"\n    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n    \n    # Find header row (first line with pipes)\n    header_idx = None\n    for i, line in enumerate(lines):\n        if '|' in line:\n            # Skip separator rows (contain only pipes, hyphens, and spaces)\n            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n            if cleaned:  # Has actual content, not just separators\n                header_idx = i\n                break\n    \n    if header_idx is None:\n        return []\n    \n    # Parse headers - KEEP empty values to preserve column positions\n    header_line = lines[header_idx]\n    header_parts = [h.strip() for h in header_line.split('|')]\n    # Remove leading/trailing empty strings from pipe delimiters\n    if header_parts and header_parts[0] == '':\n        header_parts = header_parts[1:]\n    if header_parts and header_parts[-1] == '':\n        header_parts = header_parts[:-1]\n    # Filter out any remaining empty headers\n    headers = [h for h in header_parts if h]\n    \n    print(f\"üîç Debug: Parsed {len(headers)} headers: {headers}\")\n    \n    # Parse data rows (skip header and separator)\n    rows = []\n    for idx, line in enumerate(lines[header_idx + 1:], start=header_idx+1):\n        if '|' not in line:\n            continue\n            \n        # Skip separator rows\n        cleaned = line.replace(\"|\", \"\").replace(\"-\", \"\").replace(\" \", \"\").replace(\":\", \"\")\n        if not cleaned:\n            continue\n        \n        # Parse values - KEEP empty values to preserve column positions!\n        value_parts = [v.strip() for v in line.split('|')]\n        # Remove leading/trailing empty strings from pipe delimiters\n        if value_parts and value_parts[0] == '':\n            value_parts = value_parts[1:]\n        if value_parts and value_parts[-1] == '':\n            value_parts = value_parts[:-1]\n        \n        print(f\"üîç Debug row {idx}: {len(value_parts)} values: {value_parts}\")\n        \n        # Match to headers length\n        if len(value_parts) == len(headers):\n            rows.append(dict(zip(headers, value_parts)))\n        else:\n            print(f\"‚ö†Ô∏è  Row {idx} mismatch: {len(value_parts)} values vs {len(headers)} headers - SKIPPED\")\n    \n    return rows\n\ndef filter_debit_transactions(rows, debit_col):\n    \"\"\"Filter rows to only those with debit (purchase) amounts.\n    \n    CRITICAL: For tax purposes, we only want transactions where taxpayer PAID money (debits).\n    \"\"\"\n    debit_rows = []\n    for row in rows:\n        debit_value = row.get(debit_col, '').strip()\n        # Include row if debit column has a value (not empty)\n        if debit_value:\n            debit_rows.append(row)\n    \n    return debit_rows\n\ndef extract_schema_fields(rows, date_col, desc_col, debit_col):\n    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n    if not rows:\n        return {\n            'TRANSACTION_DATES': 'NOT_FOUND',\n            'LINE_ITEM_DESCRIPTIONS': 'NOT_FOUND',\n            'TRANSACTION_AMOUNTS_PAID': 'NOT_FOUND',\n            'STATEMENT_DATE_RANGE': 'NOT_FOUND'\n        }\n    \n    # Extract lists\n    dates = []\n    descriptions = []\n    amounts = []\n    \n    for row in rows:\n        date = row.get(date_col, '').strip()\n        desc = row.get(desc_col, '').strip()\n        amount = row.get(debit_col, '').strip()\n        \n        if date:\n            dates.append(date)\n        if desc:\n            descriptions.append(desc)\n        if amount:\n            amounts.append(amount)\n    \n    # Calculate statement date range - use literal date format from image\n    # No parsing, no year assumption - just \"earliest date - latest date\"\n    date_range = 'NOT_FOUND'\n    if dates:\n        # Use first and last date as-is (same format as in the image)\n        date_range = f\"{dates[0]} - {dates[-1]}\"\n    \n    return {\n        'TRANSACTION_DATES': ' | '.join(dates) if dates else 'NOT_FOUND',\n        'LINE_ITEM_DESCRIPTIONS': ' | '.join(descriptions) if descriptions else 'NOT_FOUND',\n        'TRANSACTION_AMOUNTS_PAID': ' | '.join(amounts) if amounts else 'NOT_FOUND',\n        'STATEMENT_DATE_RANGE': date_range\n    }\n\nprint(\"=\" * 60)\nprint(\"PARSING TURN 1 MARKDOWN TABLE:\")\nprint(\"=\" * 60)\n\n# Parse the full markdown table from Turn 1\nall_rows = parse_markdown_table(cleanedOutput2)\n\nprint(f\"\\nüìä Parsed {len(all_rows)} total transactions from Turn 1 markdown table\")\n\nif all_rows:\n    # Show sample parsed row\n    print(f\"\\nüîç Sample parsed row:\")\n    for key, value in all_rows[0].items():\n        print(f\"  {key}: '{value}'\")\n\n# Filter to only debit (purchase) transactions - Python filtering, not LLM!\ndebit_rows = filter_debit_transactions(all_rows, debit_col)\n\nprint(f\"\\nüí∞ Filtered to {len(debit_rows)} debit transactions (taxpayer purchases)\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DEBIT TRANSACTIONS (WHAT TAXPAYER PAID):\")\nprint(\"=\" * 60)\nfor i, row in enumerate(debit_rows, 1):\n    print(f\"\\nTransaction {i}:\")\n    print(f\"  {date_col}: {row.get(date_col, '')}\")\n    print(f\"  {desc_col}: {row.get(desc_col, '')}\")\n    print(f\"  {debit_col}: {row.get(debit_col, '')}\")\n\n# Extract schema fields using the LITERAL column names from pattern matching\nschema_fields = extract_schema_fields(debit_rows, date_col, desc_col, debit_col)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"EXTRACTED SCHEMA FIELDS (TAX-RELEVANT DATA):\")\nprint(\"=\" * 60)\nfor field, value in schema_fields.items():\n    print(f\"{field}: {value}\")\nprint(\"=\" * 60)\n\n# Save to file with ivl3 prefix (renamed)\noutput_path = Path(\"ivl3_5_8b_extracted_fields.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as f:\n    for field, value in schema_fields.items():\n        f.write(f\"{field}: {value}\\n\")\n\nprint(f\"\\n‚úÖ Schema fields saved to: {output_path}\")\nprint(f\"üí° Fields extracted from columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")\nprint(f\"üéØ Success: Python parsing + filtering from Turn 1 markdown table\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (InternVL3.5)",
   "language": "python",
   "name": "ivl35_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat": 4,
   "nbformat_minor": 5
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}