{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InternVL3-8B: 2-Turn Balance-Description Bank Statement Extraction\n",
    "\n",
    "**Protocol**: Two independent single-turn prompts + Python parsing/filtering\n",
    "\n",
    "**Key Insight**: Balance-description prompt works for BOTH date-per-row AND date-grouped formats!\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Turn 0: Image + Prompt ‚Üí Headers (fresh context)\n",
    "        ‚Üì (Python pattern matching)\n",
    "        ‚Üì (Check if Balance column exists)\n",
    "Turn 1: Image + Prompt ‚Üí Balance-Description extraction (fresh context)\n",
    "        ‚Üì (Python parsing + filtering)\n",
    "Schema Fields: TRANSACTION_DATES, LINE_ITEM_DESCRIPTIONS, TRANSACTION_AMOUNTS_PAID\n",
    "```\n",
    "\n",
    "### Why Balance-Description Works:\n",
    "- **Anchors extraction to Balance column** - unambiguous reference point\n",
    "- **Works for date-per-row**: Each transaction gets its date\n",
    "- **Works for date-grouped**: Date headers naturally map to transactions\n",
    "- **No format classification needed** - eliminates Turn 0.5 entirely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, BitsAndBytesConfig\n",
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Set random seed\n",
    "\n",
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load InternVL3-8B model with memory-aware loading strategy\n",
    "\n",
    "MODEL_PATH = \"/home/jovyan/nfs_share/models/InternVL3-8B\"\n",
    "MAX_TILES = 14  # V100 optimized\n",
    "\n",
    "# Image preprocessing constants\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "def build_transform(input_size):\n",
    "    \"\"\"Build image transformation pipeline.\"\"\"\n",
    "    return T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ])\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    \"\"\"Find closest aspect ratio from target ratios.\"\"\"\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=MAX_TILES, image_size=448, use_thumbnail=False):\n",
    "    \"\"\"Dynamically preprocess image by splitting into tiles.\"\"\"\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "    \n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1)\n",
    "        for i in range(1, n + 1) for j in range(1, n + 1)\n",
    "        if i * j <= max_num and i * j >= min_num\n",
    "    )\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "    \n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size\n",
    "    )\n",
    "    \n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "    \n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size,\n",
    "        )\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    \n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    \n",
    "    return processed_images\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=MAX_TILES):\n",
    "    \"\"\"Load and preprocess image for InternVL3.\"\"\"\n",
    "    if isinstance(image_file, str):\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "    else:\n",
    "        image = image_file\n",
    "    \n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(img) for img in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "def split_model(model_path):\n",
    "    \"\"\"Official InternVL3 multi-GPU device mapping.\"\"\"\n",
    "    device_map = {}\n",
    "    world_size = torch.cuda.device_count()\n",
    "    config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "    num_layers = config.llm_config.num_hidden_layers\n",
    "    \n",
    "    num_layers_per_gpu = math.ceil(num_layers / (world_size - 0.5))\n",
    "    num_layers_per_gpu = [num_layers_per_gpu] * world_size\n",
    "    num_layers_per_gpu[0] = math.ceil(num_layers_per_gpu[0] * 0.5)\n",
    "    \n",
    "    layer_cnt = 0\n",
    "    for i, num_layer in enumerate(num_layers_per_gpu):\n",
    "        for _ in range(num_layer):\n",
    "            device_map[f'language_model.model.layers.{layer_cnt}'] = i\n",
    "            layer_cnt += 1\n",
    "    \n",
    "    device_map['vision_model'] = 0\n",
    "    device_map['mlp1'] = 0\n",
    "    device_map['language_model.model.tok_embeddings'] = 0\n",
    "    device_map['language_model.model.embed_tokens'] = 0\n",
    "    device_map['language_model.output'] = 0\n",
    "    device_map['language_model.model.norm'] = 0\n",
    "    device_map['language_model.model.rotary_emb'] = 0\n",
    "    device_map['language_model.lm_head'] = 0\n",
    "    device_map[f'language_model.model.layers.{num_layers - 1}'] = 0\n",
    "    \n",
    "    return device_map\n",
    "\n",
    "print(\"üîß Loading InternVL3-8B model...\")\n",
    "\n",
    "world_size = torch.cuda.device_count()\n",
    "print(f\"  Detected {world_size} GPU(s)\")\n",
    "\n",
    "# Memory-aware loading\n",
    "if world_size > 1:\n",
    "    print(\"  Using multi-GPU bfloat16 mode\")\n",
    "    device_map = split_model(MODEL_PATH)\n",
    "    model = AutoModel.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_flash_attn=False,\n",
    "        trust_remote_code=True,\n",
    "        device_map=device_map,\n",
    "    ).eval()\n",
    "    model_dtype = torch.bfloat16\n",
    "else:\n",
    "    print(\"  Using single-GPU 8-bit quantization mode\")\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        llm_int8_enable_fp32_cpu_offload=False\n",
    "    )\n",
    "    model = AutoModel.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        use_flash_attn=False,\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map={\"\":0},\n",
    "    ).eval()\n",
    "    model_dtype = torch.float16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True, use_fast=False)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully!\")\n",
    "print(f\"  Data type: {model_dtype}\")\n",
    "print(f\"  Max Tiles: {MAX_TILES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load bank statement image\n",
    "\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/cba_date_grouped.png\"\n",
    "\n",
    "print(\"üìÅ Loading image...\")\n",
    "image = Image.open(imageName).convert('RGB')\n",
    "\n",
    "print(f\"‚úÖ Image loaded: {image.size}\")\n",
    "print(\"üñºÔ∏è  Bank statement image:\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Statement Extraction Protocol (2-Turn Balance-Description)\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract using balance-description prompt\n",
    "- Python: Parse, filter, and extract schema fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Turn 0 - Identify table headers\n",
    "\n",
    "turn0_prompt = \"\"\"Look at the transaction table in this bank statement image.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "print(\"üí¨ TURN 0: Identifying actual table headers\")\n",
    "print(\"ü§ñ Generating response with InternVL3-8B...\")\n",
    "\n",
    "# Preprocess image\n",
    "pixel_values = load_image(imageName, input_size=448)\n",
    "pixel_values = pixel_values.to(dtype=model_dtype, device='cuda:0')\n",
    "\n",
    "# Generate response using chat method\n",
    "turn0_response = model.chat(\n",
    "    tokenizer=tokenizer,\n",
    "    pixel_values=pixel_values,\n",
    "    question=turn0_prompt,\n",
    "    generation_config={'max_new_tokens': 500, 'do_sample': False}\n",
    ")\n",
    "\n",
    "# Free memory\n",
    "del pixel_values\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"‚úÖ Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(turn0_response)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Parse headers from Turn 0 response\n",
    "\n",
    "def parse_headers_from_response(response_text):\n",
    "    \"\"\"Parse column headers from Turn 0 response.\"\"\"\n",
    "    header_lines = [line.strip() for line in response_text.split('\\n') if line.strip()]\n",
    "    identified_headers = []\n",
    "    \n",
    "    for line in header_lines:\n",
    "        cleaned = line.lstrip('0123456789.-‚Ä¢* ').strip()\n",
    "        cleaned = cleaned.replace('**', '').replace('__', '')\n",
    "        if cleaned.endswith(':'):\n",
    "            continue\n",
    "        if len(cleaned) > 40:\n",
    "            continue\n",
    "        if cleaned and len(cleaned) > 2:\n",
    "            identified_headers.append(cleaned)\n",
    "    \n",
    "    return identified_headers\n",
    "\n",
    "table_headers = parse_headers_from_response(turn0_response)\n",
    "\n",
    "print(f\"\\nüìã Parsed {len(table_headers)} column headers:\")\n",
    "for i, header in enumerate(table_headers, 1):\n",
    "    print(f\"  {i}. '{header}'\")\n",
    "\n",
    "print(f\"\\n‚úÖ Stored table_headers: {table_headers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Pattern Matching\n",
    "\n",
    "DATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\n",
    "DESCRIPTION_PATTERNS = [\n",
    "    'description', 'details', 'transaction details', 'trans details',\n",
    "    'particulars', 'narrative', 'transaction', 'trans'\n",
    "]\n",
    "DEBIT_PATTERNS = ['debit', 'debits', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\n",
    "CREDIT_PATTERNS = ['credit', 'credits', 'deposit', 'deposits', 'received', 'cr']\n",
    "BALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n",
    "AMOUNT_PATTERNS = ['amount', 'amt', 'value', 'total']\n",
    "\n",
    "def match_header(headers, patterns, fallback=None):\n",
    "    \"\"\"Match a header using pattern keywords.\"\"\"\n",
    "    headers_lower = [h.lower() for h in headers]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern == header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if len(pattern) > 2:\n",
    "            for i, header_lower in enumerate(headers_lower):\n",
    "                if pattern in header_lower:\n",
    "                    return headers[i]\n",
    "    \n",
    "    return fallback\n",
    "\n",
    "# Perform pattern matching\n",
    "date_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\n",
    "desc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n",
    "amount_col = match_header(table_headers, AMOUNT_PATTERNS, fallback=None)\n",
    "debit_col = match_header(table_headers, DEBIT_PATTERNS, fallback=amount_col if amount_col else 'Debit')\n",
    "credit_col = match_header(table_headers, CREDIT_PATTERNS, fallback=amount_col if amount_col else 'Credit')\n",
    "balance_col = match_header(table_headers, BALANCE_PATTERNS, fallback=None)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATTERN MATCHING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìã Extracted Headers: {table_headers}\")\n",
    "print(f\"\\nüîç Mapped Columns:\")\n",
    "print(f\"  Date        ‚Üí '{date_col}'\")\n",
    "print(f\"  Description ‚Üí '{desc_col}'\")\n",
    "print(f\"  Debit       ‚Üí '{debit_col}'\")\n",
    "print(f\"  Credit      ‚Üí '{credit_col}'\")\n",
    "print(f\"  Balance     ‚Üí '{balance_col}'\")\n",
    "\n",
    "has_balance = balance_col is not None and balance_col in table_headers\n",
    "print(f\"\\nüéØ Balance column detected: {'‚úÖ YES' if has_balance else '‚ùå NO'}\")\n",
    "\n",
    "if not has_balance:\n",
    "    print(\"‚ö†Ô∏è  WARNING: No balance column found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 1: Balance-Description Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Generate extraction prompt\n",
    "\n",
    "if has_balance:\n",
    "    extraction_prompt = f\"\"\"List all the balances in the {balance_col} column, including:\n",
    "- Date from the Date Header of the balance\n",
    "- {desc_col}\n",
    "- {debit_col} Amount or \"NOT_FOUND\"\n",
    "- {credit_col} Amount or \"NOT_FOUND\" \"\"\"\n",
    "    \n",
    "    print(\"üìù TURN 1: Balance-Description Extraction\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Extraction Prompt:\")\n",
    "    print(extraction_prompt)\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed - no balance column detected.\")\n",
    "    extraction_prompt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Execute Turn 1 extraction\n",
    "\n",
    "if extraction_prompt:\n",
    "    print(\"ü§ñ Generating response with InternVL3-8B...\")\n",
    "    \n",
    "    # Reload image for fresh context\n",
    "    pixel_values = load_image(imageName, input_size=448)\n",
    "    pixel_values = pixel_values.to(dtype=model_dtype, device='cuda:0')\n",
    "    \n",
    "    extraction_response = model.chat(\n",
    "        tokenizer=tokenizer,\n",
    "        pixel_values=pixel_values,\n",
    "        question=extraction_prompt,\n",
    "        generation_config={'max_new_tokens': 4096, 'do_sample': False}\n",
    "    )\n",
    "    \n",
    "    # Free memory\n",
    "    del pixel_values\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\n‚úÖ Turn 1 extraction complete!\")\n",
    "    print(f\"\\nüìä Response length: {len(extraction_response)} characters\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TURN 1 - BALANCE-DESCRIPTION EXTRACTION:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(extraction_response)\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    extraction_response = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Parsing: Balance-Description Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Parse balance-description response\n",
    "\n",
    "def parse_balance_description_response(response_text, date_col, desc_col, debit_col, credit_col, balance_col):\n",
    "    \"\"\"Parse the hierarchical balance-description response into transaction rows.\"\"\"\n",
    "    rows = []\n",
    "    current_date = None\n",
    "    current_transaction = {}\n",
    "    \n",
    "    lines = response_text.strip().split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Check for date header patterns\n",
    "        date_match = re.match(r\"^\\d+\\.\\s*\\*?\\*?([A-Za-z]{3}\\s+\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})\\*?\\*?\", line)\n",
    "        if not date_match:\n",
    "            date_match = re.match(r\"^\\d+\\.\\s*\\*?\\*?(\\d{1,2}\\s+[A-Za-z]{3}\\s+\\d{4})\\*?\\*?\", line)\n",
    "        if not date_match:\n",
    "            date_match = re.match(r\"^\\d+\\.\\s*\\*?\\*?(\\d{1,2}/\\d{1,2}/\\d{4})\\*?\\*?\", line)\n",
    "        \n",
    "        if date_match:\n",
    "            if current_transaction and current_date:\n",
    "                current_transaction[date_col] = current_date\n",
    "                rows.append(current_transaction)\n",
    "                current_transaction = {}\n",
    "            \n",
    "            current_date = date_match.group(1).strip()\n",
    "            continue\n",
    "        \n",
    "        # Check for field lines\n",
    "        field_match = re.match(r\"^\\s*-\\s*(\\w+):\\s*(.+)$\", line)\n",
    "        if field_match:\n",
    "            field_name = field_match.group(1).strip().lower()\n",
    "            field_value = field_match.group(2).strip()\n",
    "            \n",
    "            if field_name == \"description\":\n",
    "                if desc_col in current_transaction and current_transaction[desc_col]:\n",
    "                    if current_date:\n",
    "                        current_transaction[date_col] = current_date\n",
    "                    rows.append(current_transaction)\n",
    "                    current_transaction = {}\n",
    "                current_transaction[desc_col] = field_value\n",
    "            \n",
    "            elif field_name == \"debit\" or field_name == debit_col.lower() or field_name == \"withdrawal\":\n",
    "                current_transaction[debit_col] = field_value\n",
    "            \n",
    "            elif field_name == \"credit\" or field_name == credit_col.lower() or field_name == \"deposit\":\n",
    "                current_transaction[credit_col] = field_value\n",
    "            \n",
    "            elif field_name == \"balance\":\n",
    "                current_transaction[balance_col] = field_value\n",
    "            \n",
    "            elif field_name == \"amount\":\n",
    "                if debit_col not in current_transaction:\n",
    "                    current_transaction[debit_col] = field_value\n",
    "    \n",
    "    if current_transaction and current_date:\n",
    "        current_transaction[date_col] = current_date\n",
    "        rows.append(current_transaction)\n",
    "    \n",
    "    return rows\n",
    "\n",
    "\n",
    "def parse_markdown_table(markdown_text):\n",
    "    \"\"\"Fallback: Parse markdown table.\"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line:\n",
    "            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n",
    "            if cleaned:\n",
    "                header_idx = i\n",
    "                break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        return []\n",
    "    \n",
    "    header_line = lines[header_idx]\n",
    "    header_parts = [h.strip() for h in header_line.split('|')]\n",
    "    if header_parts and header_parts[0] == '':\n",
    "        header_parts = header_parts[1:]\n",
    "    if header_parts and header_parts[-1] == '':\n",
    "        header_parts = header_parts[:-1]\n",
    "    headers = [h for h in header_parts if h]\n",
    "    \n",
    "    rows = []\n",
    "    for line in lines[header_idx + 1:]:\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "        cleaned = line.replace('|', '').replace('-', '').replace(' ', '').replace(':', '')\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        value_parts = [v.strip() for v in line.split('|')]\n",
    "        if value_parts and value_parts[0] == '':\n",
    "            value_parts = value_parts[1:]\n",
    "        if value_parts and value_parts[-1] == '':\n",
    "            value_parts = value_parts[:-1]\n",
    "        if len(value_parts) == len(headers):\n",
    "            rows.append(dict(zip(headers, value_parts)))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "\n",
    "# Parse the extraction response\n",
    "if extraction_response:\n",
    "    all_rows = parse_balance_description_response(\n",
    "        extraction_response, date_col, desc_col, debit_col, credit_col, balance_col\n",
    "    )\n",
    "    \n",
    "    if not all_rows and \"|\" in extraction_response:\n",
    "        print(\"‚ö†Ô∏è  Fallback: parsing as markdown table\")\n",
    "        all_rows = parse_markdown_table(extraction_response)\n",
    "    \n",
    "    print(f\"\\nüìä Parsed {len(all_rows)} total rows\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PARSED TRANSACTIONS:\")\n",
    "    print(\"=\" * 60)\n",
    "    for i, row in enumerate(all_rows[:10]):\n",
    "        print(f\"\\n{i+1}. {row}\")\n",
    "    if len(all_rows) > 10:\n",
    "        print(f\"\\n... and {len(all_rows) - 10} more rows\")\n",
    "else:\n",
    "    all_rows = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for Debit Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Filter for debit transactions\n",
    "\n",
    "def parse_amount(value):\n",
    "    \"\"\"Extract numeric value from formatted currency string.\"\"\"\n",
    "    if not value or value.strip() == \"\":\n",
    "        return 0.0\n",
    "    cleaned = value.replace(\"$\", \"\").replace(\",\", \"\").replace(\"CR\", \"\").replace(\"DR\", \"\").strip()\n",
    "    try:\n",
    "        return float(cleaned)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def is_non_transaction_row(row, desc_col):\n",
    "    \"\"\"Check if this row is NOT an actual transaction.\"\"\"\n",
    "    desc = row.get(desc_col, \"\").strip().upper()\n",
    "    return any(x in desc for x in [\"OPENING BALANCE\", \"CLOSING BALANCE\", \"BROUGHT FORWARD\", \"CARRIED FORWARD\"])\n",
    "\n",
    "\n",
    "def filter_debit_transactions(rows, debit_col, desc_col=None):\n",
    "    \"\"\"Filter rows to only those with actual debit transactions.\"\"\"\n",
    "    debit_rows = []\n",
    "    for row in rows:\n",
    "        debit_value = row.get(debit_col, \"\").strip()\n",
    "        \n",
    "        if not debit_value or debit_value.upper() == \"NOT_FOUND\":\n",
    "            continue\n",
    "        \n",
    "        amount = parse_amount(debit_value)\n",
    "        if amount <= 0:\n",
    "            continue\n",
    "        \n",
    "        if desc_col and is_non_transaction_row(row, desc_col):\n",
    "            continue\n",
    "        \n",
    "        debit_rows.append(row)\n",
    "    \n",
    "    return debit_rows\n",
    "\n",
    "\n",
    "debit_rows = filter_debit_transactions(all_rows, debit_col, desc_col)\n",
    "\n",
    "print(f\"\\nüìä Filtered to {len(debit_rows)} debit transactions\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEBIT TRANSACTIONS ONLY:\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in enumerate(debit_rows):\n",
    "    date = row.get(date_col, \"N/A\")\n",
    "    desc = row.get(desc_col, \"N/A\")\n",
    "    amount = row.get(debit_col, \"N/A\")\n",
    "    print(f\"{i+1}. [{date}] {desc} - {amount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Schema Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Extract schema fields\n",
    "\n",
    "def extract_schema_fields(debit_rows, date_col, desc_col, debit_col, all_rows=None):\n",
    "    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n",
    "    if not debit_rows:\n",
    "        return {\n",
    "            \"DOCUMENT_TYPE\": \"BANK_STATEMENT\",\n",
    "            \"STATEMENT_DATE_RANGE\": \"NOT_FOUND\",\n",
    "            \"TRANSACTION_DATES\": \"NOT_FOUND\",\n",
    "            \"LINE_ITEM_DESCRIPTIONS\": \"NOT_FOUND\",\n",
    "            \"TRANSACTION_AMOUNTS_PAID\": \"NOT_FOUND\",\n",
    "        }\n",
    "    \n",
    "    debit_dates = [row.get(date_col, \"\").strip() for row in debit_rows if row.get(date_col)]\n",
    "    descriptions = [row.get(desc_col, \"\").strip() for row in debit_rows if row.get(desc_col)]\n",
    "    amounts = [row.get(debit_col, \"\").strip() for row in debit_rows if row.get(debit_col)]\n",
    "    \n",
    "    rows_for_range = all_rows if all_rows is not None else debit_rows\n",
    "    all_dates = [row.get(date_col, \"\").strip() for row in rows_for_range if row.get(date_col)]\n",
    "    date_range = f\"{all_dates[0]} - {all_dates[-1]}\" if all_dates else \"NOT_FOUND\"\n",
    "    \n",
    "    return {\n",
    "        \"DOCUMENT_TYPE\": \"BANK_STATEMENT\",\n",
    "        \"STATEMENT_DATE_RANGE\": date_range,\n",
    "        \"TRANSACTION_DATES\": \" | \".join(debit_dates) if debit_dates else \"NOT_FOUND\",\n",
    "        \"LINE_ITEM_DESCRIPTIONS\": \" | \".join(descriptions) if descriptions else \"NOT_FOUND\",\n",
    "        \"TRANSACTION_AMOUNTS_PAID\": \" | \".join(amounts) if amounts else \"NOT_FOUND\",\n",
    "    }\n",
    "\n",
    "\n",
    "schema_fields = extract_schema_fields(debit_rows, date_col, desc_col, debit_col, all_rows=all_rows)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTED SCHEMA FIELDS:\")\n",
    "print(\"=\" * 60)\n",
    "for field, value in schema_fields.items():\n",
    "    display_value = str(value)[:100] + \"...\" if len(str(value)) > 100 else str(value)\n",
    "    print(f\"\\n{field}:\")\n",
    "    print(f\"  {display_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Summary\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä EXTRACTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüîß Method: 2-Turn Balance-Description\")\n",
    "print(f\"üìã Headers detected: {len(table_headers)}\")\n",
    "print(f\"üí∞ Balance column: {balance_col}\")\n",
    "print(f\"üìù Total transactions parsed: {len(all_rows)}\")\n",
    "print(f\"üí∏ Debit transactions: {len(debit_rows)}\")\n",
    "print(f\"\\n‚úÖ Pipeline complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
