{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 Vision: Multi-Turn Bank Statement Markdown Extraction\n",
    "\n",
    "**Protocol**: Extract bank statement tables in markdown format, then filter/analyze via multi-turn conversation\n",
    "\n",
    "**No LangChain Dependencies** - Pure transformers + Llama multi-turn pattern\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Image â†’ LLM (Headers) â†’ Python (Pattern Match) â†’ LLM (Extract) â†’ \n",
    "LLM (Filter) â†’ Python (Parse to Schema) â†’ Final Fields\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify actual column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to generic concepts (Date, Description, Debit)\n",
    "3. **Turn 1 (LLM)**: Extract full markdown table with explicit dates for each transaction\n",
    "4. **Turn 2 (LLM)**: Filter to withdrawal/debit transactions only\n",
    "5. **Python Parsing**: Convert markdown to schema format (`TRANSACTION_DATES`, `LINE_ITEM_DESCRIPTIONS`, `TRANSACTION_AMOUNTS_PAID`, `STATEMENT_DATE_RANGE`)\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Uses **literal column names** from actual bank statement\n",
    "- âœ… Handles both **date-grouped** and **flat table** formats\n",
    "- âœ… Python parsing for reliable schema extraction\n",
    "- âœ… No langchain - production ready for V100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Loading Llama-3.2-Vision model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">ğŸš€ Loading Llama Vision model with robust multi-GPU optimization...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mğŸš€ Loading Llama Vision model with robust multi-GPU optimization\u001b[0m\u001b[1;34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Features: Smart quantization, memory management, V100 support</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFeatures: Smart quantization, memory management, V100 support\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”§ Configuring CUDA memory for Llama...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”§ Configuring CUDA memory for Llama\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ CUDA memory allocation configured: max_split_size_mb:64\n",
      "ğŸ’¡ Using 64MB memory blocks to reduce fragmentation\n",
      "ğŸ“Š Initial CUDA state (Multi-GPU Total): Allocated=0.00GB, Reserved=0.00GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ” Performing robust GPU memory detection...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ” Performing robust GPU memory detection\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Starting robust GPU memory detection...\n",
      "ğŸ“Š Detected 2 GPU(s), analyzing each device...\n",
      "   GPU 0 (NVIDIA L40S): 44.5GB total, 44.5GB available\n",
      "   GPU 1 (NVIDIA L40S): 44.5GB total, 44.5GB available\n",
      "\n",
      "======================================================================\n",
      "ğŸ” ROBUST GPU MEMORY DETECTION REPORT\n",
      "======================================================================\n",
      "âœ… Success: 2/2 GPUs detected\n",
      "ğŸ“Š Total Memory: 89.04GB\n",
      "ğŸ’¾ Available Memory: 89.04GB\n",
      "âš¡ Allocated Memory: 0.00GB\n",
      "ğŸ”„ Reserved Memory: 0.00GB\n",
      "ğŸ“¦ Fragmentation: 0.00GB\n",
      "ğŸ–¥ï¸  Multi-GPU: Yes\n",
      "âš–ï¸  Balanced Distribution: Yes\n",
      "\n",
      "ğŸ“‹ Per-GPU Breakdown:\n",
      "   GPU 0 (NVIDIA L40S): 44.5GB total, 44.5GB available (0.0% used)\n",
      "   GPU 1 (NVIDIA L40S): 44.5GB total, 44.5GB available (0.0% used)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ“Š GPU Hardware: NVIDIA L40S </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">2x 45GB = 89GB total</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ“Š GPU Hardware: NVIDIA L40S \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34m2x 45GB = 89GB total\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ—ï¸ Architecture: workstation_high_memory </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">dynamic detection</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ—ï¸ Architecture: workstation_high_memory \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mdynamic detection\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ¯ Model: Llama-</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3.2</span><span style=\"color: #000080; text-decoration-color: #000080\">-11B-Vision </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">estimated need: 22GB + </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">6.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB buffer</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ¯ Model: Llama-\u001b[0m\u001b[1;34m3.2\u001b[0m\u001b[34m-11B-Vision \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mestimated need: 22GB + \u001b[0m\u001b[1;34m6.\u001b[0m\u001b[34m0GB buffer\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ’¾ Available Memory: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">89.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB across </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">GPU(</span><span style=\"color: #000080; text-decoration-color: #000080\">s</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ’¾ Available Memory: \u001b[0m\u001b[1;34m89.\u001b[0m\u001b[34m0GB across \u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mGPU\u001b[0m\u001b[1;34m(\u001b[0m\u001b[34ms\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ’¡ Memory sufficient: âœ… Yes</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ’¡ Memory sufficient: âœ… Yes\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… workstation_high_memory with 89GB - running in full precision as requested</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… workstation_high_memory with 89GB - running in full precision as requested\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ“Š FINAL QUANTIZATION DECISION: DISABLED (full precision)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mğŸ“Š FINAL QUANTIZATION DECISION: DISABLED \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mfull precision\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Total GPU Memory: 89GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Total GPU Memory: 89GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Available Memory: 89GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Available Memory: 89GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Model needs: ~22GB + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>0GB buffer for Llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>-11B-Vision\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Model needs: ~22GB + \u001b[1;36m6.\u001b[0m0GB buffer for Llama-\u001b[1;36m3.2\u001b[0m-11B-Vision\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Working GPUs: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008080; text-decoration-color: #008080\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Working GPUs: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[36m/\u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ğŸš€ Using </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">16</span><span style=\"color: #008000; text-decoration-color: #008000\">-bit precision for optimal performance</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mğŸš€ Using \u001b[0m\u001b[1;32m16\u001b[0m\u001b[32m-bit precision for optimal performance\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading Llama Vision model...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading Llama Vision model\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”„ Auto-distributing model across </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> GPUs...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”„ Auto-distributing model across \u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m GPUs\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae536a24d0f445beb9f389a24b09af66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading processor...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading processor\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model and processor loaded successfully!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model and processor loaded successfully!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”„ Multi-GPU Distribution Analysis </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> GPUs</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span><span style=\"color: #000080; text-decoration-color: #000080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”„ Multi-GPU Distribution Analysis \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m GPUs\u001b[0m\u001b[1;34m)\u001b[0m\u001b[34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"font-weight: bold\">(</span>NVIDIA L40S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>8GB/48GB <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.8</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   GPU \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mNVIDIA L40S\u001b[1m)\u001b[0m: \u001b[1;36m9.\u001b[0m8GB/48GB \u001b[1m(\u001b[0m\u001b[1;36m20.8\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>NVIDIA L40S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.</span>6GB/48GB <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.4</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   GPU \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mNVIDIA L40S\u001b[1m)\u001b[0m: \u001b[1;36m11.\u001b[0m6GB/48GB \u001b[1m(\u001b[0m\u001b[1;36m24.4\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ“Š Total across all GPUs: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">21.</span><span style=\"color: #000080; text-decoration-color: #000080\">3GB allocated, </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">21.</span><span style=\"color: #000080; text-decoration-color: #000080\">6GB reserved, 96GB capacity</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ“Š Total across all GPUs: \u001b[0m\u001b[1;34m21.\u001b[0m\u001b[34m3GB allocated, \u001b[0m\u001b[1;34m21.\u001b[0m\u001b[34m6GB reserved, 96GB capacity\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model successfully distributed across GPUs</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model successfully distributed across GPUs\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> modules\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;36m0\u001b[0m: \u001b[1;36m18\u001b[0m modules\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> modules\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;36m1\u001b[0m: \u001b[1;36m28\u001b[0m modules\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                            ğŸ”§ Llama Vision Model Configuration                            </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Setting             </span>â”ƒ<span style=\"font-weight: bold\"> Value                         </span>â”ƒ<span style=\"font-weight: bold\"> Llama Status                      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model Path          </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> Llama-3.2-11B-Vision-Instruct </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Valid                          </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Device Placement    </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> cuda:0                        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Loaded                         </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Quantization Method </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 16-bit                        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… 16-bit (Performance Optimized) </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Data Type           </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> bfloat16                      </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Recommended                    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Max New Tokens      </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 2000                          </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Generation Ready               </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> GPU Configuration   </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 2x NVIDIA L40S (96GB)         </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… 96GB Total                     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model Parameters    </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 10,670,220,835                </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Loaded                         </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Memory Optimization </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> Llama Robust                  </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… V100 Compatible                </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                            ğŸ”§ Llama Vision Model Configuration                            \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mSetting            \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mValue                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mLlama Status                     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel Path         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mLlama-3.2-11B-Vision-Instruct\u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Valid                         \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mDevice Placement   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mcuda:0                       \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Loaded                        \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mQuantization Method\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m16-bit                       \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… 16-bit (Performance Optimized)\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mData Type          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mbfloat16                     \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Recommended                   \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mMax New Tokens     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m2000                         \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Generation Ready              \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mGPU Configuration  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m2x NVIDIA L40S (96GB)        \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… 96GB Total                    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel Parameters   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m10,670,220,835               \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Loaded                        \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mMemory Optimization\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mLlama Robust                 \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… V100 Compatible               \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Running model compatibility test...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mRunning model compatibility test\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model compatibility test passed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model compatibility test passed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Performing initial memory cleanup...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mPerforming initial memory cleanup\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸ§¹ Memory cleanup completed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸ§¹ Memory cleanup completed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸ’¾ Final state <span style=\"font-weight: bold\">(</span>Multi-GPU Total<span style=\"font-weight: bold\">)</span>: <span style=\"color: #808000; text-decoration-color: #808000\">Allocated</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>34GB, <span style=\"color: #808000; text-decoration-color: #808000\">Reserved</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>65GB, <span style=\"color: #808000; text-decoration-color: #808000\">Fragmentation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>30GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸ’¾ Final state \u001b[1m(\u001b[0mMulti-GPU Total\u001b[1m)\u001b[0m: \u001b[33mAllocated\u001b[0m=\u001b[1;36m21\u001b[0m\u001b[1;36m.\u001b[0m34GB, \u001b[33mReserved\u001b[0m=\u001b[1;36m21\u001b[0m\u001b[1;36m.\u001b[0m65GB, \u001b[33mFragmentation\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0m30GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ‰ Llama Vision model loading and validation complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mğŸ‰ Llama Vision model loading and validation complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”§ Llama optimizations active: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">16</span><span style=\"color: #000080; text-decoration-color: #000080\">-bit precision, memory management, vision preservation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”§ Llama optimizations active: \u001b[0m\u001b[1;34m16\u001b[0m\u001b[34m-bit precision, memory management, vision preservation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model weights tied successfully\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your local Llama model\n",
    "# model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"ğŸ”§ Loading Llama-3.2-Vision model...\")\n",
    "# model = MllamaForConditionalGeneration.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_id,\n",
    "    use_quantization=False,\n",
    "    device_map='auto',\n",
    "    max_new_tokens=2000,\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Add tie_weights() call\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    print(\"âœ… Model weights tied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ tie_weights() warning: {e}\")\n",
    "\n",
    "# processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Loading image...\n",
      "âœ… Image loaded: (600, 800)\n",
      "âœ… Images list created with 1 image(s)\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/shared_PoC_data/evaluation_data/synthetic_bank_images/cba_amount_balance.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/images/image_003.png\"\n",
    "print(\"ğŸ“ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"âœ… Image loaded: {image.size}\")\n",
    "print(f\"âœ… Images list created with {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Turn Bank Statement Protocol\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract full table using those headers\n",
    "- Turn 2: Filter using the actual column names found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ TURN 0: Identifying actual table headers\n",
      "ğŸ¤– Generating response with Llama-3.2-Vision...\n"
     ]
    }
   ],
   "source": [
    "# TURN 0: Identify Table Headers\n",
    "# First, identify the actual column headers used in this specific bank statement\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "IMPORTANT STRUCTURAL NOTE:\n",
    "Some bank statements show dates as section headings with multiple transactions underneath.\n",
    "If you see this structure, remember that each transaction needs its explicit date in the final output.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ’¬ TURN 0: Identifying actual table headers\")\n",
    "print(\"ğŸ¤– Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process the input using the CORRECT multi-turn pattern\n# Based on: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n\ntextInput = processor.apply_chat_template(\n    messageDataStructure, add_generation_prompt=True\n)\n\n# CRITICAL: Use named parameter 'images=' with list\ninputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n\n# Generate response with deterministic parameters\noutput = model.generate(\n    **inputs,\n    max_new_tokens=2000,\n    do_sample=False,\n    temperature=None,\n    top_p=None,\n)\n\n# CRITICAL: Trim input tokens from output (this is the key to clean responses!)\ngenerate_ids = output[:, inputs['input_ids'].shape[1]:-1]\ncleanedOutput = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n\nprint(\"âœ… Response generated successfully!\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\nprint(\"=\" * 60)\nprint(cleanedOutput)\nprint(\"=\" * 60)\n\n# CRITICAL: Parse the identified headers for use in subsequent turns\n# Extract column names from the response\nheader_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\nidentified_headers = []\n\n# Look for numbered list or bullet points\nfor line in header_lines:\n    # Remove common list markers\n    cleaned = line.lstrip('0123456789.-â€¢* ').strip()\n    \n    # Strip markdown bold formatting\n    cleaned = cleaned.replace('**', '').replace('__', '')\n    \n    # Skip section headers (lines ending with colon)\n    if cleaned.endswith(':'):\n        continue\n    \n    # Skip long sentences (likely explanatory text, not headers)\n    if len(cleaned) > 40:\n        continue\n        \n    if cleaned and len(cleaned) > 2:  # Ignore very short strings\n        identified_headers.append(cleaned)\n\nprint(f\"\\nğŸ“‹ Parsed {len(identified_headers)} column headers:\")\nfor i, header in enumerate(identified_headers, 1):\n    print(f\"  {i}. '{header}'\")\n\n# Store headers for use in subsequent turns\ntable_headers = identified_headers\n\n# Save the table headers\noutput_path = Path(\"llama_table_headers.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(cleanedOutput)\n\nprint(f\"\\nâœ… Table headers saved to: {output_path}\")\nprint(\"ğŸ’¡ These LITERAL header names will be used in Turn 1 & 2 prompts\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PATTERN MATCHING RESULTS:\n",
      "============================================================\n",
      "ğŸ“‹ Extracted Headers: ['Transaction Table Column Headers:', 'Date', 'Description', 'Withdrawal', 'Deposit', 'Balance']\n",
      "\n",
      "ğŸ” Mapped Columns:\n",
      "  Date       â†’ 'Date'\n",
      "  Description â†’ 'Description'\n",
      "  Debit      â†’ 'Withdrawal'\n",
      "  Credit     â†’ 'Deposit'\n",
      "  Balance    â†’ 'Balance'\n",
      "============================================================\n",
      "\n",
      "âœ… These literal column names will be used in Turn 1 and Turn 2\n",
      "ğŸ’¡ Adjust patterns above if matching fails for your bank statement format\n"
     ]
    }
   ],
   "source": [
    "# Pattern Matching: Map extracted headers to generic concepts\n",
    "# This handles variety in bank statement column naming conventions\n",
    "\n",
    "# Pattern keywords for each concept (in priority order)\n",
    "DATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\n",
    "DESCRIPTION_PATTERNS = [\n",
    "    'description', 'details', 'transaction details', 'trans details',\n",
    "    'particulars', 'narrative', 'transaction', 'trans'\n",
    "]\n",
    "DEBIT_PATTERNS = ['debit', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\n",
    "CREDIT_PATTERNS = ['credit', 'deposit', 'deposits', 'received', 'cr']\n",
    "BALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n",
    "\n",
    "def match_header(headers, patterns, fallback=None):\n",
    "    \"\"\"Match a header using pattern keywords.\"\"\"\n",
    "    headers_lower = [h.lower() for h in headers]\n",
    "    \n",
    "    # Try exact match first\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern == header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    # Try substring match\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern in header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    return fallback\n",
    "\n",
    "# Perform pattern matching on extracted headers\n",
    "date_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\n",
    "desc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n",
    "debit_col = match_header(table_headers, DEBIT_PATTERNS, fallback='Debit')\n",
    "credit_col = match_header(table_headers, CREDIT_PATTERNS, fallback='Credit')\n",
    "balance_col = match_header(table_headers, BALANCE_PATTERNS, fallback='Balance')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATTERN MATCHING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“‹ Extracted Headers: {table_headers}\")\n",
    "print(f\"\\nğŸ” Mapped Columns:\")\n",
    "print(f\"  Date       â†’ '{date_col}'\")\n",
    "print(f\"  Description â†’ '{desc_col}'\")\n",
    "print(f\"  Debit      â†’ '{debit_col}'\")\n",
    "print(f\"  Credit     â†’ '{credit_col}'\")\n",
    "print(f\"  Balance    â†’ '{balance_col}'\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nâœ… These literal column names will be used in Turn 1 and Turn 2\")\n",
    "print(\"ğŸ’¡ Adjust patterns above if matching fails for your bank statement format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation Support\n",
    "\n",
    "Llama supports multi-turn conversations by maintaining a conversation history list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”‘ Key Multi-Turn Pattern for Llama 3.2 Vision\n",
    "\n",
    "This notebook uses the **correct multi-turn conversation pattern** discovered from the Medium article:\n",
    "[Chat with Your Images Using Llama 3.2-Vision Multimodal LLMs](https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa)\n",
    "\n",
    "#### Critical Requirements:\n",
    "\n",
    "1. **Images as List**: `images = [image]` (not just `image`)\n",
    "2. **Named Parameter**: `processor(images=images, text=text, ...)` (not positional args)\n",
    "3. **Trim Generated Tokens**: `generate_ids[:, inputs['input_ids'].shape[1]:-1]`\n",
    "4. **Same Images Every Turn**: Pass the same `images` list for all turns\n",
    "\n",
    "#### Message Structure:\n",
    "\n",
    "- **Turn 1**: `{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "- **Turn 2+**: `{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}` (no image in content)\n",
    "- **Assistant**: `{\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "\n",
    "The model attends to the image only in the first turn, but the processor needs the images list for all turns because the chat template contains the `<|image|>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conversation history initialized\n",
      "ğŸ“Š Current conversation has 2 messages (1 user + 1 assistant)\n",
      "ğŸ’¡ Pattern: Using working multi-turn approach from Medium article\n"
     ]
    }
   ],
   "source": [
    "# Store conversation history for multi-turn support\n",
    "# Initialize with first exchange\n",
    "conversation_history = messageDataStructure.copy()\n",
    "\n",
    "# Add assistant's response to history\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput}]\n",
    "})\n",
    "\n",
    "print(\"âœ… Conversation history initialized\")\n",
    "print(f\"ğŸ“Š Current conversation has {len(conversation_history)} messages (1 user + 1 assistant)\")\n",
    "print(f\"ğŸ’¡ Pattern: Using working multi-turn approach from Medium article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug: View Conversation Context\n",
    "\n",
    "This cell helps you see what's being sent to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Debug conversation structure\n",
    "# print(\"ğŸ” Current conversation structure:\")\n",
    "# print(\"=\" * 60)\n",
    "# for i, msg in enumerate(conversation_history, 1):\n",
    "#     print(f\"\\nMessage {i} ({msg['role']}):\")\n",
    "#     for content in msg['content']:\n",
    "#         if content['type'] == 'text':\n",
    "#             preview = content['text'][:100] + \"...\" if len(content['text']) > 100 else content['text']\n",
    "#             print(f\"  [text]: {preview}\")\n",
    "#         else:\n",
    "#             print(f\"  [{content['type']}]\")\n",
    "# print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 1: Extract Full Table in Markdown\n",
    "\n",
    "Now that we know the actual column headers, extract the complete table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ TURN 1: Extract full markdown table\n",
      "ğŸ“‹ Using literal headers: ['Transaction Table Column Headers:', 'Date', 'Description', 'Withdrawal', 'Deposit', 'Balance']\n",
      "ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\n",
      "\n",
      "âœ… Follow-up response generated successfully!\n",
      "\n",
      "============================================================\n",
      "TURN 1 - FULL MARKDOWN TABLE:\n",
      "============================================================\n",
      "| Transaction Table Column Headers: | Date | Description | Withdrawal | Deposit | Balance |\n",
      "| --- | --- | --- | --- | --- | --- |\n",
      "| 03/05/2025 | ONLINE PURCHASE AMAZON AU | $288.03 |  | $13387.44 |\n",
      "| 04/05/2025 | EFTPOS PURCHASE COLES EXP | $22.50 |  | $13344.94 |\n",
      "| 05/05/2025 | EFTPOS PURCHASE COLES EXP | $114.66 |  | $13230.27 |\n",
      "| 06/05/2025 | DIRECT CREDIT SALARY |  |  | $16727.74 |\n",
      "| 07/05/2025 | ATM WITHDRAWAL ANZ ATM | $187.59 |  | $16540.15 |\n",
      "| 08/05/2025 | EFTPOS PURCHASE COLES EXP | $112.50 |  | $16427.65 |\n",
      "| 09/05/2025 | INTEREST PAYMENT |  | $5.16 | $16432.81 |\n",
      "| 10/05/2025 | ATM WITHDRAWAL ANZ ATM | $146.72 |  | $16286.08 |\n",
      "============================================================\n",
      "\n",
      "âœ… Markdown table saved to: llama_markdown_table_extraction.txt\n",
      "\n",
      "ğŸ“Š Conversation now has 4 messages\n",
      "ğŸ’¡ Each transaction has explicit date, even if grouped by date heading\n"
     ]
    }
   ],
   "source": [
    "# TURN 1: Extract Full Table with LITERAL Header Names\n",
    "# Using the WORKING pattern from: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "# Build the header string using LITERAL names from Turn 0\n",
    "header_string = \" | \".join(table_headers)\n",
    "\n",
    "follow_up_prompt = f\"\"\"\n",
    "Now extract the entire transaction table from the bank statement in markdown format.\n",
    "\n",
    "Use these EXACT column headers in this order:\n",
    "{header_string}\n",
    "\n",
    "Format requirements:\n",
    "- Standard markdown table syntax with | delimiters\n",
    "- Header row: | {header_string} |\n",
    "- Separator row: | {\" | \".join([\"---\"] * len(table_headers))} |\n",
    "\n",
    "CRITICAL EXTRACTION RULES:\n",
    "1. Extract EVERY transaction as a separate row\n",
    "2. Each transaction MUST have its explicit date in the date column\n",
    "3. If multiple transactions share a date heading, repeat that date for each transaction row\n",
    "4. Do NOT skip or combine any rows\n",
    "5. Keep all amounts with decimal values intact\n",
    "6. Do NOT add explanatory text - only output the markdown table\n",
    "\n",
    "Example: If you see:\n",
    "  01/06/2024\n",
    "    Transaction A    $100\n",
    "    Transaction B    $50\n",
    "    \n",
    "Output as TWO rows:\n",
    "  | 01/06/2024 | Transaction A | $100 | ... |\n",
    "  | 01/06/2024 | Transaction B | $50  | ... |\n",
    "\"\"\"\n",
    "\n",
    "# Append user's follow-up to conversation history (text only - NO image in content)\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt}]\n",
    "})\n",
    "\n",
    "print(f\"ğŸ’¬ TURN 1: Extract full markdown table\")\n",
    "print(f\"ğŸ“‹ Using literal headers: {table_headers}\")\n",
    "print(\"ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with updated conversation history\n",
    "textInput = processor.apply_chat_template(\n",
    "    conversation_history, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' and pass the SAME images list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput2 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\nâœ… Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 1 - FULL MARKDOWN TABLE:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput2)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save the markdown table\n",
    "output_path = Path(\"llama_markdown_table_extraction.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput2)\n",
    "\n",
    "print(f\"\\nâœ… Markdown table saved to: {output_path}\")\n",
    "\n",
    "# Update conversation history with assistant's response\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput2}]\n",
    "})\n",
    "\n",
    "print(f\"\\nğŸ“Š Conversation now has {len(conversation_history)} messages\")\n",
    "print(\"ğŸ’¡ Each transaction has explicit date, even if grouped by date heading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 2: Filter Using Actual Column Names\n",
    "\n",
    "Filter the extracted table using the specific column names identified in Turn 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ TURN 2: Filter using literal column names\n",
      "ğŸ“‹ Filter columns: 'Date' | 'Description' | 'Withdrawal'\n",
      "ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\n",
      "\n",
      "âœ… Follow-up response generated successfully!\n",
      "\n",
      "============================================================\n",
      "TURN 2 - FILTERED WITHDRAWALS:\n",
      "============================================================\n",
      "| Date | Description | Withdrawal |\n",
      "| --- | --- | --- |\n",
      "| 03/05/2025 | ONLINE PURCHASE AMAZON AU | $288.03 |\n",
      "| 04/05/2025 | EFTPOS PURCHASE COLES EXP | $22.50 |\n",
      "| 05/05/2025 | EFTPOS PURCHASE COLES EXP | $114.66 |\n",
      "| 07/05/2025 | ATM WITHDRAWAL ANZ ATM | $187.59 |\n",
      "| 08/05/2025 | EFTPOS PURCHASE COLES EXP | $112.50 |\n",
      "| 10/05/2025 | ATM WITHDRAWAL ANZ ATM | $146.72 |\n",
      "============================================================\n",
      "\n",
      "âœ… Filtered table saved to: llama_filtered_withdrawals.txt\n",
      "\n",
      "ğŸ“Š Conversation now has 6 messages\n",
      "\n",
      "âœ… Complete Protocol:\n",
      "   Turn 0: Identify headers â†’ ['Transaction Table Column Headers:', 'Date', 'Description', 'Withdrawal', 'Deposit', 'Balance']\n",
      "   Pattern Match: Date='Date', Desc='Description', Debit='Withdrawal'\n",
      "   Turn 1: Extract with all headers\n",
      "   Turn 2: Filter using 'Withdrawal' column\n",
      "\n",
      "âœ… No langchain dependencies - production ready!\n"
     ]
    }
   ],
   "source": [
    "# TURN 2: Filter using LITERAL column names from pattern matching\n",
    "\n",
    "follow_up_prompt_3 = f\"\"\"\n",
    "From the markdown table you just extracted, create a filtered version showing ONLY withdrawal/debit transactions.\n",
    "\n",
    "Use these EXACT column names:\n",
    "- {date_col}\n",
    "- {desc_col}  \n",
    "- {debit_col}\n",
    "\n",
    "Filter rules:\n",
    "- Only include rows where '{debit_col}' has a value (not empty)\n",
    "- Exclude credit/deposit transactions\n",
    "- Keep the markdown table format with header: | {date_col} | {desc_col} | {debit_col} |\n",
    "\n",
    "Output only the filtered markdown table.\n",
    "\"\"\"\n",
    "\n",
    "# Append user's follow-up to conversation history\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt_3}]\n",
    "})\n",
    "\n",
    "print(f\"ğŸ’¬ TURN 2: Filter using literal column names\")\n",
    "print(f\"ğŸ“‹ Filter columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")\n",
    "print(\"ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with updated conversation history\n",
    "textInput = processor.apply_chat_template(\n",
    "    conversation_history, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Use named parameter 'images=' and pass the SAME images list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput3 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\nâœ… Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 2 - FILTERED WITHDRAWALS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput3)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save filtered results\n",
    "output_path = Path(\"llama_filtered_withdrawals.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput3)\n",
    "\n",
    "print(f\"\\nâœ… Filtered table saved to: {output_path}\")\n",
    "\n",
    "# Update conversation history with assistant's response\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput3}]\n",
    "})\n",
    "\n",
    "print(f\"\\nğŸ“Š Conversation now has {len(conversation_history)} messages\")\n",
    "print(f\"\\nâœ… Complete Protocol:\")\n",
    "print(f\"   Turn 0: Identify headers â†’ {table_headers}\")\n",
    "print(f\"   Pattern Match: Date='{date_col}', Desc='{desc_col}', Debit='{debit_col}'\")\n",
    "print(f\"   Turn 1: Extract with all headers\")\n",
    "print(f\"   Turn 2: Filter using '{debit_col}' column\")\n",
    "print(\"\\nâœ… No langchain dependencies - production ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Parsing: Extract Key Fields from Markdown Table\n",
    "\n",
    "Parse the filtered markdown table and extract fields in schema format:\n",
    "- `TRANSACTION_DATES`\n",
    "- `LINE_ITEM_DESCRIPTIONS`\n",
    "- `TRANSACTION_AMOUNTS_PAID`\n",
    "- `STATEMENT_DATE_RANGE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Parsed 6 transactions from markdown table\n",
      "\n",
      "============================================================\n",
      "SAMPLE ROWS:\n",
      "============================================================\n",
      "\n",
      "Row 1:\n",
      "  Date: 03/05/2025\n",
      "  Description: ONLINE PURCHASE AMAZON AU\n",
      "  Withdrawal: $288.03\n",
      "\n",
      "Row 2:\n",
      "  Date: 04/05/2025\n",
      "  Description: EFTPOS PURCHASE COLES EXP\n",
      "  Withdrawal: $22.50\n",
      "\n",
      "Row 3:\n",
      "  Date: 05/05/2025\n",
      "  Description: EFTPOS PURCHASE COLES EXP\n",
      "  Withdrawal: $114.66\n",
      "\n",
      "============================================================\n",
      "EXTRACTED SCHEMA FIELDS:\n",
      "============================================================\n",
      "TRANSACTION_DATES: 03/05/2025 | 04/05/2025 | 05/05/2025 | 07/05/2025 | 08/05/2025 | 10/05/2025\n",
      "LINE_ITEM_DESCRIPTIONS: ONLINE PURCHASE AMAZON AU | EFTPOS PURCHASE COLES EXP | EFTPOS PURCHASE COLES EXP | ATM WITHDRAWAL ANZ ATM | EFTPOS PURCHASE COLES EXP | ATM WITHDRAWAL ANZ ATM\n",
      "TRANSACTION_AMOUNTS_PAID: $288.03 | $22.50 | $114.66 | $187.59 | $112.50 | $146.72\n",
      "STATEMENT_DATE_RANGE: 03/05/2025 to 10/05/2025\n",
      "============================================================\n",
      "\n",
      "âœ… Schema fields saved to: llama_extracted_fields.txt\n",
      "ğŸ’¡ Fields extracted from columns: 'Date' | 'Description' | 'Withdrawal'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_markdown_table(markdown_text):\n",
    "    \"\"\"Parse markdown table into list of dictionaries.\"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    # Find header row (first line with pipes)\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line and not set(line.replace('|', '').replace('-', '').strip()) == set():\n",
    "            header_idx = i\n",
    "            break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        return []\n",
    "    \n",
    "    # Parse headers\n",
    "    header_line = lines[header_idx]\n",
    "    headers = [h.strip() for h in header_line.split('|') if h.strip()]\n",
    "    \n",
    "    # Parse data rows (skip header and separator)\n",
    "    rows = []\n",
    "    for line in lines[header_idx + 1:]:\n",
    "        if '|' in line:\n",
    "            # Skip separator rows (contain only pipes, hyphens, and spaces)\n",
    "            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n",
    "            if not cleaned:\n",
    "                continue\n",
    "            \n",
    "            values = [v.strip() for v in line.split('|') if v.strip()]\n",
    "            if len(values) == len(headers):\n",
    "                rows.append(dict(zip(headers, values)))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def extract_schema_fields(rows, date_col, desc_col, debit_col):\n",
    "    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n",
    "    if not rows:\n",
    "        return {\n",
    "            'TRANSACTION_DATES': 'NOT_FOUND',\n",
    "            'LINE_ITEM_DESCRIPTIONS': 'NOT_FOUND',\n",
    "            'TRANSACTION_AMOUNTS_PAID': 'NOT_FOUND',\n",
    "            'STATEMENT_DATE_RANGE': 'NOT_FOUND'\n",
    "        }\n",
    "    \n",
    "    # Extract lists\n",
    "    dates = []\n",
    "    descriptions = []\n",
    "    amounts = []\n",
    "    \n",
    "    for row in rows:\n",
    "        date = row.get(date_col, '').strip()\n",
    "        desc = row.get(desc_col, '').strip()\n",
    "        amount = row.get(debit_col, '').strip()\n",
    "        \n",
    "        if date:\n",
    "            dates.append(date)\n",
    "        if desc:\n",
    "            descriptions.append(desc)\n",
    "        if amount:\n",
    "            amounts.append(amount)\n",
    "    \n",
    "    # Calculate statement date range\n",
    "    date_range = 'NOT_FOUND'\n",
    "    if dates:\n",
    "        try:\n",
    "            # Try to parse dates to find min/max\n",
    "            parsed_dates = []\n",
    "            for d in dates:\n",
    "                # Try common formats\n",
    "                for fmt in ['%d/%m/%Y', '%d/%m/%y', '%Y-%m-%d', '%d-%m-%Y']:\n",
    "                    try:\n",
    "                        parsed_dates.append(datetime.strptime(d, fmt))\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            \n",
    "            if parsed_dates:\n",
    "                min_date = min(parsed_dates)\n",
    "                max_date = max(parsed_dates)\n",
    "                date_range = f\"{min_date.strftime('%d/%m/%Y')} to {max_date.strftime('%d/%m/%Y')}\"\n",
    "        except Exception:\n",
    "            # If parsing fails, use first and last date as-is\n",
    "            date_range = f\"{dates[0]} to {dates[-1]}\"\n",
    "    \n",
    "    return {\n",
    "        'TRANSACTION_DATES': ' | '.join(dates) if dates else 'NOT_FOUND',\n",
    "        'LINE_ITEM_DESCRIPTIONS': ' | '.join(descriptions) if descriptions else 'NOT_FOUND',\n",
    "        'TRANSACTION_AMOUNTS_PAID': ' | '.join(amounts) if amounts else 'NOT_FOUND',\n",
    "        'STATEMENT_DATE_RANGE': date_range\n",
    "    }\n",
    "\n",
    "# Parse the filtered markdown table from Turn 2\n",
    "parsed_rows = parse_markdown_table(cleanedOutput3)\n",
    "\n",
    "print(f\"ğŸ“Š Parsed {len(parsed_rows)} transactions from markdown table\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE ROWS:\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in enumerate(parsed_rows[:3], 1):\n",
    "    print(f\"\\nRow {i}:\")\n",
    "    for key, value in row.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract schema fields using the LITERAL column names from pattern matching\n",
    "schema_fields = extract_schema_fields(parsed_rows, date_col, desc_col, debit_col)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTED SCHEMA FIELDS:\")\n",
    "print(\"=\" * 60)\n",
    "for field, value in schema_fields.items():\n",
    "    print(f\"{field}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save to file\n",
    "output_path = Path(\"llama_extracted_fields.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for field, value in schema_fields.items():\n",
    "        f.write(f\"{field}: {value}\\n\")\n",
    "\n",
    "print(f\"\\nâœ… Schema fields saved to: {output_path}\")\n",
    "print(f\"ğŸ’¡ Fields extracted from columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Multi-Turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the entire conversation to a file\n",
    "# output_path = Path(\"llama_multiturn_conversation.txt\")\n",
    "\n",
    "# with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "#     text_file.write(\"=\" * 60 + \"\\n\")\n",
    "#     text_file.write(\"MULTI-TURN CONVERSATION WITH LLAMA-3.2-VISION\\n\")\n",
    "#     text_file.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "#     for i, msg in enumerate(conversation_history, 1):\n",
    "#         role = msg[\"role\"].upper()\n",
    "#         text_file.write(f\"\\n{'-' * 60}\\n\")\n",
    "#         text_file.write(f\"MESSAGE {i} - {role}\\n\")\n",
    "#         text_file.write(f\"{'-' * 60}\\n\\n\")\n",
    "        \n",
    "#         for content in msg[\"content\"]:\n",
    "#             if content[\"type\"] == \"text\":\n",
    "#                 text_file.write(content[\"text\"] + \"\\n\")\n",
    "#             elif content[\"type\"] == \"image\":\n",
    "#                 text_file.write(\"[IMAGE]\\n\")\n",
    "    \n",
    "#     text_file.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "#     text_file.write(f\"Total messages: {len(conversation_history)}\\n\")\n",
    "#     text_file.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# print(f\"âœ… Full conversation saved to: {output_path}\")\n",
    "# print(f\"ğŸ“Š File size: {output_path.stat().st_size} bytes\")\n",
    "# print(f\"ğŸ’¬ Total messages in conversation: {len(conversation_history)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}