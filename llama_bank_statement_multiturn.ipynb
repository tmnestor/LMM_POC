{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 Vision: Multi-Turn Bank Statement Markdown Extraction\n",
    "\n",
    "**Protocol**: Extract bank statement tables in markdown format, then filter/analyze via multi-turn conversation\n",
    "\n",
    "**No LangChain Dependencies** - Pure transformers + Llama multi-turn pattern\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Image â†’ LLM (Headers) â†’ Python (Pattern Match) â†’ LLM (Extract) â†’ \n",
    "LLM (Filter) â†’ Python (Parse to Schema) â†’ Final Fields\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify actual column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to generic concepts (Date, Description, Debit)\n",
    "3. **Turn 1 (LLM)**: Extract full markdown table with explicit dates for each transaction\n",
    "4. **Turn 2 (LLM)**: Filter to withdrawal/debit transactions only\n",
    "5. **Python Parsing**: Convert markdown to schema format (`TRANSACTION_DATES`, `LINE_ITEM_DESCRIPTIONS`, `TRANSACTION_AMOUNTS_PAID`, `STATEMENT_DATE_RANGE`)\n",
    "\n",
    "### Key Features:\n",
    "- âœ… Uses **literal column names** from actual bank statement\n",
    "- âœ… Handles both **date-grouped** and **flat table** formats\n",
    "- âœ… Python parsing for reliable schema extraction\n",
    "- âœ… No langchain - production ready for V100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Loading Llama-3.2-Vision model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">ğŸš€ Loading Llama Vision model with robust multi-GPU optimization...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mğŸš€ Loading Llama Vision model with robust multi-GPU optimization\u001b[0m\u001b[1;34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Features: Smart quantization, memory management, V100 support</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mFeatures: Smart quantization, memory management, V100 support\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”§ Configuring CUDA memory for Llama...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”§ Configuring CUDA memory for Llama\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ CUDA memory allocation configured: max_split_size_mb:64\n",
      "ğŸ’¡ Using 64MB memory blocks to reduce fragmentation\n",
      "ğŸ“Š Initial CUDA state (Multi-GPU Total): Allocated=0.00GB, Reserved=0.00GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ” Performing robust GPU memory detection...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ” Performing robust GPU memory detection\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Starting robust GPU memory detection...\n",
      "ğŸ“Š Detected 2 GPU(s), analyzing each device...\n",
      "   GPU 0 (NVIDIA L40S): 44.5GB total, 44.5GB available\n",
      "   GPU 1 (NVIDIA L40S): 44.5GB total, 44.5GB available\n",
      "\n",
      "======================================================================\n",
      "ğŸ” ROBUST GPU MEMORY DETECTION REPORT\n",
      "======================================================================\n",
      "âœ… Success: 2/2 GPUs detected\n",
      "ğŸ“Š Total Memory: 89.04GB\n",
      "ğŸ’¾ Available Memory: 89.04GB\n",
      "âš¡ Allocated Memory: 0.00GB\n",
      "ğŸ”„ Reserved Memory: 0.00GB\n",
      "ğŸ“¦ Fragmentation: 0.00GB\n",
      "ğŸ–¥ï¸  Multi-GPU: Yes\n",
      "âš–ï¸  Balanced Distribution: Yes\n",
      "\n",
      "ğŸ“‹ Per-GPU Breakdown:\n",
      "   GPU 0 (NVIDIA L40S): 44.5GB total, 44.5GB available (0.0% used)\n",
      "   GPU 1 (NVIDIA L40S): 44.5GB total, 44.5GB available (0.0% used)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ“Š GPU Hardware: NVIDIA L40S </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">2x 45GB = 89GB total</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ“Š GPU Hardware: NVIDIA L40S \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34m2x 45GB = 89GB total\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ—ï¸ Architecture: workstation_high_memory </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">dynamic detection</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ—ï¸ Architecture: workstation_high_memory \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mdynamic detection\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ¯ Model: Llama-</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">3.2</span><span style=\"color: #000080; text-decoration-color: #000080\">-11B-Vision </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080\">estimated need: 22GB + </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">6.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB buffer</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ¯ Model: Llama-\u001b[0m\u001b[1;34m3.2\u001b[0m\u001b[34m-11B-Vision \u001b[0m\u001b[1;34m(\u001b[0m\u001b[34mestimated need: 22GB + \u001b[0m\u001b[1;34m6.\u001b[0m\u001b[34m0GB buffer\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ’¾ Available Memory: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">89.</span><span style=\"color: #000080; text-decoration-color: #000080\">0GB across </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">GPU(</span><span style=\"color: #000080; text-decoration-color: #000080\">s</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ’¾ Available Memory: \u001b[0m\u001b[1;34m89.\u001b[0m\u001b[34m0GB across \u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m \u001b[0m\u001b[1;34mGPU\u001b[0m\u001b[1;34m(\u001b[0m\u001b[34ms\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ’¡ Memory sufficient: âœ… Yes</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ’¡ Memory sufficient: âœ… Yes\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… workstation_high_memory with 89GB - running in full precision as requested</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… workstation_high_memory with 89GB - running in full precision as requested\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸ“Š FINAL QUANTIZATION DECISION: DISABLED (full precision)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mğŸ“Š FINAL QUANTIZATION DECISION: DISABLED \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mfull precision\u001b[0m\u001b[1;36m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Total GPU Memory: 89GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Total GPU Memory: 89GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Available Memory: 89GB</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Available Memory: 89GB\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Model needs: ~22GB + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.</span>0GB buffer for Llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>-11B-Vision\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Model needs: ~22GB + \u001b[1;36m6.\u001b[0m0GB buffer for Llama-\u001b[1;36m3.2\u001b[0m-11B-Vision\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">   Working GPUs: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008080; text-decoration-color: #008080\">/</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m   Working GPUs: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[36m/\u001b[0m\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">ğŸš€ Using </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">16</span><span style=\"color: #008000; text-decoration-color: #008000\">-bit precision for optimal performance</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mğŸš€ Using \u001b[0m\u001b[1;32m16\u001b[0m\u001b[32m-bit precision for optimal performance\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading Llama Vision model...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading Llama Vision model\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”„ Auto-distributing model across </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> GPUs...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”„ Auto-distributing model across \u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m GPUs\u001b[0m\u001b[34m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da069c25c8954b0289749c5b87222187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Loading processor...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mLoading processor\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model and processor loaded successfully!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model and processor loaded successfully!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”„ Multi-GPU Distribution Analysis </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080\"> GPUs</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">)</span><span style=\"color: #000080; text-decoration-color: #000080\">:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”„ Multi-GPU Distribution Analysis \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34m2\u001b[0m\u001b[34m GPUs\u001b[0m\u001b[1;34m)\u001b[0m\u001b[34m:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> <span style=\"font-weight: bold\">(</span>NVIDIA L40S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.</span>8GB/48GB <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20.8</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   GPU \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mNVIDIA L40S\u001b[1m)\u001b[0m: \u001b[1;36m9.\u001b[0m8GB/48GB \u001b[1m(\u001b[0m\u001b[1;36m20.8\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>NVIDIA L40S<span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.</span>6GB/48GB <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.4</span>%<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   GPU \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mNVIDIA L40S\u001b[1m)\u001b[0m: \u001b[1;36m11.\u001b[0m6GB/48GB \u001b[1m(\u001b[0m\u001b[1;36m24.4\u001b[0m%\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ“Š Total across all GPUs: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">21.</span><span style=\"color: #000080; text-decoration-color: #000080\">3GB allocated, </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">21.</span><span style=\"color: #000080; text-decoration-color: #000080\">6GB reserved, 96GB capacity</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ“Š Total across all GPUs: \u001b[0m\u001b[1;34m21.\u001b[0m\u001b[34m3GB allocated, \u001b[0m\u001b[1;34m21.\u001b[0m\u001b[34m6GB reserved, 96GB capacity\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model successfully distributed across GPUs</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model successfully distributed across GPUs\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span> modules\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;36m0\u001b[0m: \u001b[1;36m18\u001b[0m modules\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span> modules\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   \u001b[1;36m1\u001b[0m: \u001b[1;36m28\u001b[0m modules\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                            ğŸ”§ Llama Vision Model Configuration                            </span>\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Setting             </span>â”ƒ<span style=\"font-weight: bold\"> Value                         </span>â”ƒ<span style=\"font-weight: bold\"> Llama Status                      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model Path          </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> Llama-3.2-11B-Vision-Instruct </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Valid                          </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Device Placement    </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> cuda:0                        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Loaded                         </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Quantization Method </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 16-bit                        </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… 16-bit (Performance Optimized) </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Data Type           </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> bfloat16                      </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Recommended                    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Max New Tokens      </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 2000                          </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Generation Ready               </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> GPU Configuration   </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 2x NVIDIA L40S (96GB)         </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… 96GB Total                     </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Model Parameters    </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> 10,670,220,835                </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… Loaded                         </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> Memory Optimization </span>â”‚<span style=\"color: #808000; text-decoration-color: #808000\"> Llama Robust                  </span>â”‚<span style=\"color: #008000; text-decoration-color: #008000\"> âœ… V100 Compatible                </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                            ğŸ”§ Llama Vision Model Configuration                            \u001b[0m\n",
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mSetting            \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mValue                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mLlama Status                     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel Path         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mLlama-3.2-11B-Vision-Instruct\u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Valid                         \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mDevice Placement   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mcuda:0                       \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Loaded                        \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mQuantization Method\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m16-bit                       \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… 16-bit (Performance Optimized)\u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mData Type          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mbfloat16                     \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Recommended                   \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mMax New Tokens     \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m2000                         \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Generation Ready              \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mGPU Configuration  \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m2x NVIDIA L40S (96GB)        \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… 96GB Total                    \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mModel Parameters   \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33m10,670,220,835               \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… Loaded                        \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36mMemory Optimization\u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[33m \u001b[0m\u001b[33mLlama Robust                 \u001b[0m\u001b[33m \u001b[0mâ”‚\u001b[32m \u001b[0m\u001b[32mâœ… V100 Compatible               \u001b[0m\u001b[32m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Running model compatibility test...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mRunning model compatibility test\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">âœ… Model compatibility test passed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâœ… Model compatibility test passed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Performing initial memory cleanup...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mPerforming initial memory cleanup\u001b[0m\u001b[36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸ§¹ Memory cleanup completed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸ§¹ Memory cleanup completed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸ’¾ Final state <span style=\"font-weight: bold\">(</span>Multi-GPU Total<span style=\"font-weight: bold\">)</span>: <span style=\"color: #808000; text-decoration-color: #808000\">Allocated</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>34GB, <span style=\"color: #808000; text-decoration-color: #808000\">Reserved</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.</span>65GB, <span style=\"color: #808000; text-decoration-color: #808000\">Fragmentation</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>30GB\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸ’¾ Final state \u001b[1m(\u001b[0mMulti-GPU Total\u001b[1m)\u001b[0m: \u001b[33mAllocated\u001b[0m=\u001b[1;36m21\u001b[0m\u001b[1;36m.\u001b[0m34GB, \u001b[33mReserved\u001b[0m=\u001b[1;36m21\u001b[0m\u001b[1;36m.\u001b[0m65GB, \u001b[33mFragmentation\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.\u001b[0m30GB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ‰ Llama Vision model loading and validation complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mğŸ‰ Llama Vision model loading and validation complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">ğŸ”§ Llama optimizations active: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">16</span><span style=\"color: #000080; text-decoration-color: #000080\">-bit precision, memory management, vision preservation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mğŸ”§ Llama optimizations active: \u001b[0m\u001b[1;34m16\u001b[0m\u001b[34m-bit precision, memory management, vision preservation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model weights tied successfully\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your local Llama model\n",
    "# model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"ğŸ”§ Loading Llama-3.2-Vision model...\")\n",
    "# model = MllamaForConditionalGeneration.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_id,\n",
    "    use_quantization=False,\n",
    "    device_map='auto',\n",
    "    max_new_tokens=2000,\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Add tie_weights() call\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    print(\"âœ… Model weights tied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ tie_weights() warning: {e}\")\n",
    "\n",
    "# processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Loading image...\n",
      "âœ… Image loaded: (900, 1320)\n",
      "âœ… Images list created with 1 image(s)\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/shared_PoC_data/evaluation_data/synthetic_bank_images/cba_amount_balance.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/images/image_008.png\"\n",
    "print(\"ğŸ“ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"âœ… Image loaded: {image.size}\")\n",
    "print(f\"âœ… Images list created with {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Turn Bank Statement Protocol\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract full table using those headers\n",
    "- Turn 2: Filter using the actual column names found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ TURN 0: Identifying actual table headers\n",
      "ğŸ¤– Generating response with Llama-3.2-Vision...\n"
     ]
    }
   ],
   "source": [
    "# TURN 0: Identify Table Headers\n",
    "# First, identify the actual column headers used in this specific bank statement\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "IMPORTANT STRUCTURAL NOTE:\n",
    "Some bank statements show dates as section headings with multiple transactions underneath.\n",
    "If you see this structure, remember that each transaction needs its explicit date in the final output.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ğŸ’¬ TURN 0: Identifying actual table headers\")\n",
    "print(\"ğŸ¤– Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Response generated successfully!\n",
      "\n",
      "============================================================\n",
      "TURN 0 - IDENTIFIED TABLE HEADERS:\n",
      "============================================================\n",
      "The transaction table in the bank statement image has the following column header names, in order from left to right:\n",
      "\n",
      "*   **Date**\n",
      "*   **Description**\n",
      "*   **Withdrawal**\n",
      "*   **Deposit**\n",
      "*   **Balance**\n",
      "\n",
      "These column headers are used to organize and display the various transactions listed in the table.\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Parsed 5 column headers:\n",
      "  1. 'Date'\n",
      "  2. 'Description'\n",
      "  3. 'Withdrawal'\n",
      "  4. 'Deposit'\n",
      "  5. 'Balance'\n",
      "\n",
      "âœ… Table headers saved to: llama_table_headers.txt\n",
      "ğŸ’¡ These LITERAL header names will be used in Turn 1 & 2 prompts\n"
     ]
    }
   ],
   "source": [
    "# Process the input using the CORRECT multi-turn pattern\n",
    "# Based on: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' with list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response with deterministic parameters\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output (this is the key to clean responses!)\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"âœ… Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CRITICAL: Parse the identified headers for use in subsequent turns\n",
    "# Extract column names from the response\n",
    "header_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\n",
    "identified_headers = []\n",
    "\n",
    "# Look for numbered list or bullet points\n",
    "for line in header_lines:\n",
    "    # Remove common list markers\n",
    "    cleaned = line.lstrip('0123456789.-â€¢* ').strip()\n",
    "    \n",
    "    # Strip markdown bold formatting\n",
    "    cleaned = cleaned.replace('**', '').replace('__', '')\n",
    "    \n",
    "    # Skip section headers (lines ending with colon)\n",
    "    if cleaned.endswith(':'):\n",
    "        continue\n",
    "    \n",
    "    # Skip long sentences (likely explanatory text, not headers)\n",
    "    if len(cleaned) > 40:\n",
    "        continue\n",
    "        \n",
    "    if cleaned and len(cleaned) > 2:  # Ignore very short strings\n",
    "        identified_headers.append(cleaned)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Parsed {len(identified_headers)} column headers:\")\n",
    "for i, header in enumerate(identified_headers, 1):\n",
    "    print(f\"  {i}. '{header}'\")\n",
    "\n",
    "# Store headers for use in subsequent turns\n",
    "table_headers = identified_headers\n",
    "\n",
    "# Save the table headers\n",
    "output_path = Path(\"llama_table_headers.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput)\n",
    "\n",
    "print(f\"\\nâœ… Table headers saved to: {output_path}\")\n",
    "print(\"ğŸ’¡ These LITERAL header names will be used in Turn 1 & 2 prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pattern Matching: Map extracted headers to generic concepts\n# This handles variety in bank statement column naming conventions\n\n# Pattern keywords for each concept (in priority order)\nDATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\nDESCRIPTION_PATTERNS = [\n    'description', 'details', 'transaction details', 'trans details',\n    'particulars', 'narrative', 'transaction', 'trans'\n]\nDEBIT_PATTERNS = ['debit', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\nCREDIT_PATTERNS = ['credit', 'deposit', 'deposits', 'received', 'cr']\nBALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n\n# NEW: Pattern for single-column transaction formats (e.g., \"Amount\" instead of separate Debit/Credit)\nAMOUNT_PATTERNS = ['amount', 'amt', 'value', 'total']\n\ndef match_header(headers, patterns, fallback=None):\n    \"\"\"Match a header using pattern keywords.\n    \n    Matching strategy:\n    1. Exact match (case-insensitive)\n    2. Substring match (only for patterns with length > 2 to avoid false positives)\n    \"\"\"\n    headers_lower = [h.lower() for h in headers]\n    \n    # Try exact match first\n    for pattern in patterns:\n        for i, header_lower in enumerate(headers_lower):\n            if pattern == header_lower:\n                return headers[i]\n    \n    # Try substring match (only for patterns longer than 2 chars)\n    for pattern in patterns:\n        if len(pattern) > 2:  # Avoid false positives like 'cr' matching 'description'\n            for i, header_lower in enumerate(headers_lower):\n                if pattern in header_lower:\n                    return headers[i]\n    \n    return fallback\n\n# Perform pattern matching on extracted headers\ndate_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\ndesc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n\n# NEW: First try to match a generic \"Amount\" column (for 4-column formats)\namount_col = match_header(table_headers, AMOUNT_PATTERNS, fallback=None)\n\n# Use amount_col as fallback if no separate debit/credit columns exist\n# This handles formats like: Date | Description | Amount | Balance\ndebit_col = match_header(table_headers, DEBIT_PATTERNS, fallback=amount_col if amount_col else 'Debit')\ncredit_col = match_header(table_headers, CREDIT_PATTERNS, fallback=amount_col if amount_col else 'Credit')\nbalance_col = match_header(table_headers, BALANCE_PATTERNS, fallback='Balance')\n\nprint(\"=\" * 60)\nprint(\"PATTERN MATCHING RESULTS:\")\nprint(\"=\" * 60)\nprint(f\"ğŸ“‹ Extracted Headers: {table_headers}\")\nprint(f\"\\nğŸ” Mapped Columns:\")\nprint(f\"  Date        â†’ '{date_col}'\")\nprint(f\"  Description â†’ '{desc_col}'\")\nprint(f\"  Debit       â†’ '{debit_col}'\")\nprint(f\"  Credit      â†’ '{credit_col}'\")\nprint(f\"  Balance     â†’ '{balance_col}'\")\nif amount_col:\n    print(f\"\\nğŸ’¡ Single-column format detected: '{amount_col}' used for both debit and credit\")\nprint(\"=\" * 60)\nprint(\"\\nâœ… These literal column names will be used in Turn 1 and Turn 2\")\nprint(\"ğŸ’¡ Adjust patterns above if matching fails for your bank statement format\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”‘ Multi-Turn Pattern for Llama 3.2 Vision\n",
    "\n",
    "This notebook uses the **multi-turn conversation pattern** from the Medium article:\n",
    "[Chat with Your Images Using Llama 3.2-Vision Multimodal LLMs](https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa)\n",
    "\n",
    "#### Critical Requirements:\n",
    "\n",
    "1. **Images as List**: `images = [image]` (not just `image`)\n",
    "2. **Named Parameter**: `processor(images=images, text=text, ...)` (not positional args)\n",
    "3. **Trim Generated Tokens**: `generate_ids[:, inputs['input_ids'].shape[1]:-1]`\n",
    "4. **Same Images Every Turn**: Pass the same `images` list for all turns\n",
    "\n",
    "#### Message Structure:\n",
    "\n",
    "- **Turn 1**: `{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "- **Turn 2+**: `{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}` (no image in content)\n",
    "- **Assistant**: `{\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "\n",
    "The model attends to the image only in the first turn, but the processor needs the images list for all turns because the chat template contains the `<|image|>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conversation history initialized\n",
      "ğŸ“Š Current conversation has 2 messages (1 user + 1 assistant)\n",
      "ğŸ’¡ Pattern: Using working multi-turn approach from Medium article\n"
     ]
    }
   ],
   "source": [
    "# Store conversation history for multi-turn support\n",
    "# Initialize with first exchange\n",
    "conversation_history = messageDataStructure.copy()\n",
    "\n",
    "# Add assistant's response to history\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput}]\n",
    "})\n",
    "\n",
    "print(\"âœ… Conversation history initialized\")\n",
    "print(f\"ğŸ“Š Current conversation has {len(conversation_history)} messages (1 user + 1 assistant)\")\n",
    "print(f\"ğŸ’¡ Pattern: Using working multi-turn approach from Medium article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 1: Extract Full Table in Markdown\n",
    "\n",
    "Now that we know the actual column headers, extract the complete table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# TURN 1: Extract Full Table with LITERAL Header Names\n# Using the WORKING pattern from: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n\n# Build the header string using LITERAL names from Turn 0\nheader_string = \" | \".join(table_headers)\n\nfollow_up_prompt = f\"\"\"\nNow extract the entire transaction table from the bank statement in markdown format.\n\nUse these EXACT column headers in this order:\n{header_string}\n\nFormat requirements:\n- Standard markdown table syntax with | delimiters\n- Header row: | {header_string} |\n- Separator row: | {\" | \".join([\"---\"] * len(table_headers))} |\n\nCRITICAL EXTRACTION RULES:\n1. Extract EVERY transaction as a separate row\n2. Each transaction MUST have its explicit date in the date column\n3. If multiple transactions share a date heading, repeat that date for each transaction row\n4. Do NOT skip or combine any rows\n5. Keep all amounts with decimal values intact\n6. Do NOT add explanatory text - only output the markdown table\n\nCRITICAL COLUMN POSITION RULES:\n7. Place each amount in the EXACT column where it appears in the original image\n8. Do NOT move amounts between columns based on transaction type\n9. Do NOT interpret whether a transaction should be a debit or credit\n10. If an amount appears under the \"{debit_col}\" column in the image, put it in the {debit_col} column in your table\n11. If an amount appears under the \"{credit_col}\" column in the image, put it in the {credit_col} column in your table\n12. If a column is empty for a row in the image, leave it empty in your table\n13. Preserve the EXACT visual layout - read amounts strictly by their column position\n\nExample: If you see:\n  01/06/2024\n    Transaction A    $100\n    Transaction B    $50\n    \nOutput as TWO rows:\n  | 01/06/2024 | Transaction A | $100 | ... |\n  | 01/06/2024 | Transaction B | $50  | ... |\n\"\"\"\n\n# Append user's follow-up to conversation history (text only - NO image in content)\nconversation_history.append({\n    \"role\": \"user\",\n    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt}]\n})\n\nprint(f\"ğŸ’¬ TURN 1: Extract full markdown table\")\nprint(f\"ğŸ“‹ Using literal headers: {table_headers}\")\nprint(f\"ğŸ’¡ Column position rules reference: '{debit_col}' and '{credit_col}'\")\nprint(\"ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\")\n\n# Process with updated conversation history\ntextInput = processor.apply_chat_template(\n    conversation_history, add_generation_prompt=True\n)\n\n# CRITICAL: Use named parameter 'images=' and pass the SAME images list\ninputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n\n# Generate response\noutput = model.generate(\n    **inputs,\n    max_new_tokens=2000,\n    do_sample=False,\n    temperature=None,\n    top_p=None,\n)\n\n# CRITICAL: Trim input tokens from output\ngenerate_ids = output[:, inputs['input_ids'].shape[1]:-1]\ncleanedOutput2 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n\nprint(\"\\nâœ… Follow-up response generated successfully!\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 1 - FULL MARKDOWN TABLE:\")\nprint(\"=\" * 60)\nprint(cleanedOutput2)\nprint(\"=\" * 60)\n\n# Save the markdown table\noutput_path = Path(\"llama_markdown_table_extraction.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(cleanedOutput2)\n\nprint(f\"\\nâœ… Markdown table saved to: {output_path}\")\n\n# Update conversation history with assistant's response\nconversation_history.append({\n    \"role\": \"assistant\",\n    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput2}]\n})\n\nprint(f\"\\nğŸ“Š Conversation now has {len(conversation_history)} messages\")\nprint(\"ğŸ’¡ Each transaction has explicit date, even if grouped by date heading\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 2: Filter Using Actual Column Names\n",
    "\n",
    "Filter the extracted table using the specific column names identified in Turn 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ TURN 2: Filter using literal column names\n",
      "ğŸ“‹ Filter columns: 'Date' | 'Description' | 'Withdrawal'\n",
      "ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\n",
      "\n",
      "âœ… Follow-up response generated successfully!\n",
      "\n",
      "============================================================\n",
      "TURN 2 - FILTERED WITHDRAWALS:\n",
      "============================================================\n",
      "| Date | Description | Withdrawal |\n",
      "| --- | --- | --- |\n",
      "| 07/09/2025 | EFTPOS Cash Out PRICELINE PHARMACY MACKAY QLD | $322.18 |\n",
      "| 08/09/2025 | EFTPOS Purchase OFFICEWORKS BUSINESS ROCKHAMPTO... | $64.33 |\n",
      "| 04/09/2025 | Mortgage Repayment MORT 0103P16754533 NAB | $649.79 |\n",
      "| 03/09/2025 | OSKO Payment to MIKE CHEN 809845773133 | $1365.43 |\n",
      "| 02/09/2025 | Direct Debit 15395P41608263 MWF 42730 | $199.17 |\n",
      "| 27/08/2025 | Card Purchase CHEMIST WAREHOUSE DISCOUNT Richmo... | $222.56 |\n",
      "| 26/08/2025 | Fortnightly Pay ATO PAYROLL 91032P35687918 | $5679.21 |\n",
      "| 24/08/2025 | PAY RUN ACME CORP PTY LTD 99584P07785218 | $4455.46 |\n",
      "| 23/08/2025 | Online Purchase amazon.com.au AUS | $83.78 |\n",
      "| 22/08/2025 | Salary Payment ATO 28773P16041610 | $2345.10 |\n",
      "| 20/08/2025 | Salary Payment ATO 94514P80490207 | $3541.27 |\n",
      "| 20/08/2025 | Transfer To Western Port Marina NetBank From Tod | $728.48 |\n",
      "| 18/08/2025 | Contactless Payment Cinema CAIRNS QLD | $211.28 |\n",
      "| 18/08/2025 | Auto Payment UTILITIES Red Energy 15107P21771655 | $33.24 |\n",
      "| 17/08/2025 | Fortnightly Pay ATO PAYROLL 36358P70254998 | $7201.19 |\n",
      "| 14/08/2025 | Centrelink Payment JobSeeker 59392P56090878 | $2241.39 |\n",
      "| 13/08/2025 | Equipment Purchase OfficeMax Australia 13554P45... | $478.86 |\n",
      "| 11/08/2025 | Dividend Payment PREMIUM CORP PTY LTD 73535P419... | $6395.09 |\n",
      "| 10/08/2025 | Online Purchase ebay.com.au AUS | $257.95 |\n",
      "| 09/08/2025 | International Transaction Fee | $33.83 |\n",
      "| 06/08/2025 | Business Expense IT Equipment 66969P86141679 | $62.53 |\n",
      "| 06/08/2025 | Auto Payment UTILITIES Energy Australia 47683P7... | $91.04 |\n",
      "| 08/08/2025 | Auto Payment UTILITIES Red Energy 81338P61572286 | $389.57 |\n",
      "============================================================\n",
      "\n",
      "âœ… Filtered table saved to: llama_filtered_withdrawals.txt\n",
      "\n",
      "ğŸ“Š Conversation now has 6 messages\n",
      "\n",
      "âœ… Complete Protocol:\n",
      "   Turn 0: Identify headers â†’ ['Date', 'Description', 'Withdrawal', 'Deposit', 'Balance']\n",
      "   Pattern Match: Date='Date', Desc='Description', Debit='Withdrawal'\n",
      "   Turn 1: Extract with all headers\n",
      "   Turn 2: Filter using 'Withdrawal' column\n",
      "\n",
      "âœ… No langchain dependencies - production ready!\n"
     ]
    }
   ],
   "source": [
    "# TURN 2: Filter using LITERAL column names from pattern matching\n",
    "\n",
    "follow_up_prompt_3 = f\"\"\"\n",
    "From the markdown table you just extracted, create a filtered version showing ONLY withdrawal/debit transactions.\n",
    "\n",
    "Use these EXACT column names:\n",
    "- {date_col}\n",
    "- {desc_col}  \n",
    "- {debit_col}\n",
    "\n",
    "Filter rules:\n",
    "- Only include rows where '{debit_col}' has a value (not empty)\n",
    "- Exclude credit/deposit transactions\n",
    "- Keep the markdown table format with header: | {date_col} | {desc_col} | {debit_col} |\n",
    "\n",
    "Output only the filtered markdown table.\n",
    "\"\"\"\n",
    "\n",
    "# Append user's follow-up to conversation history\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt_3}]\n",
    "})\n",
    "\n",
    "print(f\"ğŸ’¬ TURN 2: Filter using literal column names\")\n",
    "print(f\"ğŸ“‹ Filter columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")\n",
    "print(\"ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with updated conversation history\n",
    "textInput = processor.apply_chat_template(\n",
    "    conversation_history, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Use named parameter 'images=' and pass the SAME images list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput3 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\nâœ… Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 2 - FILTERED WITHDRAWALS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput3)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save filtered results\n",
    "output_path = Path(\"llama_filtered_withdrawals.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput3)\n",
    "\n",
    "print(f\"\\nâœ… Filtered table saved to: {output_path}\")\n",
    "\n",
    "# Update conversation history with assistant's response\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput3}]\n",
    "})\n",
    "\n",
    "print(f\"\\nğŸ“Š Conversation now has {len(conversation_history)} messages\")\n",
    "print(f\"\\nâœ… Complete Protocol:\")\n",
    "print(f\"   Turn 0: Identify headers â†’ {table_headers}\")\n",
    "print(f\"   Pattern Match: Date='{date_col}', Desc='{desc_col}', Debit='{debit_col}'\")\n",
    "print(f\"   Turn 1: Extract with all headers\")\n",
    "print(f\"   Turn 2: Filter using '{debit_col}' column\")\n",
    "print(\"\\nâœ… No langchain dependencies - production ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# TURN 1: Extract Full Table with LITERAL Header Names\n# Using the WORKING pattern from: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n\n# Build the header string using LITERAL names from Turn 0\nheader_string = \" | \".join(table_headers)\n\nfollow_up_prompt = f\"\"\"\nNow extract the entire transaction table from the bank statement in markdown format.\n\nUse these EXACT column headers in this order:\n{header_string}\n\nFormat requirements:\n- Standard markdown table syntax with | delimiters\n- Header row: | {header_string} |\n- Separator row: | {\" | \".join([\"---\"] * len(table_headers))} |\n\nCRITICAL EXTRACTION RULES:\n1. Extract EVERY transaction as a separate row\n2. Each transaction MUST have its explicit date in the date column\n3. If multiple transactions share a date heading, repeat that date for each transaction row\n4. Do NOT skip or combine any rows\n5. Keep all amounts with decimal values intact\n6. Do NOT add explanatory text - only output the markdown table\n\nCRITICAL COLUMN POSITION RULES:\n7. Place each amount in the EXACT column where it appears in the original image\n8. Do NOT move amounts between columns based on transaction type\n9. Do NOT interpret whether a transaction should be a debit or credit\n10. If an amount appears under the \"{debit_col}\" column in the image, put it in the {debit_col} column in your table\n11. If an amount appears under the \"{credit_col}\" column in the image, put it in the {credit_col} column in your table\n12. If a column is empty for a row in the image, leave it empty in your table\n13. Preserve the EXACT visual layout - read amounts strictly by their column position\n\nExample: If you see:\n  01/06/2024\n    Transaction A    $100\n    Transaction B    $50\n    \nOutput as TWO rows:\n  | 01/06/2024 | Transaction A | $100 | ... |\n  | 01/06/2024 | Transaction B | $50  | ... |\n\"\"\"\n\n# Append user's follow-up to conversation history (text only - NO image in content)\nconversation_history.append({\n    \"role\": \"user\",\n    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt}]\n})\n\nprint(f\"ğŸ’¬ TURN 1: Extract full markdown table\")\nprint(f\"ğŸ“‹ Using literal headers: {table_headers}\")\nprint(f\"ğŸ’¡ Column position rules reference: '{debit_col}' and '{credit_col}'\")\nprint(\"ğŸ¤– Generating follow-up response with Llama-3.2-Vision...\")\n\n# Process with updated conversation history\ntextInput = processor.apply_chat_template(\n    conversation_history, add_generation_prompt=True\n)\n\n# CRITICAL: Use named parameter 'images=' and pass the SAME images list\ninputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n\n# Generate response\noutput = model.generate(\n    **inputs,\n    max_new_tokens=2000,\n    do_sample=False,\n    temperature=None,\n    top_p=None,\n)\n\n# CRITICAL: Trim input tokens from output\ngenerate_ids = output[:, inputs['input_ids'].shape[1]:-1]\ncleanedOutput2 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n\nprint(\"\\nâœ… Follow-up response generated successfully!\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 1 - FULL MARKDOWN TABLE:\")\nprint(\"=\" * 60)\nprint(cleanedOutput2)\nprint(\"=\" * 60)\n\n# Save the markdown table\noutput_path = Path(\"llama_markdown_table_extraction.txt\")\nwith output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n    text_file.write(cleanedOutput2)\n\nprint(f\"\\nâœ… Markdown table saved to: {output_path}\")\n\n# Update conversation history with assistant's response\nconversation_history.append({\n    \"role\": \"assistant\",\n    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput2}]\n})\n\nprint(f\"\\nğŸ“Š Conversation now has {len(conversation_history)} messages\")\nprint(\"ğŸ’¡ Each transaction has explicit date, even if grouped by date heading\")"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Parsed 23 transactions from markdown table\n",
      "\n",
      "============================================================\n",
      "SAMPLE ROWS:\n",
      "============================================================\n",
      "\n",
      "Row 1:\n",
      "  Date: 07/09/2025\n",
      "  Description: EFTPOS Cash Out PRICELINE PHARMACY MACKAY QLD\n",
      "  Withdrawal: $322.18\n",
      "\n",
      "Row 2:\n",
      "  Date: 08/09/2025\n",
      "  Description: EFTPOS Purchase OFFICEWORKS BUSINESS ROCKHAMPTO...\n",
      "  Withdrawal: $64.33\n",
      "\n",
      "Row 3:\n",
      "  Date: 04/09/2025\n",
      "  Description: Mortgage Repayment MORT 0103P16754533 NAB\n",
      "  Withdrawal: $649.79\n",
      "\n",
      "============================================================\n",
      "EXTRACTED SCHEMA FIELDS:\n",
      "============================================================\n",
      "TRANSACTION_DATES: 07/09/2025 | 08/09/2025 | 04/09/2025 | 03/09/2025 | 02/09/2025 | 27/08/2025 | 26/08/2025 | 24/08/2025 | 23/08/2025 | 22/08/2025 | 20/08/2025 | 20/08/2025 | 18/08/2025 | 18/08/2025 | 17/08/2025 | 14/08/2025 | 13/08/2025 | 11/08/2025 | 10/08/2025 | 09/08/2025 | 06/08/2025 | 06/08/2025 | 08/08/2025\n",
      "LINE_ITEM_DESCRIPTIONS: EFTPOS Cash Out PRICELINE PHARMACY MACKAY QLD | EFTPOS Purchase OFFICEWORKS BUSINESS ROCKHAMPTO... | Mortgage Repayment MORT 0103P16754533 NAB | OSKO Payment to MIKE CHEN 809845773133 | Direct Debit 15395P41608263 MWF 42730 | Card Purchase CHEMIST WAREHOUSE DISCOUNT Richmo... | Fortnightly Pay ATO PAYROLL 91032P35687918 | PAY RUN ACME CORP PTY LTD 99584P07785218 | Online Purchase amazon.com.au AUS | Salary Payment ATO 28773P16041610 | Salary Payment ATO 94514P80490207 | Transfer To Western Port Marina NetBank From Tod | Contactless Payment Cinema CAIRNS QLD | Auto Payment UTILITIES Red Energy 15107P21771655 | Fortnightly Pay ATO PAYROLL 36358P70254998 | Centrelink Payment JobSeeker 59392P56090878 | Equipment Purchase OfficeMax Australia 13554P45... | Dividend Payment PREMIUM CORP PTY LTD 73535P419... | Online Purchase ebay.com.au AUS | International Transaction Fee | Business Expense IT Equipment 66969P86141679 | Auto Payment UTILITIES Energy Australia 47683P7... | Auto Payment UTILITIES Red Energy 81338P61572286\n",
      "TRANSACTION_AMOUNTS_PAID: $322.18 | $64.33 | $649.79 | $1365.43 | $199.17 | $222.56 | $5679.21 | $4455.46 | $83.78 | $2345.10 | $3541.27 | $728.48 | $211.28 | $33.24 | $7201.19 | $2241.39 | $478.86 | $6395.09 | $257.95 | $33.83 | $62.53 | $91.04 | $389.57\n",
      "STATEMENT_DATE_RANGE: 06/08/2025 to 08/09/2025\n",
      "============================================================\n",
      "\n",
      "âœ… Schema fields saved to: llama_extracted_fields.txt\n",
      "ğŸ’¡ Fields extracted from columns: 'Date' | 'Description' | 'Withdrawal'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_markdown_table(markdown_text):\n",
    "    \"\"\"Parse markdown table into list of dictionaries.\"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    # Find header row (first line with pipes)\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line and not set(line.replace('|', '').replace('-', '').strip()) == set():\n",
    "            header_idx = i\n",
    "            break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        return []\n",
    "    \n",
    "    # Parse headers\n",
    "    header_line = lines[header_idx]\n",
    "    headers = [h.strip() for h in header_line.split('|') if h.strip()]\n",
    "    \n",
    "    # Parse data rows (skip header and separator)\n",
    "    rows = []\n",
    "    for line in lines[header_idx + 1:]:\n",
    "        if '|' in line:\n",
    "            # Skip separator rows (contain only pipes, hyphens, and spaces)\n",
    "            cleaned = line.replace('|', '').replace('-', '').replace(' ', '')\n",
    "            if not cleaned:\n",
    "                continue\n",
    "            \n",
    "            values = [v.strip() for v in line.split('|') if v.strip()]\n",
    "            if len(values) == len(headers):\n",
    "                rows.append(dict(zip(headers, values)))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def extract_schema_fields(rows, date_col, desc_col, debit_col):\n",
    "    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n",
    "    if not rows:\n",
    "        return {\n",
    "            'TRANSACTION_DATES': 'NOT_FOUND',\n",
    "            'LINE_ITEM_DESCRIPTIONS': 'NOT_FOUND',\n",
    "            'TRANSACTION_AMOUNTS_PAID': 'NOT_FOUND',\n",
    "            'STATEMENT_DATE_RANGE': 'NOT_FOUND'\n",
    "        }\n",
    "    \n",
    "    # Extract lists\n",
    "    dates = []\n",
    "    descriptions = []\n",
    "    amounts = []\n",
    "    \n",
    "    for row in rows:\n",
    "        date = row.get(date_col, '').strip()\n",
    "        desc = row.get(desc_col, '').strip()\n",
    "        amount = row.get(debit_col, '').strip()\n",
    "        \n",
    "        if date:\n",
    "            dates.append(date)\n",
    "        if desc:\n",
    "            descriptions.append(desc)\n",
    "        if amount:\n",
    "            amounts.append(amount)\n",
    "    \n",
    "    # Calculate statement date range\n",
    "    date_range = 'NOT_FOUND'\n",
    "    if dates:\n",
    "        try:\n",
    "            # Try to parse dates to find min/max\n",
    "            parsed_dates = []\n",
    "            for d in dates:\n",
    "                # Try common formats\n",
    "                for fmt in ['%d/%m/%Y', '%d/%m/%y', '%Y-%m-%d', '%d-%m-%Y']:\n",
    "                    try:\n",
    "                        parsed_dates.append(datetime.strptime(d, fmt))\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            \n",
    "            if parsed_dates:\n",
    "                min_date = min(parsed_dates)\n",
    "                max_date = max(parsed_dates)\n",
    "                date_range = f\"{min_date.strftime('%d/%m/%Y')} to {max_date.strftime('%d/%m/%Y')}\"\n",
    "        except Exception:\n",
    "            # If parsing fails, use first and last date as-is\n",
    "            date_range = f\"{dates[0]} to {dates[-1]}\"\n",
    "    \n",
    "    return {\n",
    "        'TRANSACTION_DATES': ' | '.join(dates) if dates else 'NOT_FOUND',\n",
    "        'LINE_ITEM_DESCRIPTIONS': ' | '.join(descriptions) if descriptions else 'NOT_FOUND',\n",
    "        'TRANSACTION_AMOUNTS_PAID': ' | '.join(amounts) if amounts else 'NOT_FOUND',\n",
    "        'STATEMENT_DATE_RANGE': date_range\n",
    "    }\n",
    "\n",
    "# Parse the filtered markdown table from Turn 2\n",
    "parsed_rows = parse_markdown_table(cleanedOutput3)\n",
    "\n",
    "print(f\"ğŸ“Š Parsed {len(parsed_rows)} transactions from markdown table\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE ROWS:\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in enumerate(parsed_rows[:3], 1):\n",
    "    print(f\"\\nRow {i}:\")\n",
    "    for key, value in row.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract schema fields using the LITERAL column names from pattern matching\n",
    "schema_fields = extract_schema_fields(parsed_rows, date_col, desc_col, debit_col)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTED SCHEMA FIELDS:\")\n",
    "print(\"=\" * 60)\n",
    "for field, value in schema_fields.items():\n",
    "    print(f\"{field}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save to file\n",
    "output_path = Path(\"llama_extracted_fields.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for field, value in schema_fields.items():\n",
    "        f.write(f\"{field}: {value}\\n\")\n",
    "\n",
    "print(f\"\\nâœ… Schema fields saved to: {output_path}\")\n",
    "print(f\"ğŸ’¡ Fields extracted from columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}