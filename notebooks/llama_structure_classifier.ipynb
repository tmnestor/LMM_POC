{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 0: Imports\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, MllamaForConditionalGeneration"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 1: Load bank statement structure classifier prompt\n",
        "prompt_path = Path(\"/home/jovyan/nfs_share/tod/LMM_POC/prompts/bank_statement_structure_classifier.yaml\")\n",
        "\n",
        "print(\"üìÑ Loading classification prompt...\")\n",
        "with prompt_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "    classifier_config = yaml.safe_load(f)\n",
        "\n",
        "print(f\"‚úÖ Loaded classifier: {classifier_config['name']}\")\n",
        "print(f\"üìã Version: {classifier_config['version']}\")\n",
        "print(f\"üéØ Task: {classifier_config['task']}\")\n",
        "print(f\"üìä Classification categories: {len(classifier_config['classification_categories'])}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 2: Load Llama-3.2-Vision model\n",
        "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
        "\n",
        "print(\"üîß Loading Llama-3.2-Vision model...\")\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 3: Load test bank statement image\n",
        "image_path = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/image_003.png\"\n",
        "\n",
        "print(\"üì∑ Loading bank statement image...\")\n",
        "image = Image.open(image_path)\n",
        "print(f\"‚úÖ Image loaded: {image.size}\")\n",
        "print(f\"üìÅ Image path: {image_path}\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 4: Build classification prompt from YAML\n",
        "classification_instruction = classifier_config['instruction']\n",
        "\n",
        "# Build detailed prompt with all categories\n",
        "categories_text = \"\\n\\n\"\n",
        "for category_name, category_data in classifier_config['classification_categories'].items():\n",
        "    categories_text += f\"**{category_data['identifier']}**\\n\"\n",
        "    categories_text += f\"{category_data['description']}\\n\"\n",
        "    categories_text += \"Structural features:\\n\"\n",
        "    for feature in category_data['structural_features']:\n",
        "        categories_text += f\"- {feature}\\n\"\n",
        "    categories_text += \"\\n\"\n",
        "\n",
        "output_format = classifier_config['output_format']\n",
        "\n",
        "full_prompt = f\"{classification_instruction}\\n{categories_text}\\n{output_format}\"\n",
        "\n",
        "print(\"üìù Classification prompt constructed\")\n",
        "print(f\"üìè Prompt length: {len(full_prompt)} characters\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLASSIFICATION PROMPT (first 500 chars):\")\n",
        "print(\"=\"*60)\n",
        "print(full_prompt[:500])\n",
        "print(\"...\")\n",
        "print(\"=\"*60)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 5: Generate classification response\n",
        "messageDataStructure = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": full_prompt,\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"ü§ñ Generating classification with Llama-3.2-Vision...\")\n",
        "\n",
        "# Process the input\n",
        "textInput = processor.apply_chat_template(\n",
        "    messageDataStructure, add_generation_prompt=True\n",
        ")\n",
        "inputs = processor(image, textInput, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Generate response\n",
        "output = model.generate(**inputs, max_new_tokens=2000)\n",
        "generatedOutput = processor.decode(output[0])\n",
        "\n",
        "print(\"‚úÖ Classification generated successfully!\")"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 6: Display classification results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LLAMA-3.2-VISION STRUCTURE CLASSIFICATION:\")\n",
        "print(\"=\"*60)\n",
        "print(generatedOutput)\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Extract clean response (remove chat template artifacts)\n",
        "if \"<|start_header_id|>assistant<|end_header_id|>\" in generatedOutput:\n",
        "    clean_response = generatedOutput.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1]\n",
        "    clean_response = clean_response.replace(\"<|eot_id|>\", \"\").strip()\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CLEAN CLASSIFICATION RESPONSE:\")\n",
        "    print(\"=\"*60)\n",
        "    print(clean_response)\n",
        "    print(\"=\"*60)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "#Cell 7: Save classification results\n",
        "output_dir = Path(\"classification_results\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save full output\n",
        "output_path = output_dir / \"llama_structure_classification.txt\"\n",
        "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(generatedOutput)\n",
        "\n",
        "# Save clean output\n",
        "if \"<|start_header_id|>assistant<|end_header_id|>\" in generatedOutput:\n",
        "    clean_output_path = output_dir / \"llama_structure_classification_clean.txt\"\n",
        "    with clean_output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
        "        text_file.write(clean_response)\n",
        "    print(f\"‚úÖ Clean response saved to: {clean_output_path}\")\n",
        "\n",
        "print(f\"‚úÖ Full response saved to: {output_path}\")\n",
        "print(f\"üìÑ File size: {output_path.stat().st_size} bytes\")"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
