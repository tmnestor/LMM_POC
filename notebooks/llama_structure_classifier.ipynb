{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 0: Imports\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 1: Load bank statement structure classifier prompt\n# Try the simpler version first\nprompt_path = Path(\"/home/jovyan/nfs_share/tod/LMM_POC/prompts/bank_statement_structure_classifier_simple.yaml\")\n\nprint(\"üìÑ Loading classification prompt...\")\nwith prompt_path.open(\"r\", encoding=\"utf-8\") as f:\n    classifier_config = yaml.safe_load(f)\n\nprint(f\"‚úÖ Loaded classifier: {classifier_config['name']}\")\nprint(f\"üìã Version: {classifier_config['version']}\")\nprint(f\"üéØ Task: {classifier_config['task']}\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 2: Load Llama-3.2-Vision model\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"üîß Loading Llama-3.2-Vision model...\")\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 3: Load test bank statement image\n",
    "image_path = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/image_003.png\"\n",
    "\n",
    "print(\"üì∑ Loading bank statement image...\")\n",
    "image = Image.open(image_path)\n",
    "print(f\"‚úÖ Image loaded: {image.size}\")\n",
    "print(f\"üìÅ Image path: {image_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 4: Build classification prompt from YAML\nclassification_instruction = classifier_config['instruction']\noutput_format = classifier_config['output_format']\n\nfull_prompt = f\"{classification_instruction}\\n\\n{output_format}\"\n\nprint(\"üìù Classification prompt constructed\")\nprint(f\"üìè Prompt length: {len(full_prompt)} characters\")\nprint(\"\\n\" + \"=\"*60)\nprint(\"FULL CLASSIFICATION PROMPT:\")\nprint(\"=\"*60)\nprint(full_prompt)\nprint(\"=\"*60)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 5: Generate classification response\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": full_prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ü§ñ Generating classification with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process the input\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "inputs = processor(image, textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(**inputs, max_new_tokens=2000)\n",
    "generatedOutput = processor.decode(output[0])\n",
    "\n",
    "print(\"‚úÖ Classification generated successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 6: Display and classify results\nprint(\"\\n\" + \"=\"*60)\nprint(\"LLAMA-3.2-VISION STRUCTURE CLASSIFICATION:\")\nprint(\"=\"*60)\nprint(generatedOutput)\nprint(\"=\"*60)\n\n# Extract clean response (remove chat template artifacts)\nif \"<|start_header_id|>assistant<|end_header_id|>\" in generatedOutput:\n    clean_response = generatedOutput.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1]\n    clean_response = clean_response.replace(\"<|eot_id|>\", \"\").strip()\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"EXTRACTED HEADERS:\")\n    print(\"=\"*60)\n    print(clean_response)\n    print(\"=\"*60)\n    \n    # Python-based counting and classification\n    if \"NO_HEADERS\" in clean_response:\n        column_count = 0\n        structure_type = \"MOBILE_APP_LIGHT_INLINE\"\n        headers = []\n    else:\n        # Look for lines containing typical header keywords\n        header_keywords = ['Date', 'Transaction', 'Description', 'Amount', 'Debit', 'Credit', 'Balance', 'Particulars']\n        \n        header_text = None\n        for line in clean_response.split('\\n'):\n            line = line.strip()\n            # Skip empty lines\n            if not line:\n                continue\n            # Must contain commas AND at least one header keyword\n            if ',' in line and any(keyword in line for keyword in header_keywords):\n                header_text = line\n                break\n        \n        if not header_text:\n            # Still not found? Take the last non-empty line (VLM might put headers at end)\n            lines = [l.strip() for l in clean_response.split('\\n') if l.strip()]\n            if lines:\n                header_text = lines[-1]\n            else:\n                header_text = \"\"\n        \n        # Clean up trailing periods\n        header_text = header_text.rstrip('.')\n        \n        # Split by comma and clean\n        headers = [h.strip() for h in header_text.split(',') if h.strip()]\n        column_count = len(headers)\n        \n        # Classification based on Python count\n        if column_count == 3:\n            structure_type = \"TABLE_3COL_SIMPLE\"\n        elif column_count == 4:\n            structure_type = \"TABLE_4COL_STANDARD\"\n        elif column_count == 5:\n            structure_type = \"TABLE_5COL_STANDARD\"\n        elif column_count >= 6:\n            structure_type = \"TABLE_EXTENDED_LOCATION\"\n        else:\n            structure_type = \"UNKNOWN\"\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"PYTHON-BASED CLASSIFICATION:\")\n    print(\"=\"*60)\n    print(f\"Headers found: {headers}\")\n    print(f\"Column count: {column_count}\")\n    print(f\"Structure type: {structure_type}\")\n    print(\"=\"*60)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 7: Save classification results\n",
    "output_dir = Path(\"classification_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save full output\n",
    "output_path = output_dir / \"llama_structure_classification.txt\"\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(generatedOutput)\n",
    "\n",
    "# Save clean output\n",
    "if \"<|start_header_id|>assistant<|end_header_id|>\" in generatedOutput:\n",
    "    clean_output_path = output_dir / \"llama_structure_classification_clean.txt\"\n",
    "    with clean_output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(clean_response)\n",
    "    print(f\"‚úÖ Clean response saved to: {clean_output_path}\")\n",
    "\n",
    "print(f\"‚úÖ Full response saved to: {output_path}\")\n",
    "print(f\"üìÑ File size: {output_path.stat().st_size} bytes\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#Cell 8: Test document type classifier (Mobile App vs Bank Statement)\ndoc_type_prompt_path = Path(\"/home/jovyan/nfs_share/tod/LMM_POC/prompts/document_type_classifier.yaml\")\n\nprint(\"üìÑ Loading document type classifier prompt...\")\nwith doc_type_prompt_path.open(\"r\", encoding=\"utf-8\") as f:\n    doc_type_config = yaml.safe_load(f)\n\nprint(f\"‚úÖ Loaded classifier: {doc_type_config['name']}\")\nprint(f\"üìã Version: {doc_type_config['version']}\")\n\n# Build prompt\ndoc_type_instruction = doc_type_config['instruction']\ndoc_type_output = doc_type_config['output_format']\ndoc_type_prompt = f\"{doc_type_instruction}\\n\\n{doc_type_output}\"\n\n# Generate classification\ndoc_type_message = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\"},\n            {\"type\": \"text\", \"text\": doc_type_prompt},\n        ],\n    }\n]\n\nprint(\"ü§ñ Classifying document type...\")\ndoc_type_text_input = processor.apply_chat_template(\n    doc_type_message, add_generation_prompt=True\n)\ndoc_type_inputs = processor(image, doc_type_text_input, return_tensors=\"pt\").to(model.device)\ndoc_type_output = model.generate(**doc_type_inputs, max_new_tokens=100)\ndoc_type_result = processor.decode(doc_type_output[0])\n\n# Extract clean result\nif \"<|start_header_id|>assistant<|end_header_id|>\" in doc_type_result:\n    doc_type_clean = doc_type_result.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1]\n    doc_type_clean = doc_type_clean.replace(\"<|eot_id|>\", \"\").strip()\nelse:\n    doc_type_clean = doc_type_result\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"DOCUMENT TYPE CLASSIFICATION:\")\nprint(\"=\"*60)\nprint(doc_type_clean)\nprint(\"=\"*60)\n\n# Determine classification\nif \"Mobile_APP\" in doc_type_clean:\n    classification = \"Mobile_APP\"\nelif \"BANK_STATEMENT\" in doc_type_clean:\n    classification = \"BANK_STATEMENT\"\nelse:\n    classification = \"UNKNOWN\"\n\nprint(f\"\\nüè∑Ô∏è  Classification: {classification}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}