{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 0: Imports\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 1: Load both classifier prompts\ndoc_type_prompt_path = Path(\"/home/jovyan/nfs_share/tod/LMM_POC/prompts/document_type_classifier.yaml\")\nheader_prompt_path = Path(\"/home/jovyan/nfs_share/tod/LMM_POC/prompts/bank_statement_structure_classifier_simple.yaml\")\n\nprint(\"üìÑ Loading document type classifier...\")\nwith doc_type_prompt_path.open(\"r\", encoding=\"utf-8\") as f:\n    doc_type_config = yaml.safe_load(f)\nprint(f\"‚úÖ {doc_type_config['name']} v{doc_type_config['version']}\")\n\nprint(\"\\nüìÑ Loading header classifier...\")\nwith header_prompt_path.open(\"r\", encoding=\"utf-8\") as f:\n    header_config = yaml.safe_load(f)\nprint(f\"‚úÖ {header_config['name']} v{header_config['version']}\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 2: Load Llama-3.2-Vision model\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"üîß Loading Llama-3.2-Vision model...\")\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#Cell 3: Load test bank statement image\n",
    "image_path = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/image_003.png\"\n",
    "\n",
    "print(\"üì∑ Loading bank statement image...\")\n",
    "image = Image.open(image_path)\n",
    "print(f\"‚úÖ Image loaded: {image.size}\")\n",
    "print(f\"üìÅ Image path: {image_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 4: STAGE 1 - Document Type Classification\nprint(\"=\"*60)\nprint(\"STAGE 1: DOCUMENT TYPE CLASSIFICATION\")\nprint(\"=\"*60)\n\n# Build document type classification prompt\ndoc_type_prompt = f\"{doc_type_config['instruction']}\\n\\n{doc_type_config['output_format']}\"\n\n# Generate classification\ndoc_type_message = [\n    {\n        \"role\": \"user\",\n        \"content\": [\n            {\"type\": \"image\"},\n            {\"type\": \"text\", \"text\": doc_type_prompt},\n        ],\n    }\n]\n\nprint(\"ü§ñ Classifying document type...\")\ndoc_type_text_input = processor.apply_chat_template(\n    doc_type_message, add_generation_prompt=True\n)\ndoc_type_inputs = processor(image, doc_type_text_input, return_tensors=\"pt\").to(model.device)\ndoc_type_output = model.generate(**doc_type_inputs, max_new_tokens=100)\ndoc_type_result = processor.decode(doc_type_output[0])\n\n# Extract clean result\nif \"<|start_header_id|>assistant<|end_header_id|>\" in doc_type_result:\n    doc_type_clean = doc_type_result.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1]\n    doc_type_clean = doc_type_clean.replace(\"<|eot_id|>\", \"\").strip()\nelse:\n    doc_type_clean = doc_type_result\n\n# Determine classification\nif \"Mobile_APP\" in doc_type_clean:\n    document_type = \"Mobile_APP\"\nelif \"BANK_STATEMENT\" in doc_type_clean:\n    document_type = \"BANK_STATEMENT\"\nelse:\n    document_type = \"UNKNOWN\"\n\nprint(f\"‚úÖ Document Type: {document_type}\")\nprint(f\"üìù Raw response: {doc_type_clean}\")\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 5: STAGE 2 - Conditional Header Extraction\nprint(\"\\n\" + \"=\"*60)\nprint(\"STAGE 2: HEADER EXTRACTION\")\nprint(\"=\"*60)\n\nheaders_pipe_separated = None\n\nif document_type == \"BANK_STATEMENT\":\n    print(\"‚úÖ Bank statement detected - extracting headers...\")\n    \n    # Build header extraction prompt\n    header_prompt = f\"{header_config['instruction']}\\n\\n{header_config['output_format']}\"\n    \n    # Generate header extraction\n    header_message = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"image\"},\n                {\"type\": \"text\", \"text\": header_prompt},\n            ],\n        }\n    ]\n    \n    print(\"ü§ñ Extracting transaction table headers...\")\n    header_text_input = processor.apply_chat_template(\n        header_message, add_generation_prompt=True\n    )\n    header_inputs = processor(image, header_text_input, return_tensors=\"pt\").to(model.device)\n    header_output = model.generate(**header_inputs, max_new_tokens=2000)\n    header_result = processor.decode(header_output[0])\n    \n    # Extract clean response\n    if \"<|start_header_id|>assistant<|end_header_id|>\" in header_result:\n        header_clean = header_result.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1]\n        header_clean = header_clean.replace(\"<|eot_id|>\", \"\").strip()\n    else:\n        header_clean = header_result\n    \n    # Parse headers from response\n    if \"NO_HEADERS\" in header_clean:\n        headers_pipe_separated = \"NO_HEADERS\"\n    else:\n        # Look for header keywords\n        header_keywords = ['Date', 'Transaction', 'Description', 'Amount', 'Debit', 'Credit', 'Balance', 'Particulars']\n        \n        header_text = None\n        for line in header_clean.split('\\n'):\n            line = line.strip()\n            if not line:\n                continue\n            if ',' in line and any(keyword in line for keyword in header_keywords):\n                header_text = line\n                break\n        \n        if not header_text:\n            lines = [l.strip() for l in header_clean.split('\\n') if l.strip()]\n            if lines:\n                header_text = lines[-1]\n            else:\n                header_text = \"\"\n        \n        # Clean up and convert to pipe-separated\n        header_text = header_text.rstrip('.')\n        headers_list = [h.strip() for h in header_text.split(',') if h.strip()]\n        headers_pipe_separated = \" | \".join(headers_list)\n    \n    print(f\"‚úÖ Headers extracted: {headers_pipe_separated}\")\n    \nelif document_type == \"Mobile_APP\":\n    print(\"‚ÑπÔ∏è  Mobile app detected - skipping header extraction\")\n    headers_pipe_separated = \"N/A\"\nelse:\n    print(\"‚ö†Ô∏è  Unknown document type - skipping header extraction\")\n    headers_pipe_separated = \"UNKNOWN\"\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 6: Display Final Results\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL CLASSIFICATION RESULTS\")\nprint(\"=\"*60)\nprint(f\"üìÑ Image: {image_path}\")\nprint(f\"üè∑Ô∏è  Document Type: {document_type}\")\nprint(f\"üìã Headers: {headers_pipe_separated}\")\nprint(\"=\"*60)\n\n# Store results for potential saving\nclassification_result = {\n    \"image_path\": str(image_path),\n    \"document_type\": document_type,\n    \"headers\": headers_pipe_separated\n}\n",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "#Cell 7: Save Classification Results (Optional)\nimport json\n\noutput_dir = Path(\"classification_results\")\noutput_dir.mkdir(exist_ok=True)\n\n# Save as JSON\njson_path = output_dir / \"classification_result.json\"\nwith json_path.open(\"w\", encoding=\"utf-8\") as f:\n    json.dump(classification_result, f, indent=2)\n\nprint(f\"‚úÖ Results saved to: {json_path}\")\n\n# Also save as simple text format\ntext_path = output_dir / \"classification_result.txt\"\nwith text_path.open(\"w\", encoding=\"utf-8\") as f:\n    f.write(f\"Document Type: {document_type}\\n\")\n    f.write(f\"Headers: {headers_pipe_separated}\\n\")\n\nprint(f\"‚úÖ Text results saved to: {text_path}\")\n",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}