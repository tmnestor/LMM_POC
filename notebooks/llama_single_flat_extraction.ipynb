{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jovyan/_LMM_POC')\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "\n",
    "from common.reproducibility import set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "from rich import print as rprint\n",
    "\n",
    "model_path = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "rprint(\"[bold green]Loading Llama model with robust multi-GPU detection...[/bold green]\")\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_path,\n",
    "    use_quantization=False,  # No quantization as requested\n",
    "    device_map='auto',\n",
    "    max_new_tokens=2000,\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Call tie_weights() after loading\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    rprint(\"[green]‚úÖ Model weights tied successfully[/green]\")\n",
    "except Exception as e:\n",
    "    rprint(f\"[yellow]‚ö†Ô∏è tie_weights() warning (can be ignored): {e}[/yellow]\")\n",
    "\n",
    "rprint(\"[bold green]‚úÖ Model ready for single-image extraction[/bold green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "# imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/image_008.png\"\n",
    "imageName = \"/home/jovyan/_LMM_POC/evaluation_data/image_008.png\"\n",
    "\n",
    "print(\"üìÇ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "print(f\"‚úÖ Image loaded: {image.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "# basic flat 5 column [\"Date\", \"Description\", \"Withdrawal\", \"Credit\", \"Balance\"] transaction table prompt\n",
    "# prompt_text = \"\"\"\n",
    "# You are an expert document analyzer specializing in bank statement extraction.\n",
    "# Extract structured data from this flat table bank statement for taxpayer expense claims.\n",
    "\n",
    "# CONVERSATION PROTOCOL:\n",
    "# - Start your response immediately with \"DOCUMENT_TYPE: BANK_STATEMENT\"\n",
    "# - Do NOT include conversational text like \"I'll extract...\" or \"Based on the document...\"\n",
    "# - Do NOT use bullet points, numbered lists, asterisks, or markdown formatting (no **, no ##, no 1., no -)\n",
    "# - Output ONLY the structured extraction data below\n",
    "# - End immediately after \"TRANSACTION_AMOUNTS_PAID:\" with no additional text\n",
    "# - NO explanations, NO comments, NO additional text\n",
    "\n",
    "# CRITICAL:\n",
    "# - The transaction table in the image has a \"Date\", a \"Description\", a \"Withdrawal\", a \"Deposit\" and a \"Balance\" column\n",
    "# - Specifically, it has a \"Date\" column, a \"Description\" column, a \"Withdrawal\" column, a \"Deposit\" column and a \"Balance\" column\n",
    "\n",
    "# ANTI-HALLUCINATION RULES:\n",
    "# - YOU MUST NOT GUESS values you are unsure of\n",
    "# - Rows may have missing values\n",
    "# - Rows NEVER HAVE REPEATED AMOUNTS, SO YOU MUST NOT REPEAT VALUES THAT YOU ARE UNSURE OF\n",
    "# - If a value is unclear or missing, use \"NOT_FOUND\" instead of guessing\n",
    "\n",
    "# STEP 1:\n",
    "# - Extract the Transaction Table formatted as markdown.\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "prompt_text = \"\"\"\n",
    "You are an expert document analyzer specializing in bank statement extraction.\n",
    "\n",
    "Step 1\n",
    "  - Extract the Transaction Table formatted as markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "from common.text_cleaning import clean_llama_response, clean_markdown_table\n",
    "\n",
    "print(\"‚úÖ Text cleaning utilities loaded\")\n",
    "\n",
    "# Create message structure for Llama chat template\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": prompt_text},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Process the input\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "inputs = processor(image, textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response with deterministic parameters\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=4000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "generatedOutput = processor.decode(output[0])\n",
    "\n",
    "# Clean the response to remove chat and markdown artifacts\n",
    "cleanedOutput = clean_llama_response(generatedOutput)\n",
    "cleanedOutput = cleanedOutput.replace(\"\\\"**\", \"\") # remove \"**\" markdown formatting\n",
    "\n",
    "# Clean markdown table: replace empty cells with NOT_FOUND\n",
    "if '|' in cleanedOutput:  # Check if it contains a table\n",
    "    cleanedOutput = clean_markdown_table(cleanedOutput)\n",
    "    print(\"‚úÖ Empty cells replaced with NOT_FOUND\")\n",
    "\n",
    "print(\"‚úÖ Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEANED EXTRACTION:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save the cleaned response to a file\n",
    "output_path = Path(\"llama_grouped_bank_statement_output.txt\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput)\n",
    "\n",
    "print(f\"‚úÖ Response saved to: {output_path}\")\n",
    "print(f\"üìÅ File size: {output_path.stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lfy15cyglti",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "# Transform markdown table into structured extraction format\n",
    "from common.table_parser import parse_markdown_table, extract_columns, format_structured_extraction\n",
    "\n",
    "# Parse markdown table from cleanedOutput\n",
    "table_rows = parse_markdown_table(cleanedOutput)\n",
    "\n",
    "print(f\"üìä Parsed {len(table_rows)} transaction rows from markdown table\\n\")\n",
    "\n",
    "# Extract columns (0=Date, 1=Description, 2=Withdrawal)\n",
    "dates, descriptions, withdrawals = extract_columns(table_rows, 0, 1, 2)\n",
    "\n",
    "# Generate structured output (STEPS 2-5)\n",
    "structured_output = format_structured_extraction(dates, descriptions, withdrawals)\n",
    "\n",
    "# Display structured output\n",
    "print(\"=\" * 60)\n",
    "print(\"STRUCTURED EXTRACTION OUTPUT:\")\n",
    "print(\"=\" * 60)\n",
    "print(structured_output)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save structured output\n",
    "structured_path = Path(\"llama_structured_extraction_output.txt\")\n",
    "with structured_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(structured_output)\n",
    "\n",
    "print(f\"\\n‚úÖ Structured output saved to: {structured_path}\")\n",
    "print(f\"üìÅ File size: {structured_path.stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y9569i60prh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "# Filter out rows with NOT_FOUND in TRANSACTION_AMOUNTS_PAID\n",
    "from common.table_parser import filter_not_found_rows\n",
    "\n",
    "# Filter rows using module function\n",
    "filtered_dates, filtered_descriptions, filtered_amounts = filter_not_found_rows(\n",
    "    dates, descriptions, withdrawals\n",
    ")\n",
    "\n",
    "print(f\"üìä Filtered out {len(dates) - len(filtered_dates)} rows with NOT_FOUND\")\n",
    "print(f\"‚úÖ {len(filtered_dates)} transactions with actual withdrawal amounts\\n\")\n",
    "\n",
    "# Generate filtered structured output\n",
    "filtered_structured_output = format_structured_extraction(\n",
    "    filtered_dates, filtered_descriptions, filtered_amounts\n",
    ")\n",
    "\n",
    "# Display filtered structured output\n",
    "print(\"=\" * 60)\n",
    "print(\"FILTERED STRUCTURED EXTRACTION OUTPUT:\")\n",
    "print(\"(Rows with NOT_FOUND in withdrawals removed)\")\n",
    "print(\"=\" * 60)\n",
    "print(filtered_structured_output)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save filtered structured output\n",
    "filtered_path = Path(\"llama_filtered_extraction_output.txt\")\n",
    "with filtered_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(filtered_structured_output)\n",
    "\n",
    "print(f\"\\n‚úÖ Filtered output saved to: {filtered_path}\")\n",
    "print(f\"üìÅ File size: {filtered_path.stat().st_size} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
