{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, MllamaForConditionalGeneration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "print(\"‚úÖ Random seed set to 42 for reproducibility\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3\n",
        "model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
        "\n",
        "print(\"üîß Loading Llama-3.2-Vision model...\")\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# processor\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "for i in range(torch.cuda.device_count()):\n",
        "    allocated = torch.cuda.memory_allocated(i) / 1e9\n",
        "    reserved = torch.cuda.memory_reserved(i) / 1e9\n",
        "    print(f\"    GPU [{i}]: {{allocated:.2f}}GB allocated, {{reserved:.2f}}GB reserved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4\n",
        "def clean_llama_response(response: str) -> str:\n",
        "    \"\"\"Remove chat template artifacts and extract only the assistant's response.\"\"\"\n",
        "    start_marker = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
        "    end_marker = \"<|eot_id|>\"\n",
        "    \n",
        "    start_idx = response.find(start_marker)\n",
        "    if start_idx != -1:\n",
        "        start_idx += len(start_marker)\n",
        "        end_idx = response.find(end_marker, start_idx)\n",
        "        if end_idx != -1:\n",
        "            return response[start_idx:end_idx].strip()\n",
        "    \n",
        "    return response.replace(\"***\",\"\").strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5\n",
        "imageName = \"/home/jovyan/_LMM_POC/evaluation_data/image_008.png\"\n",
        "\n",
        "print(\"üìÇ Loading image...\")\n",
        "image = Image.open(imageName)\n",
        "print(f\"‚úÖ Image loaded: {image.size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6\n",
        "# basic flat 5 column [\"Date\", \"Description\", \"Withdrawal\", \"Credit\", \"Balance\"] transaction table prompt\n",
        "prompt_text = \"\"\"\n",
        "You are an expert document analyzer specializing in bank statement extraction.\n",
        "Extract structured data from this flat table bank statement for taxpayer expense claims.\n",
        "\n",
        "CONVERSATION PROTOCOL:\n",
        "- Start your response immediately with \"DOCUMENT_TYPE: BANK_STATEMENT\"\n",
        "- Do NOT include conversational text like \"I'll extract...\" or \"Based on the document...\"\n",
        "- Do NOT use bullet points, numbered lists, asterisks, or markdown formatting (no **, no ##, no 1., no -)\n",
        "- Output ONLY the structured extraction data below\n",
        "- End immediately after \"TRANSACTION_AMOUNTS_PAID:\" with no additional text\n",
        "- NO explanations, NO comments, NO additional text\n",
        "\n",
        "CRITICAL:\n",
        "- The transaction table in the image has a \"Date\", a \"Description\", a \"Withdrawal\", a \"Deposit\" and a \"Balance\" column\n",
        "- Specifically, it has a \"Date\" column, a \"Description\" column, a \"Withdrawal\" column, a \"Deposit\" column and a \"Balance\" column\n",
        "\n",
        "ANTI-HALLUCINATION RULES:\n",
        "- YOU MUST NOT GUESS values you are unsure of\n",
        "- Rows may have missing values\n",
        "- Rows NEVER HAVE REPEATED AMOUNTS, SO YOU MUST NOT REPEAT VALUES THAT YOU ARE UNSURE OF\n",
        "- If a value is unclear or missing, use \"NOT_FOUND\" instead of guessing\n",
        "\n",
        "STEP 1:\n",
        "- Extract the Transaction Table formatted as markdown.\n",
        "\n",
        "STEP 2:\n",
        "- Extract the earliest and latest date in the \"Date\" column from the extracted Transaction Table in STEP 1\n",
        "- Format as STATEMENT_DATE_RANGE: [ First date in \"Date\" column - Last date in \"Date\" column ]\n",
        "\n",
        "STEP 3:\n",
        "- Extract the \"Date\" column from the extracted Transaction Table in STEP 1\n",
        "- Format as TRANSACTION_DATES: [ All \"Date\" column dates, each separated by \" | \" ] on a single line\n",
        "\n",
        "STEP 4:\n",
        "- Extract the \"Description\" column from the extracted Transaction Table in STEP 1\n",
        "- Format as LINE_ITEM_DESCRIPTIONS: [ All \"Description\" column descriptions, each separated by \" | \" ] on a single line\n",
        "\n",
        "STEP 5:\n",
        "- Extract the \"Withdrawal\" column from the extracted Transaction Table in STEP 1, replacing missing values with \"NOT_FOUND\".\n",
        "- Format as TRANSACTION_AMOUNTS_PAID: [ All \"Withdrawal\" column amounts each separated by \" | \" ] on a single line\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0beb9a45",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Load YAML and generate dynamic prompt\n",
        "# import yaml\n",
        "# import sys\n",
        "# sys.path.insert(0, '/home/jovyan/nfs_share/tod/LMM_POC')\n",
        "# from common.header_mapping import map_headers_smart, generate_flat_table_prompt\n",
        "\n",
        "# # Assume headers were extracted earlier\n",
        "# headers = \"Date | Description | Withdrawal | Deposit | Balance\"\n",
        "# mapping = map_headers_smart(headers)\n",
        "\n",
        "# with open('/home/jovyan/nfs_share/tod/LMM_POC/prompts/flat_table_extraction.yaml') as f:\n",
        "#     config = yaml.safe_load(f)\n",
        "\n",
        "# prompt_text = generate_flat_table_prompt(mapping, headers, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7\n",
        "# Create message structure for Llama\n",
        "messageDataStructure = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\n",
        "                \"type\": \"text\",\n",
        "                \"text\": prompt_text,\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"üìù Prompt: {prompt_text}\")\n",
        "print(\"ü§ñ Generating response with Llama-3.2-Vision...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8\n",
        "# Process the input\n",
        "textInput = processor.apply_chat_template(\n",
        "    messageDataStructure, add_generation_prompt=True\n",
        ")\n",
        "inputs = processor(image, textInput, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Generate response with deterministic parameters\n",
        "output = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=4000,\n",
        "    do_sample=False,\n",
        "    temperature=None,\n",
        "    top_p=None,\n",
        ")\n",
        "generatedOutput = processor.decode(output[0])\n",
        "\n",
        "# Clean the response to remove chat and markdown artifacts\n",
        "cleanedOutput = clean_llama_response(generatedOutput)\n",
        "cleanedOutput = cleanedOutput.replace(\"\\\"**\", \"\") # remove \"**\" markdown formatting\n",
        "\n",
        "print(\"‚úÖ Response generated successfully!\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CLEANED EXTRACTION:\")\n",
        "print(\"=\" * 60)\n",
        "print(cleanedOutput)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Save the cleaned response to a file\n",
        "output_path = Path(\"llama_grouped_bank_statement_output.txt\")\n",
        "\n",
        "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(cleanedOutput)\n",
        "\n",
        "print(f\"‚úÖ Response saved to: {output_path}\")\n",
        "print(f\"üìÅ File size: {output_path.stat().st_size} bytes\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
