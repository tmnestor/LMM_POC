{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print(\"âœ… Random seed set to 42 for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Loading Llama-3.2-Vision model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0725fcb60c454caaa897cbec0f8f1ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Update this path to your local Llama model\n",
    "# model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"ðŸ”§ Loading Llama-3.2-Vision model...\")\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Loading image...\n",
      "âœ… Image loaded: (900, 1320)\n",
      "âœ… Images list created with 1 image(s)\n"
     ]
    }
   ],
   "source": [
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/shared_PoC_data/evaluation_data/image_009.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/image_008.png\"\n",
    "print(\"ðŸ“ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"âœ… Image loaded: {image.size}\")\n",
    "print(f\"âœ… Images list created with {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Prompt: \n",
      "You are an expert document analyser specializing in Date Grouped Australian Bank Statement extraction.\n",
      "Date Grouped Bank Statements are date ordered, with one or more transactions for each date header.\n",
      "Every transaction for a given date heading has a description, a debit/credit amount and finally a balance amount with a ' CR' suffix.\n",
      "Extract all balance amounts along with their ' CR' suffix, the transaction dates (from the date heading) and transaction descriptions,\n",
      "maintaining the same date ordering as the image, with every transaction appearing on its own row and remembering that some date headings have more than one balance.\n",
      "\n",
      "ðŸ¤– Generating response with Llama-3.2-Vision...\n"
     ]
    }
   ],
   "source": [
    "# Visual Question Answering - ask a simple question about the image\n",
    "prompt = \"\"\"\n",
    "You are an expert document analyser specializing in Date Grouped Australian Bank Statement extraction.\n",
    "Date Grouped Bank Statements are date ordered, with one or more transactions for each date header.\n",
    "Every transaction for a given date heading has a description, a debit/credit amount and finally a balance amount with a ' CR' suffix.\n",
    "Extract all balance amounts along with their ' CR' suffix, the transaction dates (from the date heading) and transaction descriptions,\n",
    "maintaining the same date ordering as the image, with every transaction appearing on its own row and remembering that some date headings have more than one balance.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"ðŸ’¬ Prompt: {prompt}\")\n",
    "print(\"ðŸ¤– Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Response Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_llama_response(response: str) -> str:\n",
    "    \"\"\"Remove chat template artifacts and extract only the assistant's response.\n",
    "    \n",
    "    Note: This function is kept for backwards compatibility, but when using\n",
    "    the proper multi-turn pattern (trimming generate_ids), it's not needed.\n",
    "    \"\"\"\n",
    "    start_marker = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "    end_marker = \"<|eot_id|>\"\n",
    "    \n",
    "    start_idx = response.find(start_marker)\n",
    "    if start_idx != -1:\n",
    "        start_idx += len(start_marker)\n",
    "        end_idx = response.find(end_marker, start_idx)\n",
    "        if end_idx != -1:\n",
    "            return response[start_idx:end_idx].strip()\n",
    "    \n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Response generated successfully!\n",
      "\n",
      "============================================================\n",
      "CLEANED EXTRACTION:\n",
      "============================================================\n",
      "Here is the extracted data in the format you requested:\n",
      "\n",
      "| Date | Balance | Transaction Description |\n",
      "| --- | --- | --- |\n",
      "| 07/09/2025 | $48890.58 | EFTPOS Cash Out PRICELINE PHARMACY MACKAY QLD |\n",
      "| 08/09/2025 | $49212.76 | EFTPOS Purchase OFFICEWORKS BUSINESS ROCKHAMPTO... |\n",
      "| 04/09/2025 | $49277.09 | Mortgage Repayment MORT 0103P16754533 NAB |\n",
      "| 03/09/2025 | $49226.81 | OSKO Payment to MIKE CHEN 809845773133 |\n",
      "| 03/09/2025 | $51312.57 | Direct Debit 15395P41608263 MWF 42730 |\n",
      "| 02/09/2025 | $61511.48 | Salary Payment ATO 28782P60782100 |\n",
      "| 01/09/2025 | $43405.77 | Auto Payment UTILITIES AGL 79479A0P85943944 |\n",
      "| 01/09/2025 | $43440.81 | DIRECT CREDIT SALARY 6080P67812986 |\n",
      "| 01/09/2025 | $43708.81 | BPAY Payment BILLER60279 CRN 9813018480 |\n",
      "| 31/08/2025 | $39296.85 | Professional Services Red Energy 98073P31959417 |\n",
      "| 29/08/2025 | $41754.72 | Card Purchase RED ROOSTER Paramatta SA |\n",
      "| 29/08/2025 | $42025.03 | Credit Card Payment CC 72599P33283283V98 |\n",
      "| 27/08/2025 | $43882.12 | EFTPOS Cash Out PRICELINE PHARMACY BRISBANE QLD |\n",
      "| 27/08/2025 | $44203.72 | Card Purchase CHEMIST WAREHOUSE DISCOUNT Richmo... |\n",
      "| 26/08/2025 | $44426.28 | Fortnightly Pay ATO PAYROLL 91032P35687918 |\n",
      "| 24/08/2025 | $38747.07 | PAY RUN ACME CORP PTY LTD 99584P07785218 |\n",
      "| 24/08/2025 | $34291.61 | Salary Payment ATO 30175P32361415 |\n",
      "| 23/08/2025 | $26339.68 | Online Purchase amazon.com.au AUS |\n",
      "| 22/08/2025 | $20423.46 | Salary Payment ATO 28773P16041610 |\n",
      "| 20/08/2025 | $20409.76 | Transfer To Vicks Account NetBank 54381P90841102 |\n",
      "| 20/08/2025 | $22754.86 | Salary Payment ATO 94514P80490207 |\n",
      "| 20/08/2025 | $19213.59 | Transfer To Western Port Marina NetBank From Tod |\n",
      "| 19/08/2025 | $19940.07 | Subscription Netflix 33588P77385123 |\n",
      "| 18/08/2025 | $20141.21 | Contactless Payment Cinema CAIRNS QLD |\n",
      "| 18/08/2025 | $20352.49 | Auto Payment UTILITIES Red Energy 15107P21771655 |\n",
      "| 18/08/2025 | $20385.73 | Contactless Payment Restaurant MACKAY QLD |\n",
      "| 17/08/2025 | $20531.43 | Fortnightly Pay ATO PAYROLL 36358P70254998 |\n",
      "| 14/08/2025 | $13330.24 | Centrelink Payment JobSeeker 59392P56090878 |\n",
      "| 14/08/2025 | $11088.85 | International Transaction Fee |\n",
      "| 13/08/2025 | $11115.91 | Equipment Purchase OfficeMax Australia 13554P45... |\n",
      "| 13/08/2025 | $11594.77 | International ATM USA USD |\n",
      "| 11/08/2025 | $11855.48 | Dividend Payment PREMIUM CORP PTY LTD 7353SP419... |\n",
      "| 11/08/2025 | $5460.39 | Invoice Payment HARVEY NORMAN FLAGSHIP PTY LTD ... |\n",
      "| 10/08/2025 | $5689.78 | Online Purchase ebay.com.au AUS |\n",
      "| 10/08/2025 | $5949.73 | Subscription Spotify Monthly 15369P58427775 |\n",
      "| 09/08/2025 | $9133.98 | International Transaction Fee |\n",
      "| 06/08/2025 | $6157.78 | Business Expense IT Equipment 66969P86141679 |\n",
      "| 06/08/2025 | $6792.96 | Auto Payment UTILITIES Energy Australia 47683P7... |\n",
      "| 08/08/2025 | $6884.90 | Auto Payment UTILITIES Red Energy 81338P61572286 |\n",
      "\n",
      "Note: The 'CR' suffix is not explicitly mentioned in the provided data, but it is implied in the context of the question.\n",
      "============================================================\n",
      "âœ… Response saved to: llama_grouped_bank_statement_output.txt\n",
      "ðŸ“Š File size: 2994 bytes\n"
     ]
    }
   ],
   "source": [
    "# Process the input using the CORRECT multi-turn pattern\n",
    "# Based on: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' with list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response with deterministic parameters\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output (this is the key to clean responses!)\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"âœ… Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLEANED EXTRACTION:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save the cleaned response to a file\n",
    "output_path = Path(\"llama_grouped_bank_statement_output.txt\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput)\n",
    "\n",
    "print(f\"âœ… Response saved to: {output_path}\")\n",
    "print(f\"ðŸ“Š File size: {output_path.stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation Support\n",
    "\n",
    "Llama supports multi-turn conversations by maintaining a conversation history list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Key Multi-Turn Pattern for Llama 3.2 Vision\n",
    "\n",
    "This notebook uses the **correct multi-turn conversation pattern** discovered from the Medium article:\n",
    "[Chat with Your Images Using Llama 3.2-Vision Multimodal LLMs](https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa)\n",
    "\n",
    "### Critical Requirements:\n",
    "\n",
    "1. **Images as List**: `images = [image]` (not just `image`)\n",
    "2. **Named Parameter**: `processor(images=images, text=text, ...)` (not positional args)\n",
    "3. **Trim Generated Tokens**: `generate_ids[:, inputs['input_ids'].shape[1]:-1]`\n",
    "4. **Same Images Every Turn**: Pass the same `images` list for all turns\n",
    "\n",
    "### Message Structure:\n",
    "\n",
    "- **Turn 1**: `{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "- **Turn 2+**: `{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}` (no image in content)\n",
    "- **Assistant**: `{\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "\n",
    "The model attends to the image only in the first turn, but the processor needs the images list for all turns because the chat template contains the `<|image|>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Conversation history initialized\n",
      "ðŸ“Š Current conversation has 2 messages (1 user + 1 assistant)\n",
      "ðŸ’¡ Pattern: Using working multi-turn approach from Medium article\n"
     ]
    }
   ],
   "source": [
    "# Store conversation history for multi-turn support\n",
    "# Initialize with first exchange\n",
    "conversation_history = messageDataStructure.copy()\n",
    "\n",
    "# Add assistant's response to history\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput}]\n",
    "})\n",
    "\n",
    "print(\"âœ… Conversation history initialized\")\n",
    "print(f\"ðŸ“Š Current conversation has {len(conversation_history)} messages (1 user + 1 assistant)\")\n",
    "print(f\"ðŸ’¡ Pattern: Using working multi-turn approach from Medium article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug: View Conversation Context\n",
    "\n",
    "This cell helps you see what's being sent to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Current conversation structure:\n",
      "============================================================\n",
      "\n",
      "Message 1 (user):\n",
      "  [image]\n",
      "  [text]: \n",
      "You are an expert document analyser specializing in Date Grouped Australian Bank Statement extracti...\n",
      "\n",
      "Message 2 (assistant):\n",
      "  [text]: Here is the extracted data in the format you requested:\n",
      "\n",
      "| Date | Balance | Transaction Description ...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Optional: Debug conversation structure\n",
    "print(\"ðŸ” Current conversation structure:\")\n",
    "print(\"=\" * 60)\n",
    "for i, msg in enumerate(conversation_history, 1):\n",
    "    print(f\"\\nMessage {i} ({msg['role']}):\")\n",
    "    for content in msg['content']:\n",
    "        if content['type'] == 'text':\n",
    "            preview = content['text'][:100] + \"...\" if len(content['text']) > 100 else content['text']\n",
    "            print(f\"  [text]: {preview}\")\n",
    "        else:\n",
    "            print(f\"  [{content['type']}]\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow-up Question (Turn 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Follow-up question: How many transactions are shown in this bank statement?\n",
      "ðŸ¤– Generating follow-up response with Llama-3.2-Vision...\n",
      "\n",
      "âœ… Follow-up response generated successfully!\n",
      "\n",
      "============================================================\n",
      "FOLLOW-UP RESPONSE:\n",
      "============================================================\n",
      "There are 40 transactions shown in this bank statement.\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Conversation now has 4 messages\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question (Turn 2)\n",
    "# Using the WORKING pattern from: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "follow_up_prompt = \"How many transactions are shown in this bank statement?\"\n",
    "\n",
    "# Append user's follow-up to conversation history (text only - NO image in content)\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt}]\n",
    "})\n",
    "\n",
    "print(f\"ðŸ’¬ Follow-up question: {follow_up_prompt}\")\n",
    "print(\"ðŸ¤– Generating follow-up response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with updated conversation history\n",
    "textInput = processor.apply_chat_template(\n",
    "    conversation_history, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' and pass the SAME images list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput2 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\nâœ… Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FOLLOW-UP RESPONSE:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput2)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Update conversation history with assistant's response\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput2}]\n",
    "})\n",
    "\n",
    "print(f\"\\nðŸ“Š Conversation now has {len(conversation_history)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Follow-up (Turn 3 - Optional)\n",
    "\n",
    "You can continue the conversation by running this cell with different questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Follow-up question: What is the date range covered by this bank statement?\n",
      "ðŸ¤– Generating follow-up response with Llama-3.2-Vision...\n",
      "\n",
      "âœ… Follow-up response generated successfully!\n",
      "\n",
      "============================================================\n",
      "FOLLOW-UP RESPONSE:\n",
      "============================================================\n",
      "The date range covered by this bank statement is from **August 8, 2025**, to **September 7, 2025**.\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Conversation now has 6 messages\n",
      "\n",
      "ðŸ’¡ To ask more questions, copy this cell and modify the 'follow_up_prompt_3' variable\n"
     ]
    }
   ],
   "source": [
    "# Third turn - another follow-up (uncomment to use)\n",
    "follow_up_prompt_3 = \"What is the date range covered by this bank statement?\"\n",
    "\n",
    "# Append user's follow-up to conversation history\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt_3}]\n",
    "})\n",
    "\n",
    "print(f\"ðŸ’¬ Follow-up question: {follow_up_prompt_3}\")\n",
    "print(\"ðŸ¤– Generating follow-up response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with updated conversation history\n",
    "textInput = processor.apply_chat_template(\n",
    "    conversation_history, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Use named parameter 'images=' and pass the SAME images list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput3 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\nâœ… Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FOLLOW-UP RESPONSE:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput3)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Update conversation history with assistant's response\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput3}]\n",
    "})\n",
    "\n",
    "print(f\"\\nðŸ“Š Conversation now has {len(conversation_history)} messages\")\n",
    "print(\"\\nðŸ’¡ To ask more questions, copy this cell and modify the 'follow_up_prompt_3' variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Multi-Turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Full conversation saved to: llama_multiturn_conversation.txt\n",
      "ðŸ“Š File size: 5079 bytes\n",
      "ðŸ’¬ Total messages in conversation: 6\n"
     ]
    }
   ],
   "source": [
    "# Save the entire conversation to a file\n",
    "output_path = Path(\"llama_multiturn_conversation.txt\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(\"=\" * 60 + \"\\n\")\n",
    "    text_file.write(\"MULTI-TURN CONVERSATION WITH LLAMA-3.2-VISION\\n\")\n",
    "    text_file.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "    for i, msg in enumerate(conversation_history, 1):\n",
    "        role = msg[\"role\"].upper()\n",
    "        text_file.write(f\"\\n{'-' * 60}\\n\")\n",
    "        text_file.write(f\"MESSAGE {i} - {role}\\n\")\n",
    "        text_file.write(f\"{'-' * 60}\\n\\n\")\n",
    "        \n",
    "        for content in msg[\"content\"]:\n",
    "            if content[\"type\"] == \"text\":\n",
    "                text_file.write(content[\"text\"] + \"\\n\")\n",
    "            elif content[\"type\"] == \"image\":\n",
    "                text_file.write(\"[IMAGE]\\n\")\n",
    "    \n",
    "    text_file.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "    text_file.write(f\"Total messages: {len(conversation_history)}\\n\")\n",
    "    text_file.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Full conversation saved to: {output_path}\")\n",
    "print(f\"ðŸ“Š File size: {output_path.stat().st_size} bytes\")\n",
    "print(f\"ðŸ’¬ Total messages in conversation: {len(conversation_history)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
