{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 Vision: Multi-Turn Bank Statement Markdown Extraction\n",
    "\n",
    "**Protocol**: Extract bank statement tables in markdown format, then filter/analyze via multi-turn conversation\n",
    "\n",
    "**No LangChain Dependencies** - Pure transformers + Llama multi-turn pattern\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Workflow\n",
    "\n",
    "```\n",
    "Image ‚Üí LLM (Headers) ‚Üí Python (Pattern Match) ‚Üí LLM (Extract) ‚Üí \n",
    "LLM (Filter) ‚Üí Python (Parse to Schema) ‚Üí Final Fields\n",
    "```\n",
    "\n",
    "### Pipeline Stages:\n",
    "1. **Turn 0 (LLM)**: Identify actual column headers from image\n",
    "2. **Pattern Matching (Python)**: Map headers to generic concepts (Date, Description, Debit)\n",
    "3. **Turn 1 (LLM)**: Extract full markdown table with explicit dates for each transaction\n",
    "4. **Turn 2 (LLM)**: Filter to withdrawal/debit transactions only\n",
    "5. **Python Parsing**: Convert markdown to schema format (`TRANSACTION_DATES`, `LINE_ITEM_DESCRIPTIONS`, `TRANSACTION_AMOUNTS_PAID`, `STATEMENT_DATE_RANGE`)\n",
    "\n",
    "### Key Features:\n",
    "- ‚úÖ Uses **literal column names** from actual bank statement\n",
    "- ‚úÖ Handles both **date-grouped** and **flat table** formats\n",
    "- ‚úÖ Python parsing for reliable schema extraction\n",
    "- ‚úÖ No langchain - production ready for V100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.reproducibility import set_seed\n",
    "set_seed(42)\n",
    "print(\"‚úÖ Random seed set to 42 for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your local Llama model\n",
    "# model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "model_id = \"/home/jovyan/nfs_share/models/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"üîß Loading Llama-3.2-Vision model...\")\n",
    "# model = MllamaForConditionalGeneration.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "# processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_id,\n",
    "    use_quantization=False,\n",
    "    device_map='auto',\n",
    "    max_new_tokens=2000,\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Add tie_weights() call\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    print(\"‚úÖ Model weights tied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è tie_weights() warning: {e}\")\n",
    "\n",
    "# processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your test image\n",
    "# imageName = \"/home/jovyan/shared_PoC_data/evaluation_data/image_009.png\"\n",
    "imageName = \"/home/jovyan/nfs_share/tod/LMM_POC/evaluation_data/image_008.png\"\n",
    "print(\"üìÅ Loading image...\")\n",
    "image = Image.open(imageName)\n",
    "\n",
    "# CRITICAL: Store as list for multi-turn compatibility\n",
    "images = [image]\n",
    "\n",
    "print(f\"‚úÖ Image loaded: {image.size}\")\n",
    "print(f\"‚úÖ Images list created with {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Turn Bank Statement Protocol\n",
    "- Turn 0: Identify actual table headers\n",
    "- Turn 1: Extract full table using those headers\n",
    "- Turn 2: Filter using the actual column names found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN 0: Identify Table Headers\n",
    "# First, identify the actual column headers used in this specific bank statement\n",
    "\n",
    "prompt = \"\"\"\n",
    "Look at the transaction table in this bank statement image.\n",
    "\n",
    "IMPORTANT STRUCTURAL NOTE:\n",
    "Some bank statements show dates as section headings with multiple transactions underneath.\n",
    "If you see this structure, remember that each transaction needs its explicit date in the final output.\n",
    "\n",
    "What are the exact column header names used in the transaction table?\n",
    "\n",
    "List each column header exactly as it appears, in order from left to right.\n",
    "Do not interpret or rename them - use the EXACT text from the image.\n",
    "\"\"\"\n",
    "\n",
    "# Create message structure for Llama\n",
    "messageDataStructure = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üí¨ TURN 0: Identifying actual table headers\")\n",
    "print(\"ü§ñ Generating response with Llama-3.2-Vision...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the input using the CORRECT multi-turn pattern\n",
    "# Based on: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "textInput = processor.apply_chat_template(\n",
    "    messageDataStructure, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' with list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response with deterministic parameters\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output (this is the key to clean responses!)\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"‚úÖ Response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 0 - IDENTIFIED TABLE HEADERS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# CRITICAL: Parse the identified headers for use in subsequent turns\n",
    "# Extract column names from the response\n",
    "header_lines = [line.strip() for line in cleanedOutput.split('\\n') if line.strip()]\n",
    "identified_headers = []\n",
    "\n",
    "# Look for numbered list or bullet points\n",
    "for line in header_lines:\n",
    "    # Remove common list markers\n",
    "    cleaned = line.lstrip('0123456789.-‚Ä¢* ').strip()\n",
    "    if cleaned and len(cleaned) > 2:  # Ignore very short strings\n",
    "        identified_headers.append(cleaned)\n",
    "\n",
    "print(f\"\\nüìã Parsed {len(identified_headers)} column headers:\")\n",
    "for i, header in enumerate(identified_headers, 1):\n",
    "    print(f\"  {i}. '{header}'\")\n",
    "\n",
    "# Store headers for use in subsequent turns\n",
    "table_headers = identified_headers\n",
    "\n",
    "# Save the table headers\n",
    "output_path = Path(\"llama_table_headers.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput)\n",
    "\n",
    "print(f\"\\n‚úÖ Table headers saved to: {output_path}\")\n",
    "print(\"üí° These LITERAL header names will be used in Turn 1 & 2 prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching: Map Generic Concepts to Actual Headers\n",
    "\n",
    "Different bank statements use different column names. Use pattern matching to identify:\n",
    "- Which header represents **Date**\n",
    "- Which header represents **Description/Details**  \n",
    "- Which header represents **Debit/Withdrawal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern Matching: Map extracted headers to generic concepts\n",
    "# This handles variety in bank statement column naming conventions\n",
    "\n",
    "# Pattern keywords for each concept (in priority order)\n",
    "DATE_PATTERNS = ['date', 'day', 'transaction date', 'trans date']\n",
    "DESCRIPTION_PATTERNS = [\n",
    "    'description', 'details', 'transaction details', 'trans details',\n",
    "    'particulars', 'narrative', 'transaction', 'trans'\n",
    "]\n",
    "DEBIT_PATTERNS = ['debit', 'withdrawal', 'withdrawals', 'paid', 'paid out', 'spent', 'dr']\n",
    "CREDIT_PATTERNS = ['credit', 'deposit', 'deposits', 'received', 'cr']\n",
    "BALANCE_PATTERNS = ['balance', 'bal', 'running balance']\n",
    "\n",
    "def match_header(headers, patterns, fallback=None):\n",
    "    \"\"\"Match a header using pattern keywords.\"\"\"\n",
    "    headers_lower = [h.lower() for h in headers]\n",
    "    \n",
    "    # Try exact match first\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern == header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    # Try substring match\n",
    "    for pattern in patterns:\n",
    "        for i, header_lower in enumerate(headers_lower):\n",
    "            if pattern in header_lower:\n",
    "                return headers[i]\n",
    "    \n",
    "    return fallback\n",
    "\n",
    "# Perform pattern matching on extracted headers\n",
    "date_col = match_header(table_headers, DATE_PATTERNS, fallback=table_headers[0] if table_headers else 'Date')\n",
    "desc_col = match_header(table_headers, DESCRIPTION_PATTERNS, fallback=table_headers[1] if len(table_headers) > 1 else 'Description')\n",
    "debit_col = match_header(table_headers, DEBIT_PATTERNS, fallback='Debit')\n",
    "credit_col = match_header(table_headers, CREDIT_PATTERNS, fallback='Credit')\n",
    "balance_col = match_header(table_headers, BALANCE_PATTERNS, fallback='Balance')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PATTERN MATCHING RESULTS:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìã Extracted Headers: {table_headers}\")\n",
    "print(f\"\\nüîç Mapped Columns:\")\n",
    "print(f\"  Date       ‚Üí '{date_col}'\")\n",
    "print(f\"  Description ‚Üí '{desc_col}'\")\n",
    "print(f\"  Debit      ‚Üí '{debit_col}'\")\n",
    "print(f\"  Credit     ‚Üí '{credit_col}'\")\n",
    "print(f\"  Balance    ‚Üí '{balance_col}'\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚úÖ These literal column names will be used in Turn 1 and Turn 2\")\n",
    "print(\"üí° Adjust patterns above if matching fails for your bank statement format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation Support\n",
    "\n",
    "Llama supports multi-turn conversations by maintaining a conversation history list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë Key Multi-Turn Pattern for Llama 3.2 Vision\n",
    "\n",
    "This notebook uses the **correct multi-turn conversation pattern** discovered from the Medium article:\n",
    "[Chat with Your Images Using Llama 3.2-Vision Multimodal LLMs](https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa)\n",
    "\n",
    "#### Critical Requirements:\n",
    "\n",
    "1. **Images as List**: `images = [image]` (not just `image`)\n",
    "2. **Named Parameter**: `processor(images=images, text=text, ...)` (not positional args)\n",
    "3. **Trim Generated Tokens**: `generate_ids[:, inputs['input_ids'].shape[1]:-1]`\n",
    "4. **Same Images Every Turn**: Pass the same `images` list for all turns\n",
    "\n",
    "#### Message Structure:\n",
    "\n",
    "- **Turn 1**: `{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "- **Turn 2+**: `{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}` (no image in content)\n",
    "- **Assistant**: `{\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"...\"}]}`\n",
    "\n",
    "The model attends to the image only in the first turn, but the processor needs the images list for all turns because the chat template contains the `<|image|>` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store conversation history for multi-turn support\n",
    "# Initialize with first exchange\n",
    "conversation_history = messageDataStructure.copy()\n",
    "\n",
    "# Add assistant's response to history\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput}]\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Conversation history initialized\")\n",
    "print(f\"üìä Current conversation has {len(conversation_history)} messages (1 user + 1 assistant)\")\n",
    "print(f\"üí° Pattern: Using working multi-turn approach from Medium article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug: View Conversation Context\n",
    "\n",
    "This cell helps you see what's being sent to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Debug conversation structure\n",
    "# print(\"üîç Current conversation structure:\")\n",
    "# print(\"=\" * 60)\n",
    "# for i, msg in enumerate(conversation_history, 1):\n",
    "#     print(f\"\\nMessage {i} ({msg['role']}):\")\n",
    "#     for content in msg['content']:\n",
    "#         if content['type'] == 'text':\n",
    "#             preview = content['text'][:100] + \"...\" if len(content['text']) > 100 else content['text']\n",
    "#             print(f\"  [text]: {preview}\")\n",
    "#         else:\n",
    "#             print(f\"  [{content['type']}]\")\n",
    "# print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 1: Extract Full Table in Markdown\n",
    "\n",
    "Now that we know the actual column headers, extract the complete table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN 1: Extract Full Table with LITERAL Header Names\n",
    "# Using the WORKING pattern from: https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa\n",
    "\n",
    "# Build the header string using LITERAL names from Turn 0\n",
    "header_string = \" | \".join(table_headers)\n",
    "\n",
    "follow_up_prompt = f\"\"\"\n",
    "Now extract the entire transaction table from the bank statement in markdown format.\n",
    "\n",
    "Use these EXACT column headers in this order:\n",
    "{header_string}\n",
    "\n",
    "Format requirements:\n",
    "- Standard markdown table syntax with | delimiters\n",
    "- Header row: | {header_string} |\n",
    "- Separator row: | {\" | \".join([\"---\"] * len(table_headers))} |\n",
    "\n",
    "CRITICAL EXTRACTION RULES:\n",
    "1. Extract EVERY transaction as a separate row\n",
    "2. Each transaction MUST have its explicit date in the date column\n",
    "3. If multiple transactions share a date heading, repeat that date for each transaction row\n",
    "4. Do NOT skip or combine any rows\n",
    "5. Keep all amounts with decimal values intact\n",
    "6. Do NOT add explanatory text - only output the markdown table\n",
    "\n",
    "Example: If you see:\n",
    "  01/06/2024\n",
    "    Transaction A    $100\n",
    "    Transaction B    $50\n",
    "    \n",
    "Output as TWO rows:\n",
    "  | 01/06/2024 | Transaction A | $100 | ... |\n",
    "  | 01/06/2024 | Transaction B | $50  | ... |\n",
    "\"\"\"\n",
    "\n",
    "# Append user's follow-up to conversation history (text only - NO image in content)\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt}]\n",
    "})\n",
    "\n",
    "print(f\"üí¨ TURN 1: Extract full markdown table\")\n",
    "print(f\"üìã Using literal headers: {table_headers}\")\n",
    "print(\"ü§ñ Generating follow-up response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with updated conversation history\n",
    "textInput = processor.apply_chat_template(\n",
    "    conversation_history, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# CRITICAL: Use named parameter 'images=' and pass the SAME images list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# CRITICAL: Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput2 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\n‚úÖ Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 1 - FULL MARKDOWN TABLE:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput2)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save the markdown table\n",
    "output_path = Path(\"llama_markdown_table_extraction.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput2)\n",
    "\n",
    "print(f\"\\n‚úÖ Markdown table saved to: {output_path}\")\n",
    "\n",
    "# Update conversation history with assistant's response\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput2}]\n",
    "})\n",
    "\n",
    "print(f\"\\nüìä Conversation now has {len(conversation_history)} messages\")\n",
    "print(\"üí° Each transaction has explicit date, even if grouped by date heading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TURN 2: Filter Using Actual Column Names\n",
    "\n",
    "Filter the extracted table using the specific column names identified in Turn 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURN 2: Filter using LITERAL column names from pattern matching\n",
    "\n",
    "follow_up_prompt_3 = f\"\"\"\n",
    "From the markdown table you just extracted, create a filtered version showing ONLY withdrawal/debit transactions.\n",
    "\n",
    "Use these EXACT column names:\n",
    "- {date_col}\n",
    "- {desc_col}  \n",
    "- {debit_col}\n",
    "\n",
    "Filter rules:\n",
    "- Only include rows where '{debit_col}' has a value (not empty)\n",
    "- Exclude credit/deposit transactions\n",
    "- Keep the markdown table format with header: | {date_col} | {desc_col} | {debit_col} |\n",
    "\n",
    "Output only the filtered markdown table.\n",
    "\"\"\"\n",
    "\n",
    "# Append user's follow-up to conversation history\n",
    "conversation_history.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": follow_up_prompt_3}]\n",
    "})\n",
    "\n",
    "print(f\"üí¨ TURN 2: Filter using literal column names\")\n",
    "print(f\"üìã Filter columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")\n",
    "print(\"ü§ñ Generating follow-up response with Llama-3.2-Vision...\")\n",
    "\n",
    "# Process with updated conversation history\n",
    "textInput = processor.apply_chat_template(\n",
    "    conversation_history, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# Use named parameter 'images=' and pass the SAME images list\n",
    "inputs = processor(images=images, text=textInput, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=2000,\n",
    "    do_sample=False,\n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    ")\n",
    "\n",
    "# Trim input tokens from output\n",
    "generate_ids = output[:, inputs['input_ids'].shape[1]:-1]\n",
    "cleanedOutput3 = processor.decode(generate_ids[0], clean_up_tokenization_spaces=False)\n",
    "\n",
    "print(\"\\n‚úÖ Follow-up response generated successfully!\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TURN 2 - FILTERED WITHDRAWALS:\")\n",
    "print(\"=\" * 60)\n",
    "print(cleanedOutput3)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save filtered results\n",
    "output_path = Path(\"llama_filtered_withdrawals.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(cleanedOutput3)\n",
    "\n",
    "print(f\"\\n‚úÖ Filtered table saved to: {output_path}\")\n",
    "\n",
    "# Update conversation history with assistant's response\n",
    "conversation_history.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": [{\"type\": \"text\", \"text\": cleanedOutput3}]\n",
    "})\n",
    "\n",
    "print(f\"\\nüìä Conversation now has {len(conversation_history)} messages\")\n",
    "print(f\"\\n‚úÖ Complete Protocol:\")\n",
    "print(f\"   Turn 0: Identify headers ‚Üí {table_headers}\")\n",
    "print(f\"   Pattern Match: Date='{date_col}', Desc='{desc_col}', Debit='{debit_col}'\")\n",
    "print(f\"   Turn 1: Extract with all headers\")\n",
    "print(f\"   Turn 2: Filter using '{debit_col}' column\")\n",
    "print(\"\\n‚úÖ No langchain dependencies - production ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Parsing: Extract Key Fields from Markdown Table\n",
    "\n",
    "Parse the filtered markdown table and extract fields in schema format:\n",
    "- `TRANSACTION_DATES`\n",
    "- `LINE_ITEM_DESCRIPTIONS`\n",
    "- `TRANSACTION_AMOUNTS_PAID`\n",
    "- `STATEMENT_DATE_RANGE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_markdown_table(markdown_text):\n",
    "    \"\"\"Parse markdown table into list of dictionaries.\"\"\"\n",
    "    lines = [line.strip() for line in markdown_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    # Find header row (first line with pipes)\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if '|' in line and not line.strip().startswith('|---'):\n",
    "            header_idx = i\n",
    "            break\n",
    "    \n",
    "    if header_idx is None:\n",
    "        return []\n",
    "    \n",
    "    # Parse headers\n",
    "    header_line = lines[header_idx]\n",
    "    headers = [h.strip() for h in header_line.split('|') if h.strip()]\n",
    "    \n",
    "    # Parse data rows (skip header and separator)\n",
    "    rows = []\n",
    "    for line in lines[header_idx + 1:]:\n",
    "        if '|' in line and not line.strip().startswith('|---'):\n",
    "            values = [v.strip() for v in line.split('|') if v.strip() or v == '']\n",
    "            if len(values) == len(headers):\n",
    "                rows.append(dict(zip(headers, values)))\n",
    "    \n",
    "    return rows\n",
    "\n",
    "def extract_schema_fields(rows, date_col, desc_col, debit_col):\n",
    "    \"\"\"Extract fields in universal.yaml schema format.\"\"\"\n",
    "    if not rows:\n",
    "        return {\n",
    "            'TRANSACTION_DATES': 'NOT_FOUND',\n",
    "            'LINE_ITEM_DESCRIPTIONS': 'NOT_FOUND',\n",
    "            'TRANSACTION_AMOUNTS_PAID': 'NOT_FOUND',\n",
    "            'STATEMENT_DATE_RANGE': 'NOT_FOUND'\n",
    "        }\n",
    "    \n",
    "    # Extract lists\n",
    "    dates = []\n",
    "    descriptions = []\n",
    "    amounts = []\n",
    "    \n",
    "    for row in rows:\n",
    "        date = row.get(date_col, '').strip()\n",
    "        desc = row.get(desc_col, '').strip()\n",
    "        amount = row.get(debit_col, '').strip()\n",
    "        \n",
    "        if date:\n",
    "            dates.append(date)\n",
    "        if desc:\n",
    "            descriptions.append(desc)\n",
    "        if amount:\n",
    "            amounts.append(amount)\n",
    "    \n",
    "    # Calculate statement date range\n",
    "    date_range = 'NOT_FOUND'\n",
    "    if dates:\n",
    "        try:\n",
    "            # Try to parse dates to find min/max\n",
    "            parsed_dates = []\n",
    "            for d in dates:\n",
    "                # Try common formats\n",
    "                for fmt in ['%d/%m/%Y', '%d/%m/%y', '%Y-%m-%d', '%d-%m-%Y']:\n",
    "                    try:\n",
    "                        parsed_dates.append(datetime.strptime(d, fmt))\n",
    "                        break\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            \n",
    "            if parsed_dates:\n",
    "                min_date = min(parsed_dates)\n",
    "                max_date = max(parsed_dates)\n",
    "                date_range = f\"{min_date.strftime('%d/%m/%Y')} to {max_date.strftime('%d/%m/%Y')}\"\n",
    "        except Exception:\n",
    "            # If parsing fails, use first and last date as-is\n",
    "            date_range = f\"{dates[0]} to {dates[-1]}\"\n",
    "    \n",
    "    return {\n",
    "        'TRANSACTION_DATES': ' | '.join(dates) if dates else 'NOT_FOUND',\n",
    "        'LINE_ITEM_DESCRIPTIONS': ' | '.join(descriptions) if descriptions else 'NOT_FOUND',\n",
    "        'TRANSACTION_AMOUNTS_PAID': ' | '.join(amounts) if amounts else 'NOT_FOUND',\n",
    "        'STATEMENT_DATE_RANGE': date_range\n",
    "    }\n",
    "\n",
    "# Parse the filtered markdown table from Turn 2\n",
    "parsed_rows = parse_markdown_table(cleanedOutput3)\n",
    "\n",
    "print(f\"üìä Parsed {len(parsed_rows)} transactions from markdown table\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE ROWS:\")\n",
    "print(\"=\" * 60)\n",
    "for i, row in enumerate(parsed_rows[:3], 1):\n",
    "    print(f\"\\nRow {i}:\")\n",
    "    for key, value in row.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Extract schema fields using the LITERAL column names from pattern matching\n",
    "schema_fields = extract_schema_fields(parsed_rows, date_col, desc_col, debit_col)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTED SCHEMA FIELDS:\")\n",
    "print(\"=\" * 60)\n",
    "for field, value in schema_fields.items():\n",
    "    print(f\"{field}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save to file\n",
    "output_path = Path(\"llama_extracted_fields.txt\")\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for field, value in schema_fields.items():\n",
    "        f.write(f\"{field}: {value}\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Schema fields saved to: {output_path}\")\n",
    "print(f\"üí° Fields extracted from columns: '{date_col}' | '{desc_col}' | '{debit_col}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Multi-Turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the entire conversation to a file\n",
    "# output_path = Path(\"llama_multiturn_conversation.txt\")\n",
    "\n",
    "# with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "#     text_file.write(\"=\" * 60 + \"\\n\")\n",
    "#     text_file.write(\"MULTI-TURN CONVERSATION WITH LLAMA-3.2-VISION\\n\")\n",
    "#     text_file.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "#     for i, msg in enumerate(conversation_history, 1):\n",
    "#         role = msg[\"role\"].upper()\n",
    "#         text_file.write(f\"\\n{'-' * 60}\\n\")\n",
    "#         text_file.write(f\"MESSAGE {i} - {role}\\n\")\n",
    "#         text_file.write(f\"{'-' * 60}\\n\\n\")\n",
    "        \n",
    "#         for content in msg[\"content\"]:\n",
    "#             if content[\"type\"] == \"text\":\n",
    "#                 text_file.write(content[\"text\"] + \"\\n\")\n",
    "#             elif content[\"type\"] == \"image\":\n",
    "#                 text_file.write(\"[IMAGE]\\n\")\n",
    "    \n",
    "#     text_file.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "#     text_file.write(f\"Total messages: {len(conversation_history)}\\n\")\n",
    "#     text_file.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# print(f\"‚úÖ Full conversation saved to: {output_path}\")\n",
    "# print(f\"üìä File size: {output_path.stat().st_size} bytes\")\n",
    "# print(f\"üí¨ Total messages in conversation: {len(conversation_history)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unified_vision_processor)",
   "language": "python",
   "name": "unified_vision_processor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
