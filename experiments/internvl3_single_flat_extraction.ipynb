{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "print(\"‚úÖ Random seed set to 42 for reproducibility\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3\n",
        "model_path = \"/home/jovyan/shared_PTM/InternVL3-8B\"\n",
        "\n",
        "print(\"üîß Loading InternVL3-8B model...\")\n",
        "model = AutoModel.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    low_cpu_mem_usage=True,\n",
        "    use_flash_attn=True,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\"\n",
        ").eval()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True, use_fast=False)\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "for i in range(torch.cuda.device_count()):\n",
        "    allocated = torch.cuda.memory_allocated(i) / 1e9\n",
        "    reserved = torch.cuda.memory_reserved(i) / 1e9\n",
        "    print(f\"    GPU [{i}]: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4\n",
        "def build_transform(input_size):\n",
        "    \"\"\"Build image transformation pipeline for InternVL3\"\"\"\n",
        "    IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "    IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "    \n",
        "    transform = T.Compose([\n",
        "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
        "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "    ])\n",
        "    return transform\n",
        "\n",
        "\n",
        "def load_image(image_file, input_size=448, max_num=12):\n",
        "    \"\"\"Load and preprocess image for InternVL3\"\"\"\n",
        "    image = Image.open(image_file).convert('RGB')\n",
        "    transform = build_transform(input_size=input_size)\n",
        "    pixel_values = transform(image).unsqueeze(0).to(torch.bfloat16).cuda()\n",
        "    return pixel_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5\n",
        "imageName = \"/home/jovyan/_LMM_POC/evaluation_data/image_008.png\"\n",
        "\n",
        "print(\"üìÇ Loading image...\")\n",
        "image = Image.open(imageName)\n",
        "print(f\"‚úÖ Image loaded: {image.size}\")\n",
        "\n",
        "# Preprocess for InternVL3\n",
        "pixel_values = load_image(imageName, input_size=448)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6\n",
        "# basic flat 5 column [\"Date\", \"Description\", \"Withdrawal\", \"Credit\", \"Balance\"] transaction table prompt\n",
        "prompt_text = \"\"\"\n",
        "You are an expert document analyzer specializing in bank statement extraction.\n",
        "Extract structured data from this flat table bank statement for taxpayer expense claims.\n",
        "\n",
        "CONVERSATION PROTOCOL:\n",
        "- Start your response immediately with \"DOCUMENT_TYPE: BANK_STATEMENT\"\n",
        "- Do NOT include conversational text like \"I'll extract...\" or \"Based on the document...\"\n",
        "- Do NOT use bullet points, numbered lists, asterisks, or markdown formatting (no **, no ##, no 1., no -)\n",
        "- Output ONLY the structured extraction data below\n",
        "- End immediately after \"TRANSACTION_AMOUNTS_PAID:\" with no additional text\n",
        "- NO explanations, NO comments, NO additional text\n",
        "\n",
        "CRITICAL:\n",
        "- The transaction table in the image has a \"Date\", a \"Description\", a \"Withdrawal\", a \"Deposit\" and a \"Balance\" column\n",
        "- Specifically, it has a \"Date\" column, a \"Description\" column, a \"Withdrawal\" column, a \"Deposit\" column and a \"Balance\" column\n",
        "\n",
        "ANTI-HALLUCINATION RULES:\n",
        "- YOU MUST NOT GUESS values you are unsure of\n",
        "- Rows may have missing values\n",
        "- Rows NEVER HAVE REPEATED AMOUNTS, SO YOU MUST NOT REPEAT VALUES THAT YOU ARE UNSURE OF\n",
        "- If a value is unclear or missing, use \"NOT_FOUND\" instead of guessing\n",
        "\n",
        "STEP 1:\n",
        "- Extract the Transaction Table formatted as markdown.\n",
        "\n",
        "STEP 2:\n",
        "- Extract the earliest and latest date in the \"Date\" column from the extracted Transaction Table in STEP 1\n",
        "- Format as STATEMENT_DATE_RANGE: [ First date in \"Date\" column - Last date in \"Date\" column ]\n",
        "\n",
        "STEP 3:\n",
        "- Extract the \"Date\" column from the extracted Transaction Table in STEP 1\n",
        "- Format as TRANSACTION_DATES: [ All \"Date\" column dates, each separated by \" | \" ] on a single line\n",
        "\n",
        "STEP 4:\n",
        "- Extract the \"Description\" column from the extracted Transaction Table in STEP 1\n",
        "- Format as LINE_ITEM_DESCRIPTIONS: [ All \"Description\" column descriptions, each separated by \" | \" ] on a single line\n",
        "\n",
        "STEP 5:\n",
        "- Extract the \"Withdrawal\" column from the extracted Transaction Table in STEP 1, replacing missing values with \"NOT_FOUND\".\n",
        "- Format as TRANSACTION_AMOUNTS_PAID: [ All \"Withdrawal\" column amounts each separated by \" | \" ] on a single line\n",
        "\"\"\"\n",
        "\n",
        "print(f\"üìù Prompt length: {len(prompt_text)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7\n",
        "generation_config = dict(max_new_tokens=4000, do_sample=False)\n",
        "\n",
        "print(\"ü§ñ Generating response with InternVL3-8B...\")\n",
        "\n",
        "# Generate response\n",
        "response = model.chat(\n",
        "    tokenizer=tokenizer,\n",
        "    pixel_values=pixel_values,\n",
        "    question=prompt_text,\n",
        "    generation_config=generation_config\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Response generated successfully!\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"EXTRACTION RESULT:\")\n",
        "print(\"=\" * 60)\n",
        "print(response)\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8\n",
        "# Save the response to a file\n",
        "output_path = Path(\"internvl3_grouped_bank_statement_output.txt\")\n",
        "\n",
        "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
        "    text_file.write(response)\n",
        "\n",
        "print(f\"‚úÖ Response saved to: {output_path}\")\n",
        "print(f\"üìÅ File size: {output_path.stat().st_size} bytes\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
