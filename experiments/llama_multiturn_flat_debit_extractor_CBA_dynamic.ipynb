{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.2 Vision Multi-Turn Flat Debit Extractor - CBA Dynamic\n",
    "\n",
    "- This notebook demonstrates multi-turn conversational extraction using Llama 3.2 Vision.\n",
    "- Uses the `chat_with_mllm` pattern to handle multiple turns of conversation with Flat Bank Statement images.\n",
    "- **Dynamic column references**: Uses actual column names from Turn 0 instead of hardcoded values.\n",
    "- **Position-based mapping**: Column roles determined by position (1=date, 2=description, 3=debit, 4=credit, 5=balance)\n",
    "\n",
    "**Reference**: [Chat with Your Images Using Multimodal LLMs](https://medium.com/data-science/chat-with-your-images-using-multimodal-llms-60af003e8bfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path for common/ imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration\n",
    "from transformers.image_utils import load_image\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-emptive Memory Cleanup\n",
    "\n",
    "Optional GPU memory cleanup to prevent OOM errors when switching between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Pre-emptive memory cleanup (useful when switching models)\n",
    "try:\n",
    "    from common.gpu_optimization import emergency_cleanup\n",
    "    print(\"ðŸ§¹ Clearing GPU memory...\")\n",
    "    emergency_cleanup(verbose=False)\n",
    "    print(\"âœ… Memory cleanup complete\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ GPU optimization module not available - skipping cleanup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.reproducibility import set_seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"/home/jovyan/shared_PTM/Llama-3.2-11B-Vision-Instruct\"\n",
    "\n",
    "print(\"ðŸ”§ Loading Llama-3.2-Vision model...\")\n",
    "\n",
    "from common.llama_model_loader_robust import load_llama_model_robust\n",
    "\n",
    "model, processor = load_llama_model_robust(\n",
    "    model_path=model_id,\n",
    "    use_quantization=False,\n",
    "    device_map='auto',\n",
    "    max_new_tokens=2000,\n",
    "    torch_dtype='bfloat16',\n",
    "    low_cpu_mem_usage=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Add tie_weights() call\n",
    "try:\n",
    "    model.tie_weights()\n",
    "    print(\"âœ… Model weights tied successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ tie_weights() warning: {e}\")\n",
    "\n",
    "print(\"âœ… Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Manual Memory Cleanup\n",
    "\n",
    "Run this cell if you experience memory issues during the conversation. Not needed for normal operation on H200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Run this cell if you experience memory issues during conversation\n",
    "# import gc\n",
    "\n",
    "# print(\"ðŸ§¹ Manual memory cleanup...\")\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Show memory status\n",
    "# if torch.cuda.is_available():\n",
    "#     for i in range(torch.cuda.device_count()):\n",
    "#         allocated = torch.cuda.memory_allocated(i) / 1e9\n",
    "#         reserved = torch.cuda.memory_reserved(i) / 1e9\n",
    "#         print(f\"   GPU {i}: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved\")\n",
    "# print(\"âœ… Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define chat_with_mllm Function\n",
    "\n",
    "This function encapsulates the multi-turn conversation pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from common.llama_multiturn_chat import chat_with_mllm\n\nprint(\"âœ… chat_with_mllm function imported from common.llama_multiturn_chat\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Column Mapping Functions\n",
    "\n",
    "These functions parse Turn 0 output and generate prompts with actual column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from common.header_mapping import parse_5_column_headers\n\n\ndef generate_dynamic_prompts(column_map):\n    \"\"\"Generate conversation prompts with actual column names from Turn 0.\n    \n    Args:\n        column_map: dict from parse_5_column_headers() with keys: date, description, debit, credit, balance\n    \n    Returns:\n        dict: CONVERSATION_PROMPTS dictionary with dynamic column references\n    \"\"\"\n    return {\n        \"turn_0_identify_headers\": \"\"\"Look at the bank statement image.\n\nFind the transaction table where transactions are listed.\n\nAt the top of this table, there is a row of column headers.\n\nYour task: List ALL the column headers from this table, starting from the left edge and moving to the right edge.\n\nIMPORTANT: The leftmost column is usually \"Date\" or \"Date of Transaction\". Start there and read every header moving right.\n\nInclude EVERY header you see. Do not skip any.\n\nOutput Format:\n- TRANSACTION TABLE HEADERS (reading left to right):\n- [Write ONLY the headers you actually see in the image, separated by commas]\n- If no table headers visible, write: NO_HEADERS\"\"\",\n        \n        \"turn_1_initial_extraction\": f\"\"\"Extract the transaction table from this Australian bank statement in markdown format.\n\nCRITICAL FORMATTING RULES:\n\n1. DATE FORMAT:\n   - Australian bank statements use \"DD Mon YYYY\" or \"DD Mon\" format\n   - Example formats: \"15 Mar 2024\", \"15 Mar\", \"15 March\"\n   - Each row has ONE date entry in the \"{column_map['date']}\" column (leftmost)\n\n2. TRANSACTION DESCRIPTIONS:\n   - Some transaction descriptions span multiple visual lines\n   - You MUST combine all lines for a single transaction into ONE table row\n   - Example: If you see:\n     Line 1: \"SUPERMARKET PAYMENT\"\n     Line 2: \"Card xx1234\"\n     Line 3: \"Value Date: 20/03/2024\"\n   - Combine as: \"SUPERMARKET PAYMENT Card xx1234 Value Date: 20/03/2024\"\n\n3. COLUMN STRUCTURE:\n   - The table has these columns: {column_map['date']} | {column_map['description']} | {column_map['debit']} | {column_map['credit']} | {column_map['balance']}\n   - Maintain proper markdown table alignment with | separators\n   - Empty cells should be represented with nothing between pipes\n\n4. CR NOTATION (if applicable):\n   - \"{column_map['balance']}\" column may show \"CR\" suffix (e.g., \"$1,234.56 CR\")\n   - \"{column_map['credit']}\" column typically does NOT show \"CR\" suffix\n   - Preserve \"CR\" notation exactly as shown in the image\n\nOutput the complete transaction table in markdown format.\"\"\",\n        \n        \"turn_2_select_columns\": f\"\"\"STEP 2: From the table you extracted in STEP 1, extract only the \"{column_map['date']} | {column_map['description']} | {column_map['debit']}\" columns\"\"\",\n        \n        \"turn_3_extract_debits\": f\"\"\"STEP 3: From the table you extracted in STEP 2, remove any row NOT showing an amount (i.e. having an empty cell) in the \"{column_map['debit']}\" column.\"\"\",\n        \n        \"turn_4_date_range\": f\"\"\"Extract earliest date and the latest date from the \"{column_map['date']}\" column. Express your answer in the format \"STATEMENT_DATE_RANGE: dd/mm/yyyy - dd/mm/yyyy\" \"\"\"\n    }\n\nprint(\"âœ… parse_5_column_headers imported from common.header_mapping\")\nprint(\"âœ… generate_dynamic_prompts function defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Turn 0 Prompt\n",
    "\n",
    "Turn 0 prompt is always static (used to identify headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TURN_0_PROMPT = \"\"\"Look at the bank statement image.\n",
    "\n",
    "Find the transaction table where transactions are listed.\n",
    "\n",
    "At the top of this table, there is a row of column headers.\n",
    "\n",
    "Your task: List ALL the column headers from this table, starting from the left edge and moving to the right edge.\n",
    "\n",
    "IMPORTANT: The leftmost column is usually \"Date\" or \"Date of Transaction\". Start there and read every header moving right.\n",
    "\n",
    "Include EVERY header you see. Do not skip any.\n",
    "\n",
    "Output Format:\n",
    "- TRANSACTION TABLE HEADERS (reading left to right):\n",
    "- [Write ONLY the headers you actually see in the image, separated by commas]\n",
    "- If no table headers visible, write: NO_HEADERS\"\"\"\n",
    "\n",
    "print(\"âœ… Turn 0 prompt defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image path\n",
    "imageName = \"/home/jovyan/_LMM_POC/evaluation_data/image_003.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "source": "# OPTIONAL: Uncomment to enable preprocessing\n# from common.image_preprocessing import enhance_for_llama, preprocess_statement_for_llama, enhance_statement_quality\n# from PIL import Image\n# import tempfile\n\n# # Choose ONE preprocessing approach:\n\n# # Option 1: Light enhancement (recommended for high-quality scans)\n# # preprocessed_img = enhance_statement_quality(imageName)\n\n# # Option 2: Moderate enhancement (upscaling + sharpness + contrast)\n# # preprocessed_img = enhance_for_llama(imageName)\n\n# # Option 3: Aggressive preprocessing (denoise + binarize + remove lines)\n# # preprocessed_img = preprocess_statement_for_llama(imageName)\n\n# # Save preprocessed image to temporary file and update imageName\n# # with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:\n# #     preprocessed_img.save(tmp.name)\n# #     imageName = tmp.name\n# #     print(f\"âœ… Using preprocessed image: {imageName}\")\n# #     display(preprocessed_img)\n\nprint(\"â­ï¸  Skipping preprocessing - using original image\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## OPTIONAL: Image Preprocessing\n\n**Experimental:** Test whether preprocessing improves extraction accuracy.\n\nAvailable preprocessing functions:\n- `enhance_for_llama()` - Upscale, sharpen, increase contrast\n- `preprocess_statement_for_llama()` - Denoise, binarize, remove table lines\n- `enhance_statement_quality()` - Moderate enhancement for bank statements\n\n**Note:** Modern VLMs are trained on natural images. Preprocessing may help with low-quality scans but could hurt performance on high-quality images. Test both approaches to see what works best for your data.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 0: Identify Table Headers\n",
    "\n",
    "First, identify all column headers in the transaction table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize conversation\nmessages = []\nimages = []\n\nprint(\"ðŸ“¸ Processing bank statement image...\")\nprint(f\"ðŸ“ Using prompt: turn_0_identify_headers\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PROMPT:\")\nprint(\"=\" * 60)\nprint(TURN_0_PROMPT)\nprint(\"=\" * 60 + \"\\n\")\n\nresponse0, messages, images = chat_with_mllm(\n    model, \n    processor, \n    TURN_0_PROMPT,\n    images_path=[imageName],\n    do_sample=False,\n    max_new_tokens=500,\n    show_image=True,\n    messages=messages,\n    images=images\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 0 - IDENTIFY TABLE HEADERS:\")\nprint(\"=\" * 60)\nprint(response0)\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Column Headers and Generate Dynamic Prompts\n",
    "\n",
    "Extract actual column names from Turn 0 and create prompts that reference them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Parse Turn 0 response to extract column names\ncolumn_map = parse_5_column_headers(response0)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"COLUMN MAPPING (Position-Based):\")\nprint(\"=\" * 60)\nprint(f\"Position 1 (Date):        '{column_map['date']}'\")\nprint(f\"Position 2 (Description): '{column_map['description']}'\")\nprint(f\"Position 3 (Debit):       '{column_map['debit']}'\")\nprint(f\"Position 4 (Credit):      '{column_map['credit']}'\")\nprint(f\"Position 5 (Balance):     '{column_map['balance']}'\")\nprint(\"=\" * 60)\n\n# Generate dynamic prompts using actual column names\nCONVERSATION_PROMPTS = generate_dynamic_prompts(column_map)\nprint(\"\\nâœ… Dynamic prompts generated with actual column names\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 1: Extract Transaction Table\n",
    "\n",
    "Extract the complete transaction table in markdown format using dynamic column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"ðŸ“ Using prompt: turn_1_initial_extraction\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PROMPT:\")\nprint(\"=\" * 60)\nprint(CONVERSATION_PROMPTS[\"turn_1_initial_extraction\"])\nprint(\"=\" * 60 + \"\\n\")\n\nresponse1, messages, images = chat_with_mllm(\n    model, \n    processor, \n    CONVERSATION_PROMPTS[\"turn_1_initial_extraction\"],\n    messages=messages,\n    images=images,\n    do_sample=False,\n    max_new_tokens=3000\n)\n\ndisplay(Markdown(response1))\n\n# Save initial extraction\nPath(\"llama_debit_extractor_initial_dynamic.txt\").write_text(response1)\nprint(\"\\nâœ… Initial extraction saved to llama_debit_extractor_initial_dynamic.txt\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 2: Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"ðŸ“ Using prompt: turn_2_select_columns\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PROMPT:\")\nprint(\"=\" * 60)\nprint(CONVERSATION_PROMPTS[\"turn_2_select_columns\"])\nprint(\"=\" * 60 + \"\\n\")\n\nresponse2, messages, images = chat_with_mllm(\n    model, processor,\n    CONVERSATION_PROMPTS[\"turn_2_select_columns\"],\n    messages=messages, \n    images=images,\n    max_new_tokens=2000\n)\n\ndisplay(Markdown(response2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 3: Extract Debit/Withdrawal Amounts Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"ðŸ“ Using prompt: turn_3_extract_debits\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PROMPT:\")\nprint(\"=\" * 60)\nprint(CONVERSATION_PROMPTS[\"turn_3_extract_debits\"])\nprint(\"=\" * 60 + \"\\n\")\n\nresponse3, messages, images = chat_with_mllm(\n    model, processor,\n    CONVERSATION_PROMPTS[\"turn_3_extract_debits\"],\n    messages=messages,\n    images=images,\n    max_new_tokens=2000\n)\n\ndisplay(Markdown(response3))\n\n# Save debit amounts\nPath(\"llama_debit_amounts_dynamic.txt\").write_text(response3)\nprint(\"\\nâœ… Debit amounts saved to llama_debit_amounts_dynamic.txt\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn 4: Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"ðŸ“ Using prompt: turn_4_date_range\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PROMPT:\")\nprint(\"=\" * 60)\nprint(CONVERSATION_PROMPTS[\"turn_4_date_range\"])\nprint(\"=\" * 60 + \"\\n\")\n\nresponse4, messages, images = chat_with_mllm(\n    model, processor,\n    CONVERSATION_PROMPTS[\"turn_4_date_range\"],\n    messages=messages,\n    images=images,\n    max_new_tokens=50\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"TURN 4 - DATE RANGE:\")\nprint(\"=\" * 60)\nprint(response4)\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug: View Conversation Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Current conversation structure:\")\n",
    "print(\"=\" * 60)\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"\\nMessage {i} ({msg['role']}):\")\n",
    "    for content in msg['content']:\n",
    "        if content['type'] == 'text':\n",
    "            preview = content['text'][:100] + \"...\" if len(content['text']) > 100 else content['text']\n",
    "            print(f\"  [text]: {preview}\")\n",
    "        else:\n",
    "            print(f\"  [{content['type']}]\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸ“Š Total messages: {len(messages)}\")\n",
    "print(f\"ðŸ“Š User messages: {sum(1 for m in messages if m['role'] == 'user')}\")\n",
    "print(f\"ðŸ“Š Assistant messages: {sum(1 for m in messages if m['role'] == 'assistant')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Full Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire conversation to a file\n",
    "output_path = Path(\"llama_multiturn_debit_conversation_dynamic.txt\")\n",
    "\n",
    "with output_path.open(\"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(\"=\" * 60 + \"\\n\")\n",
    "    text_file.write(\"MULTI-TURN DEBIT EXTRACTION CONVERSATION (DYNAMIC)\\n\")\n",
    "    text_file.write(\"Llama-3.2-Vision-11B\\n\")\n",
    "    text_file.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "    # Write column mapping\n",
    "    text_file.write(\"COLUMN MAPPING:\\n\")\n",
    "    text_file.write(f\"  Date column:        {column_map['date']}\\n\")\n",
    "    text_file.write(f\"  Description column: {column_map['description']}\\n\")\n",
    "    text_file.write(f\"  Debit column:       {column_map['debit']}\\n\")\n",
    "    text_file.write(f\"  Credit column:      {column_map['credit']}\\n\")\n",
    "    text_file.write(f\"  Balance column:     {column_map['balance']}\\n\")\n",
    "    text_file.write(\"\\n\" + \"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "    for i, msg in enumerate(messages, 1):\n",
    "        role = msg[\"role\"].upper()\n",
    "        text_file.write(f\"\\n{'-' * 60}\\n\")\n",
    "        text_file.write(f\"MESSAGE {i} - {role}\\n\")\n",
    "        text_file.write(f\"{'-' * 60}\\n\\n\")\n",
    "        \n",
    "        for content in msg[\"content\"]:\n",
    "            if content[\"type\"] == \"text\":\n",
    "                text_file.write(content[\"text\"] + \"\\n\")\n",
    "            elif content[\"type\"] == \"image\":\n",
    "                text_file.write(\"[IMAGE]\\n\")\n",
    "    \n",
    "    text_file.write(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "    text_file.write(f\"Total messages: {len(messages)}\\n\")\n",
    "    text_file.write(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "print(f\"âœ… Full conversation saved to: {output_path}\")\n",
    "print(f\"ðŸ“Š File size: {output_path.stat().st_size} bytes\")\n",
    "print(f\"ðŸ’¬ Total messages in conversation: {len(messages)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}